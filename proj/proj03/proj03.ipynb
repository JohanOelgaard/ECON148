{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import of packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.formula.api as smf\n",
    "from stargazer.stargazer import Stargazer\n",
    "from random import choices  # To randomly choose clusters\n",
    "from sklearn.utils import resample \n",
    "\n",
    "\n",
    "# autoreload for easier debugging\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "baseline = pd.read_stata('data/baseline.dta')\n",
    "bok_inflation = pd.read_stata('data/BOK_inflation.dta')\n",
    "cleanpricedata_y1y2 = pd.read_stata('data/cleanPriceData_Y1Y2.dta')\n",
    "intensity_obs_short = pd.read_stata('data/intensity_obs_short.dta')\n",
    "lrfu_select_dataset = pd.read_stata('data/LRFU_select_dataset.dta')\n",
    "ms1ms2_pooled = pd.read_stata('data/MS1MS2_pooled.dta')\n",
    "repayment_datay1 = pd.read_stata('data/repayment_dataY1.dta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Table 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by cleaning the ms1ms2_pooled and baseline data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1019\n"
     ]
    }
   ],
   "source": [
    "# clean ms1ms2_pooled (drop if MS !=2, keep columns oafid and treatMS1MS2, group by oafid and take mean and rename)\n",
    "ms1ms2_pooled_tab1 = ms1ms2_pooled[ms1ms2_pooled['MS']==2]\n",
    "ms1ms2_pooled_tab1 = ms1ms2_pooled_tab1[['oafid', 'treatMS1MS2']]\n",
    "ms1ms2_pooled_tab1 = ms1ms2_pooled_tab1.groupby('oafid', as_index=False).mean()\n",
    "ms1ms2_pooled_tab1.rename(columns={'treatMS1MS2': 'treat13'}, inplace=True)\n",
    "print(ms1ms2_pooled_tab1.shape[0]) # checking we have the right number of observations as described in the original article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the baseline data we note that some of the columns have already been renamed with the suffix `_base` however and thus need to account for this. We however, assume that the data have not been altered in any other way compared to what the do in the `do` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yw/jsw5n53s1cb1s2q6tt0msrm00000gn/T/ipykernel_16581/2284489521.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  baseline_clean.loc[baseline_clean['treatment2012'] == '', 'treat12'] = np.nan\n"
     ]
    }
   ],
   "source": [
    "# clean baseline data (the stata code indicates that the variables columns 'businessprofitmonth' and 'delta' should be kept, however they have already been renamed to 'businessprofitmonth_base' and 'delta_base')\n",
    "base_cols = ['oafid', 'logtotcons_base', 'male', 'num_adults', 'num_schoolchildren', 'finished_primary',\n",
    "                   'finished_secondary', 'cropland', 'num_rooms', 'schoolfees', 'totcons_base', 'logpercapcons_base',\n",
    "                   'total_cash_savings_base', 'total_cash_savings_trimmed', 'has_savings_acct', 'taken_bank_loan',\n",
    "                   'taken_informal_loan', 'liquidWealth', 'wagepay', 'businessprofitmonth_base', 'price_avg_diff_pct',\n",
    "                   'price_expect_diff_pct', 'harvest2011', 'netrevenue2011', 'netseller2011', 'autarkic2011',\n",
    "                   'maizelostpct2011', 'harvest2012', 'correct_interest', 'digit_recall', 'maizegiver', 'delta_base', 'treatment']\n",
    "baseline_clean = baseline[base_cols].copy()\n",
    "\n",
    "# rename columns\n",
    "baseline_clean.columns = [col + '_base' if not col.endswith('_base') and col != 'oafid' and col != 'treatment' else col for col in baseline_clean.columns]\n",
    "baseline_clean.rename(columns={'treatment': 'treatment2012'}, inplace=True)\n",
    "\n",
    "# generate treat12 as bool for treatment and control in 2012\n",
    "baseline_clean['treat12'] = baseline_clean['treatment2012'].apply(lambda x: x in ['T1', 'T2'])\n",
    "baseline_clean.loc[baseline_clean['treatment2012'] == '', 'treat12'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can merge the two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge baseline_clean and ms1ms2_pooled_clean on oafid\n",
    "base_ms1ms2_pool = pd.merge(baseline_clean, ms1ms2_pooled_tab1, on='oafid', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Table 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "Baseline characteristic & Treat & Control & Obs & Std diff & P-val \\\\\n",
      "\\midrule\n",
      "Male & 0.296 & 0.334 & 1589 & -0.083 & 0.109 \\\\\n",
      "Number of adults & 3.004 & 3.196 & 1510 & -0.099 & 0.067 \\\\\n",
      "Children in school & 2.998 & 3.072 & 1589 & -0.038 & 0.454 \\\\\n",
      "Finished primary school & 0.718 & 0.772 & 1490 & -0.122 & 0.019 \\\\\n",
      "Finished secondary school & 0.253 & 0.270 & 1490 & -0.039 & 0.460 \\\\\n",
      "Total cropland (acres) & 2.441 & 2.398 & 1512 & 0.014 & 0.796 \\\\\n",
      "Number of rooms in household & 3.073 & 3.252 & 1511 & -0.072 & 0.219 \\\\\n",
      "Total school fees & 27239.693 & 29813.631 & 1589 & -0.068 & 0.191 \\\\\n",
      "Average monthly consumption (Ksh) & 14970.862 & 15371.378 & 1437 & -0.032 & 0.550 \\\\\n",
      "Average monthly consumption/capita (log) & 7.975 & 7.963 & 1434 & 0.019 & 0.721 \\\\\n",
      "Total cash savings (Ksh) & 5157.396 & 8021.499 & 1572 & -0.128 & 0.028 \\\\\n",
      "Total cash savings (trim) & 4731.623 & 5389.836 & 1572 & -0.050 & 0.343 \\\\\n",
      "Has bank savings acct & 0.419 & 0.425 & 1589 & -0.012 & 0.815 \\\\\n",
      "Taken bank loan & 0.079 & 0.083 & 1589 & -0.018 & 0.730 \\\\\n",
      "Taken informal loan & 0.244 & 0.249 & 1589 & -0.011 & 0.836 \\\\\n",
      "Liquid wealth (Ksh) & 93878.938 & 97280.922 & 1491 & -0.032 & 0.547 \\\\\n",
      "Off-farm wages (Ksh) & 3916.817 & 3797.480 & 1589 & 0.010 & 0.854 \\\\\n",
      "Business profit (Ksh) & 2302.588 & 1801.685 & 1589 & 0.051 & 0.265 \\\\\n",
      "Avg $\\%\\Delta$ price Sep-Jun & 133.495 & 133.178 & 1504 & 0.004 & 0.939 \\\\\n",
      "Expect $\\%\\Delta$ price Sep12-Jun13 & 124.680 & 117.255 & 1510 & 0.075 & 0.103 \\\\\n",
      "2011 LR harvest (bags) & 9.364 & 9.025 & 1511 & 0.022 & 0.670 \\\\\n",
      "Net revenue 2011 (Ksh) & -3303.691 & -4088.622 & 1428 & 0.017 & 0.716 \\\\\n",
      "Net seller 2011 & 0.324 & 0.303 & 1428 & 0.046 & 0.393 \\\\\n",
      "Autarkic 2011 & 0.068 & 0.060 & 1589 & 0.034 & 0.506 \\\\\n",
      "\\% maize lost 2011 & 0.016 & 0.013 & 1428 & 0.030 & 0.563 \\\\\n",
      "2012 LR harvest (bags) & 11.181 & 11.030 & 1484 & 0.018 & 0.733 \\\\\n",
      "Calculated interest correctly & 0.715 & 0.730 & 1580 & -0.034 & 0.502 \\\\\n",
      "Digit span recall & 4.568 & 4.576 & 1504 & -0.007 & 0.890 \\\\\n",
      "Maize giver & 0.261 & 0.261 & 1589 & -0.001 & 0.985 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create table 1\n",
    "# copy in case we need this later\n",
    "df_tab1 = base_ms1ms2_pool.copy()\n",
    "df_tab1['schoolfees_base'] = df_tab1['schoolfees_base']*1000\n",
    "\n",
    "# var list for table 1\n",
    "vars_list = [\n",
    "    \"male_base\", \"num_adults_base\", \"num_schoolchildren_base\", \"finished_primary_base\",\n",
    "    \"finished_secondary_base\", \"cropland_base\", \"num_rooms_base\", \"schoolfees_base\",\n",
    "    \"totcons_base\", \"logpercapcons_base\", \"total_cash_savings_base\",\n",
    "    \"total_cash_savings_trimmed_base\", \"has_savings_acct_base\", \"taken_bank_loan_base\",\n",
    "    \"taken_informal_loan_base\", \"liquidWealth_base\", \"wagepay_base\",\n",
    "    \"businessprofitmonth_base\", \"price_avg_diff_pct_base\",\n",
    "    \"price_expect_diff_pct_base\", \"harvest2011_base\", \"netrevenue2011_base\",\n",
    "    \"netseller2011_base\", \"autarkic2011_base\", \"maizelostpct2011_base\",\n",
    "    \"harvest2012_base\", \"correct_interest_base\", \"digit_recall_base\",\n",
    "    \"maizegiver_base\"\n",
    "]\n",
    "\n",
    "renaming = {\n",
    "    \"male_base\": \"Male\",\n",
    "    \"num_adults_base\": \"Number of adults\",\n",
    "    \"num_schoolchildren_base\": \"Children in school\",\n",
    "    \"finished_primary_base\": \"Finished primary school\",\n",
    "    \"finished_secondary_base\": \"Finished secondary school\",\n",
    "    \"cropland_base\": \"Total cropland (acres)\",\n",
    "    \"num_rooms_base\": \"Number of rooms in household\",\n",
    "    \"schoolfees_base\": \"Total school fees\",\n",
    "    \"totcons_base\": \"Average monthly consumption (Ksh)\",\n",
    "    \"logpercapcons_base\": \"Average monthly consumption/capita (log)\",\n",
    "    \"total_cash_savings_base\": \"Total cash savings (Ksh)\",\n",
    "    \"total_cash_savings_trimmed_base\": \"Total cash savings (trim)\",\n",
    "    \"has_savings_acct_base\": \"Has bank savings acct\",\n",
    "    \"taken_bank_loan_base\": \"Taken bank loan\",\n",
    "    \"taken_informal_loan_base\": \"Taken informal loan\",\n",
    "    \"liquidWealth_base\": \"Liquid wealth (Ksh)\",\n",
    "    \"wagepay_base\": \"Off-farm wages (Ksh)\",\n",
    "    \"businessprofitmonth_base\": \"Business profit (Ksh)\",\n",
    "    \"price_avg_diff_pct_base\": \"Avg $\\%\\Delta$ price Sep-Jun\",\n",
    "    \"price_expect_diff_pct_base\": \"Expect $\\%\\Delta$ price Sep12-Jun13\",\n",
    "    \"harvest2011_base\": \"2011 LR harvest (bags)\",\n",
    "    \"netrevenue2011_base\": \"Net revenue 2011 (Ksh)\",\n",
    "    \"netseller2011_base\": \"Net seller 2011\",\n",
    "    \"autarkic2011_base\": \"Autarkic 2011\",\n",
    "    \"maizelostpct2011_base\": \"\\% maize lost 2011\",\n",
    "    \"harvest2012_base\": \"2012 LR harvest (bags)\",\n",
    "    \"correct_interest_base\": \"Calculated interest correctly\",\n",
    "    \"digit_recall_base\": \"Digit span recall\",\n",
    "    \"maizegiver_base\": \"Maize giver\"\n",
    "}\n",
    "\n",
    "# function to perform t-tests\n",
    "def t_test_by_group(df, var, group_var='treat12'):\n",
    "    group1 = df[df[group_var] == 0][var].dropna()\n",
    "    group2 = df[df[group_var] == 1][var].dropna()\n",
    "    t_stat, p_val = stats.ttest_ind(group1, group2, equal_var=False)\n",
    "    return group1.mean(), group2.mean(), len(group1) + len(group2), t_stat, p_val\n",
    "\n",
    "# applying t-tests and collecting results\n",
    "results = []\n",
    "for var in vars_list:\n",
    "    control_mean, treat_mean, obs, t_stat, p_val = t_test_by_group(df_tab1, var)\n",
    "    std_diff = (treat_mean - control_mean) / np.sqrt(((len(df_tab1[df_tab1['treat12'] == 0][var]) - 1) * np.std(df_tab1[df_tab1['treat12'] == 0][var], ddof=1) ** 2 + (len(df_tab1[df_tab1['treat12'] == 1][var]) - 1) * np.std(df_tab1[df_tab1['treat12'] == 1][var], ddof=1) ** 2) / (len(df_tab1[df_tab1['treat12'] == 0][var]) + len(df_tab1[df_tab1['treat12'] == 1][var]) - 2))\n",
    "    results.append([var, treat_mean, control_mean, obs, std_diff, p_val])\n",
    "\n",
    "# convert results to a df to use pandas output to latex\n",
    "results_df = pd.DataFrame(results, columns=['Variable', 'Treat Mean', 'Control Mean', 'Observations', 'Std Diff', 'P-value'])\n",
    "results_df['Variable'] = results_df['Variable'].map(renaming)\n",
    "results_df = results_df.rename(columns={\n",
    "    'Variable':'Baseline characteristic', \n",
    "    'Treat Mean':'Treat', \n",
    "    'Control Mean':'Control', \n",
    "    'Observations':'Obs', \n",
    "    'Std Diff':'Std diff', \n",
    "    'P-value':'P-val'})\n",
    "\n",
    "latex_table1 = results_df.to_latex(index=False, float_format=\"%.3f\")\n",
    "print(latex_table1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Table 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the raw data and create columns for treatment and interaction variable\n",
    "ms1ms2_pooled_tab7 = ms1ms2_pooled.copy()\n",
    "ms1ms2_pooled_tab7.sort_index(inplace=True)\n",
    "ms1ms2_pooled_tab7['z'] = pd.NA\n",
    "ms1ms2_pooled_tab7['z_hi'] = pd.NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the first set of regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of treaments\n",
    "treatments = ['treat12', 'treat13', 'treatMS1MS2']\n",
    "\n",
    "# list of dependent variables\n",
    "dependent_vars = ['inventory_trim', 'netrevenue_trim', 'logtotcons_trim']\n",
    "\n",
    "# list of changeing independent variables depending on the treatment\n",
    "independent_vars = {\n",
    "    'treat12': 'Y1round2 + Y1round3',\n",
    "    'treat13': 'Y2round2 + Y2round3',\n",
    "    'treatMS1MS2': 'Y1round2 + Y1round3 + Y2round1 + Y2round2 + Y2round3'\n",
    "    }\n",
    "\n",
    "# empty dictionary to store results\n",
    "results = {}\n",
    "pvals = {var: [] for var in ['z', 'hi', 'z_hi','z+z_hi']}\n",
    "\n",
    "# Simulating the loop to replace variables and run regressions\n",
    "for dv in dependent_vars:\n",
    "    for treat in treatments:\n",
    "        # Stata automatically omits the missing values in the regression – here we have to do it manually so we copy the data and drop variables\n",
    "        df = ms1ms2_pooled_tab7.copy(deep=True)\n",
    "        df = df.dropna(subset=[dv, treat, 'hi', 'subloc','interviewdate'])\n",
    "        # setting treament variable\n",
    "        df['z'] = df[treat] # setting z to the treatment variable\n",
    "        \n",
    "        # setting interaction variable\n",
    "        df['z_hi'] = df[treat]*df['hi'] # setting z_hi to the interaction of the treatment hi saturation\n",
    "        \n",
    "        # setting the formula to run the regression\n",
    "        formula = f'{dv} ~ z + hi + z_hi + interviewdate + {independent_vars[treat]}'\n",
    "\n",
    "        # Run the regression\n",
    "        i = dependent_vars.index(dv)*len(treatments) + treatments.index(treat)\n",
    "        results[f'model_{i}'] = smf.ols(formula, data=df).fit(cov_type='cluster', cov_kwds={'groups': df['subloc']})\n",
    "        # print(results[f'model_{i}'].summary())\n",
    "\n",
    "        # test the hypothesis that z + z_hi = 0\n",
    "        hypothesis = 'z + z_hi = 0'\n",
    "        t_test = results[f'model_{i}'].t_test(hypothesis)\n",
    "\n",
    "        # store p-value round to 3 decimals\n",
    "        pvals['z+z_hi'].append(np.round(t_test.pvalue,3))\n",
    "        pvals['z'].append(np.round(results[f'model_{i}'].pvalues['z'],3))\n",
    "        pvals['hi'].append(np.round(results[f'model_{i}'].pvalues['hi'],3))\n",
    "        pvals['z_hi'].append(np.round(results[f'model_{i}'].pvalues['z_hi'],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running bootstrap regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[9, 15, 16, 18, 19, 24, 25, 30, 38, 168, 174, 192, 200, 279, 281, 289, 296, 297, 301, 302, 356, 357, 383, 393, 525, 531, 534, 535, 540, 542, 600, 612, 646, 648, 653, 667, 668, 672, 673, 745, 751, 756, 757, 766, 770, 774, 795, 797, 810, 812, 826, 830, 843, 845, 847, 848, 949, 1027, 1035, 1037, 1044, 1053, 1077, 1083, 1098, 1108, 1140, 1148, 1149, 1150, 1155, 1157, 1158, 1162, 1163, 1164, 1172, 1174, 1179, 1198, 1205, 1207, 1208, 1223, 1224, 1225, 1232, 1233, 1234, 1245, 1246, 1252, 1256, 1258, 1259, 1261, 1277, 1278, 1285, 1287, 1289, 1290, 1321, 1323, 1334, 1342, 1364, 1369, 1370, 1385, 1388, 1391, 1398, 1405, 1406, 1407, 1408, 1415, 1425, 1436, 1438, 1439, 1454, 1458, 1460, 1461, 1484, 1538, 1554, 1556, 1559, 1562, 1569, 1599, 1601, 1608, 1625, 1647, 1652, 1655, 1656, 1687, 1691, 1692, 1693, 1695, 1696, 1702, 1710, 1711, 1713, 1719, 1720, 1791, 1792, 1795, 1796, 1798, 1887, 1888, 1900, 1906, 1911, 1917, 1922, 1933, 1936, 1963, 1966, 1968, 1976, 2031, 2032, 2038, 2039, 2042, 2047, 2054, 2058, 2059, 2102, 2104, 2111, 2120, 2121, 2244, 2245, 2251, 2256, 2257, 2258, 2259, 2279, 2285, 2288, 2291, 2292, 2299, 2308, 2309, 2314, 2316, 2319, 2324, 2325, 2336, 2344, 2345, 2362, 2370, 2373, 2429, 2435, 2437, 2456, 2457, 2462, 2463, 2470, 2474, 2523, 2532, 2544, 2545, 2554, 2558, 2562, 2563, 2568, 2574, 2581, 2586, 2589, 2590, 2607, 2615, 2619, 2620, 2623, 2633, 2634, 2635, 2642, 2669, 2670, 2671, 2672, 2674, 2686, 2693, 2694, 2712, 2713, 2714, 2720, 2727, 2735, 2736, 2737, 2749, 2750, 2781, 2782, 2789, 2793, 2795, 2801, 2802, 2803, 2809, 2810, 2812, 2823, 2825, 2918, 2919, 2920, 2928, 2934, 2939, 2940, 2942, 2944, 2952, 2959, 2969, 2974, 2975, 3000, 3011, 3015, 3037, 3050, 3051, 3052, 3056, 3058, 3062, 3063, 3084, 3093, 3094, 3107, 3134, 3136, 3140, 3144, 3145, 3153, 3155, 3171, 3192, 3198, 3199, 3204, 3244, 3245, 3253, 3323, 3324, 3325, 3326, 3341, 3351, 3352, 3353, 3359, 3362, 3376, 3381, 3382, 3398, 3400, 3406, 3516, 3520, 3521, 3522, 3523, 3528, 3529, 3541, 3781, 3782, 3783, 3785, 3788, 3789, 3796, 3805, 3806, 3820, 3832, 3849, 3851, 3852, 3856, 3863, 3869, 3875, 3879, 3890, 3903, 3905, 3908, 3909, 3910, 3912, 3916, 3917, 3918, 3919, 3921, 3924, 3926, 3931, 3933, 3938, 3939, 3948, 3953, 3962, 3963, 3965, 3971, 3976, 3978, 3979, 3989, 3991, 3999, 4150, 4158, 4177, 4178, 4179, 4187, 4188, 4191, 4200, 4202, 4327, 4328, 4337, 4338, 4341, 4353, 4359, 4369, 4392, 4394, 4396, 4397, 4398, 4405, 4410, 4412, 4413, 4414, 4424, 4429, 4433, 4439, 4446, 4456, 4462, 4472, 4473, 4477, 4478, 4479, 4483, 4516, 4517, 4541, 4558, 4562, 4563, 4564, 4568, 4576, 4579, 4586, 4588, 4590, 4593, 4595, 4597, 4598, 4599, 4602, 4603, 4604, 4614, 4615, 4616, 4618, 4619, 4620, 4624, 4625, 4626, 4628, 4634, 4635, 4636, 4638, 4643, 4644, 4654, 4656, 4663, 4665, 4671, 4676, 4682, 4691, 4697, 4700, 4703, 4720, 4721, 4723, 4725, 4728, 4732, 4733, 4737, 4741, 4742, 4743, 4760, 4761, 4765, 4769, 4771, 4780, 4783, 4784, 4785, 4792, 4795, 4806, 4811, 4821, 4822, 4827, 4835, 4836, 4837, 4838, 4842, 4846, 4847, 4854, 4855, 4856, 4857, 4861, 5035, 5037, 5041, 5042, 5047, 5048, 5054, 5058, 5066, 5071, 5075, 5083, 5084, 5091, 5100, 5130, 5132, 5225, 5228, 5235, 5239, 5243, 5244, 5257, 5258, 5260, 5261, 5267, 5270, 5284, 5288, 5290, 5295, 5296, 5301, 5305, 5307, 5311, 5318, 5328, 5332, 5335, 5340, 5347, 5348, 5355, 5358, 5359, 5361, 5362, 5365, 5366, 5369, 5375, 5381, 5382, 5386, 5389, 5390, 5393, 5394, 5396, 5397, 5400, 5406, 5413, 5415, 5416, 5422, 5425, 5429, 5430, 5435, 5437, 5438, 5442, 5444, 5446, 5447, 5449, 5454, 5647, 5657, 5661, 5662, 5663, 5665, 5667, 5771, 5772, 5782, 5785, 5786, 5787, 5788, 6011, 6012, 6023, 6033, 6041, 6046, 6047, 6049, 6054, 6055, 6067, 6071, 6084, 6085, 6086, 6090, 6091, 6093, 6095, 6100, 6101, 6102, 6103, 6104, 6105, 6106, 6110, 6111, 6112, 6113, 6116, 6118, 6119, 6122, 6123, 6126, 6143, 6145, 6146, 6147, 6152, 6218, 6226, 6231, 6232, 6235, 6245, 6253, 6254, 6262, 6264, 6273, 6275, 6302, 6303, 6306, 6309, 6313, 6315, 6327, 6333, 6334, 6338, 6355, 6356, 6357, 6361, 6362, 6363, 6365, 6377, 6378, 6394, 6399, 6404, 6405, 6420, 6434, 6438, 6439, 6440, 6446, 6457, 6459, 6504, 6510, 6511, 6512, 6513, 6529, 6535, 6536, 6537, 6542, 6547, 6555, 6558, 6559, 6560, 6566, 6567, 6574, 6576, 6580, 6588, 6612, 6618, 6619, 6621, 6628, 6746, 6747, 6749, 6750, 6756, 6757, 6761, 6764, 6766, 6767, 6768, 6775, 6776, 6778, 6779, 6784, 6789, 6790, 6792, 6796, 6797, 6798, 6799, 6800, 6802, 6810, 6825, 6840, 6841, 6865, 6871, 6900, 6901, 6905, 6906, 6907, 6908, 6916, 6921, 6928, 6951, 6956, 6958, 6959, 6960, 6966, 6970, 7013, 7014, 7019, 7057, 7058, 7060, 7109, 7112, 7124, 7125, 7126] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# perturb residuals and create new dependent variable to follow bootstrap-t procedure with Rademacher weight\u001b[39;00m\n\u001b[1;32m     47\u001b[0m perturbed_residuals \u001b[38;5;241m=\u001b[39m resampled_cluster[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresiduals\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m], size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(resampled_cluster[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresiduals\u001b[39m\u001b[38;5;124m'\u001b[39m]), replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 48\u001b[0m perturbed_y \u001b[38;5;241m=\u001b[39m results[model_key]\u001b[38;5;241m.\u001b[39mpredict(resampled_cluster) \u001b[38;5;241m+\u001b[39m perturbed_residuals\u001b[38;5;241m.\u001b[39mloc[sample\u001b[38;5;241m.\u001b[39mindex]\n\u001b[1;32m     49\u001b[0m perturbed_data \u001b[38;5;241m=\u001b[39m resampled_cluster\u001b[38;5;241m.\u001b[39massign(y\u001b[38;5;241m=\u001b[39mperturbed_y)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# run the regression on the perturbed sample\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1150\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1152\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_axis(maybe_callable, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1382\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1380\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_iterable(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1322\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_listlike_indexer(key, axis)\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1324\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1325\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1520\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1517\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1518\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1520\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, axis_name)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:6115\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6113\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6117\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6119\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:6179\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6178\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6179\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: '[9, 15, 16, 18, 19, 24, 25, 30, 38, 168, 174, 192, 200, 279, 281, 289, 296, 297, 301, 302, 356, 357, 383, 393, 525, 531, 534, 535, 540, 542, 600, 612, 646, 648, 653, 667, 668, 672, 673, 745, 751, 756, 757, 766, 770, 774, 795, 797, 810, 812, 826, 830, 843, 845, 847, 848, 949, 1027, 1035, 1037, 1044, 1053, 1077, 1083, 1098, 1108, 1140, 1148, 1149, 1150, 1155, 1157, 1158, 1162, 1163, 1164, 1172, 1174, 1179, 1198, 1205, 1207, 1208, 1223, 1224, 1225, 1232, 1233, 1234, 1245, 1246, 1252, 1256, 1258, 1259, 1261, 1277, 1278, 1285, 1287, 1289, 1290, 1321, 1323, 1334, 1342, 1364, 1369, 1370, 1385, 1388, 1391, 1398, 1405, 1406, 1407, 1408, 1415, 1425, 1436, 1438, 1439, 1454, 1458, 1460, 1461, 1484, 1538, 1554, 1556, 1559, 1562, 1569, 1599, 1601, 1608, 1625, 1647, 1652, 1655, 1656, 1687, 1691, 1692, 1693, 1695, 1696, 1702, 1710, 1711, 1713, 1719, 1720, 1791, 1792, 1795, 1796, 1798, 1887, 1888, 1900, 1906, 1911, 1917, 1922, 1933, 1936, 1963, 1966, 1968, 1976, 2031, 2032, 2038, 2039, 2042, 2047, 2054, 2058, 2059, 2102, 2104, 2111, 2120, 2121, 2244, 2245, 2251, 2256, 2257, 2258, 2259, 2279, 2285, 2288, 2291, 2292, 2299, 2308, 2309, 2314, 2316, 2319, 2324, 2325, 2336, 2344, 2345, 2362, 2370, 2373, 2429, 2435, 2437, 2456, 2457, 2462, 2463, 2470, 2474, 2523, 2532, 2544, 2545, 2554, 2558, 2562, 2563, 2568, 2574, 2581, 2586, 2589, 2590, 2607, 2615, 2619, 2620, 2623, 2633, 2634, 2635, 2642, 2669, 2670, 2671, 2672, 2674, 2686, 2693, 2694, 2712, 2713, 2714, 2720, 2727, 2735, 2736, 2737, 2749, 2750, 2781, 2782, 2789, 2793, 2795, 2801, 2802, 2803, 2809, 2810, 2812, 2823, 2825, 2918, 2919, 2920, 2928, 2934, 2939, 2940, 2942, 2944, 2952, 2959, 2969, 2974, 2975, 3000, 3011, 3015, 3037, 3050, 3051, 3052, 3056, 3058, 3062, 3063, 3084, 3093, 3094, 3107, 3134, 3136, 3140, 3144, 3145, 3153, 3155, 3171, 3192, 3198, 3199, 3204, 3244, 3245, 3253, 3323, 3324, 3325, 3326, 3341, 3351, 3352, 3353, 3359, 3362, 3376, 3381, 3382, 3398, 3400, 3406, 3516, 3520, 3521, 3522, 3523, 3528, 3529, 3541, 3781, 3782, 3783, 3785, 3788, 3789, 3796, 3805, 3806, 3820, 3832, 3849, 3851, 3852, 3856, 3863, 3869, 3875, 3879, 3890, 3903, 3905, 3908, 3909, 3910, 3912, 3916, 3917, 3918, 3919, 3921, 3924, 3926, 3931, 3933, 3938, 3939, 3948, 3953, 3962, 3963, 3965, 3971, 3976, 3978, 3979, 3989, 3991, 3999, 4150, 4158, 4177, 4178, 4179, 4187, 4188, 4191, 4200, 4202, 4327, 4328, 4337, 4338, 4341, 4353, 4359, 4369, 4392, 4394, 4396, 4397, 4398, 4405, 4410, 4412, 4413, 4414, 4424, 4429, 4433, 4439, 4446, 4456, 4462, 4472, 4473, 4477, 4478, 4479, 4483, 4516, 4517, 4541, 4558, 4562, 4563, 4564, 4568, 4576, 4579, 4586, 4588, 4590, 4593, 4595, 4597, 4598, 4599, 4602, 4603, 4604, 4614, 4615, 4616, 4618, 4619, 4620, 4624, 4625, 4626, 4628, 4634, 4635, 4636, 4638, 4643, 4644, 4654, 4656, 4663, 4665, 4671, 4676, 4682, 4691, 4697, 4700, 4703, 4720, 4721, 4723, 4725, 4728, 4732, 4733, 4737, 4741, 4742, 4743, 4760, 4761, 4765, 4769, 4771, 4780, 4783, 4784, 4785, 4792, 4795, 4806, 4811, 4821, 4822, 4827, 4835, 4836, 4837, 4838, 4842, 4846, 4847, 4854, 4855, 4856, 4857, 4861, 5035, 5037, 5041, 5042, 5047, 5048, 5054, 5058, 5066, 5071, 5075, 5083, 5084, 5091, 5100, 5130, 5132, 5225, 5228, 5235, 5239, 5243, 5244, 5257, 5258, 5260, 5261, 5267, 5270, 5284, 5288, 5290, 5295, 5296, 5301, 5305, 5307, 5311, 5318, 5328, 5332, 5335, 5340, 5347, 5348, 5355, 5358, 5359, 5361, 5362, 5365, 5366, 5369, 5375, 5381, 5382, 5386, 5389, 5390, 5393, 5394, 5396, 5397, 5400, 5406, 5413, 5415, 5416, 5422, 5425, 5429, 5430, 5435, 5437, 5438, 5442, 5444, 5446, 5447, 5449, 5454, 5647, 5657, 5661, 5662, 5663, 5665, 5667, 5771, 5772, 5782, 5785, 5786, 5787, 5788, 6011, 6012, 6023, 6033, 6041, 6046, 6047, 6049, 6054, 6055, 6067, 6071, 6084, 6085, 6086, 6090, 6091, 6093, 6095, 6100, 6101, 6102, 6103, 6104, 6105, 6106, 6110, 6111, 6112, 6113, 6116, 6118, 6119, 6122, 6123, 6126, 6143, 6145, 6146, 6147, 6152, 6218, 6226, 6231, 6232, 6235, 6245, 6253, 6254, 6262, 6264, 6273, 6275, 6302, 6303, 6306, 6309, 6313, 6315, 6327, 6333, 6334, 6338, 6355, 6356, 6357, 6361, 6362, 6363, 6365, 6377, 6378, 6394, 6399, 6404, 6405, 6420, 6434, 6438, 6439, 6440, 6446, 6457, 6459, 6504, 6510, 6511, 6512, 6513, 6529, 6535, 6536, 6537, 6542, 6547, 6555, 6558, 6559, 6560, 6566, 6567, 6574, 6576, 6580, 6588, 6612, 6618, 6619, 6621, 6628, 6746, 6747, 6749, 6750, 6756, 6757, 6761, 6764, 6766, 6767, 6768, 6775, 6776, 6778, 6779, 6784, 6789, 6790, 6792, 6796, 6797, 6798, 6799, 6800, 6802, 6810, 6825, 6840, 6841, 6865, 6871, 6900, 6901, 6905, 6906, 6907, 6908, 6916, 6921, 6928, 6951, 6956, 6958, 6959, 6960, 6966, 6970, 7013, 7014, 7019, 7057, 7058, 7060, 7109, 7112, 7124, 7125, 7126] not in index'"
     ]
    }
   ],
   "source": [
    "# initialize dictionary to store p-values for each bootstrap iteration\n",
    "bootstrap_results = {}\n",
    "\n",
    "n_bootstraps = 2000\n",
    "\n",
    "# define function to resample within clusters\n",
    "def resample_within_group(sample_df, group_key):\n",
    "    grouped = sample_df.groupby('subloc')\n",
    "    resampled = [resample(group, n_samples=len(group)) for _, group in grouped]\n",
    "    resampled_df = pd.concat(resampled)\n",
    "    return resampled_df\n",
    "\n",
    "# loop over each dependent variable and treatment\n",
    "for dv in dependent_vars:\n",
    "    for treat in treatments:\n",
    "        # copy the raw data and drop missing values\n",
    "        df = ms1ms2_pooled_tab7.copy(deep=True)\n",
    "        df.dropna(subset=[dv, treat, 'hi', 'subloc', 'interviewdate'], inplace=True)\n",
    "        df['subloc'] = df['subloc'].astype(int)\n",
    "        \n",
    "        # setting the formula for the regression\n",
    "        formula = f'{dv} ~ z + hi + z_hi + interviewdate + {independent_vars[treat]}'\n",
    "\n",
    "        # Update the model key\n",
    "        i = dependent_vars.index(dv) * len(treatments) + treatments.index(treat)\n",
    "        model_key = f'model_{i}'\n",
    "        df['residuals'] = results[model_key].resid\n",
    "\n",
    "        # Prepare treatment and interaction terms\n",
    "        df['z'] = df[treat]  # Setting z to the treatment variable\n",
    "        df['z_hi'] = df[treat] * df['hi']  # Setting z_hi to the interaction of the treatment and hi saturation\n",
    "\n",
    "        # List unique clusters\n",
    "        unique_clusters = df['subloc'].unique()\n",
    "        bootstrap_coeffs = pd.DataFrame(index=range(n_bootstraps), columns=['z', 'hi', 'z_hi'])\n",
    "\n",
    "        # perform bootstrap iterations\n",
    "        for j in range(n_bootstraps):\n",
    "            # resample clusters with replacement\n",
    "            sampled_clusters = choices(unique_clusters, k=len(unique_clusters))\n",
    "\n",
    "            # create a new sample DataFrame including all rows belonging to the resampled clusters\n",
    "            sample = df[df['subloc'].isin(sampled_clusters)]\n",
    "            resampled_cluster = resample_within_group(sample, 'subloc')\n",
    "\n",
    "            # perturb residuals and create new dependent variable to follow bootstrap-t procedure with Rademacher weight\n",
    "            perturbed_residuals = resampled_cluster['residuals'] * np.random.choice([-1, 1], size=len(resampled_cluster['residuals']), replace=True)\n",
    "            perturbed_y = results[model_key].predict(resampled_cluster) + perturbed_residuals.loc[sample.index]\n",
    "            perturbed_data = resampled_cluster.assign(y=perturbed_y)\n",
    "\n",
    "            # run the regression on the perturbed sample\n",
    "            model = smf.ols(formula, data=perturbed_data).fit()\n",
    "\n",
    "            # store the coefficients\n",
    "            bootstrap_coeffs.loc[j] = model.params['z'], model.params['hi'], model.params['z_hi']\n",
    "\n",
    "            # append the results to the bootstrap_results dictionary\n",
    "            bootstrap_results[model_key] = bootstrap_coeffs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty dictionary to store bootstrap p-values\n",
    "bootstrap_pvals = {'z': [], 'hi': [], 'z_hi': []}\n",
    "\n",
    "# calculate bootstrap p-values for each coefficient\n",
    "for dv in dependent_vars:\n",
    "    for treat in treatments:\n",
    "        model_key = f'model_{dependent_vars.index(dv) * len(treatments) + treatments.index(treat)}'\n",
    "        original_coefficients = results[model_key].params['z'], results[model_key].params['hi'], results[model_key].params['z_hi']\n",
    "        extreme_values = (np.abs(bootstrap_results[model_key]) >= np.abs(original_coefficients)).sum(axis=0)\n",
    "        p_values = extreme_values / n_bootstraps\n",
    "\n",
    "        for key in bootstrap_pvals.keys():\n",
    "            bootstrap_pvals[key].append(p_values[key])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'z': [0.503, 0.4625, 0.4765, 0.5155, 0.4925, 0.526, 0.7615, 0.495, 0.6535],\n",
       " 'hi': [0.718, 0.8965, 0.938, 0.5335, 0.7435, 0.705, 0.9535, 0.5225, 0.515],\n",
       " 'z_hi': [0.5365, 0.77, 0.522, 0.5155, 0.525, 0.4865, 0.7725, 0.498, 0.521]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap_pvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output code to LaTeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[!htbp] \\centering\n",
      "\\begin{tabular}{@{\\extracolsep{5pt}}lccccccccc}\n",
      "\\\\[-1.8ex]\\hline\n",
      "\\hline \\\\[-1.8ex]\n",
      "\\\\[-1.8ex] & \\multicolumn{3}{c}{Inventory} & \\multicolumn{3}{c}{Net Revenues} & \\multicolumn{3}{c}{Consumption}  \\\\\n",
      "\\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) & (6) & (7) & (8) & (9) \n",
      " \\\\ & Y1 & Y2 & Pooled & Y1 & Y2 & Pooled & Y1 & Y2 & Pooled \\\\\n",
      "\\hline \\\\[-1.8ex]\n",
      " Treat & 0.759$^{***}$ & 0.546$^{***}$ & 0.740$^{***}$ & 1059.602$^{**}$ & 1193.768$^{*}$ & 1101.389$^{**}$ & 0.012$^{}$ & -0.051$^{}$ & -0.011$^{}$ \\\\\n",
      "& (0.189) & (0.185) & (0.155) & (437.732) & (685.048) & (430.091) & (0.040) & (0.040) & (0.023) \\\\\n",
      " High & 0.124$^{}$ & -0.028$^{}$ & 0.017$^{}$ & 533.903$^{}$ & -152.603$^{}$ & 164.936$^{}$ & -0.003$^{}$ & -0.084$^{}$ & -0.047$^{}$ \\\\\n",
      "& (0.355) & (0.219) & (0.241) & (551.179) & (558.948) & (479.685) & (0.051) & (0.053) & (0.043) \\\\\n",
      " Treat*High & -0.333$^{}$ & -0.065$^{}$ & -0.291$^{}$ & -1114.628$^{**}$ & -555.215$^{}$ & -816.770$^{}$ & -0.013$^{}$ & 0.174$^{***}$ & 0.067$^{*}$ \\\\\n",
      "& (0.229) & (0.255) & (0.192) & (535.594) & (804.864) & (520.036) & (0.052) & (0.055) & (0.037) \\\\\n",
      " P-value T + TH = 0 & 0.002 & 0.006 & 0.002 & 0.861 & 0.125 & 0.396 & 0.969 & 0.001 & 0.063 \\\\\n",
      " P-value Treat & 0.0 & 0.003 & 0.0 & 0.015 & 0.081 & 0.01 & 0.764 & 0.209 & 0.621 \\\\\n",
      " P-value Treat Bootstrap & 0.503 & 0.4625 & 0.4765 & 0.5155 & 0.4925 & 0.526 & 0.7615 & 0.495 & 0.6535 \\\\\n",
      " P-value High & 0.726 & 0.899 & 0.944 & 0.333 & 0.785 & 0.731 & 0.961 & 0.115 & 0.279 \\\\\n",
      " P-value High Bootstrap & 0.718 & 0.8965 & 0.938 & 0.5335 & 0.7435 & 0.705 & 0.9535 & 0.5225 & 0.515 \\\\\n",
      " P-value Treat*High & 0.146 & 0.799 & 0.13 & 0.037 & 0.49 & 0.116 & 0.798 & 0.002 & 0.072 \\\\\n",
      " P-value Treat*High Bootstrap & 0.5365 & 0.77 & 0.522 & 0.5155 & 0.525 & 0.4865 & 0.7725 & 0.498 & 0.521 \\\\\n",
      "\\hline \\\\[-1.8ex]\n",
      " Observations & 3836 & 2944 & 6780 & 3795 & 2935 & 6730 & 3792 & 2944 & 6736 \\\\\n",
      " $R^2$ & 0.346 & 0.184 & 0.293 & 0.009 & 0.043 & 0.091 & 0.002 & 0.017 & 0.025 \\\\\n",
      " % Adjusted $R^2$ & 0.345 & 0.182 & 0.292 & 0.008 & 0.041 & 0.090 & 0.000 & 0.015 & 0.024 \\\\\n",
      " % Residual Std. Error & 3.015 & 2.793 & 2.947 & 6188.647 & 6410.741 & 6286.767 & 0.621 & 0.647 & 0.633 \\\\\n",
      " % F Statistic & 369.556$^{***}$ & 93.029$^{***}$ & 364.779$^{***}$ & 2.004$^{*}$ & 19.627$^{***}$ & 119.335$^{***}$ & 0.616$^{}$ & 4.496$^{***}$ & 16.477$^{***}$ \\\\\n",
      "\\hline\n",
      "\\hline \\\\[-1.8ex]\n",
      "% \\textit{Note:} & \\multicolumn{9}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\\\\n",
      "\\end{tabular}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "# use stargazer to create a table\n",
    "result_list = list(results.values())\n",
    "stargazer = Stargazer(result_list)\n",
    "\n",
    "# configure Stargazer object for output\n",
    "stargazer.custom_columns(['Inventory', 'Net Revenues', 'Consumption'], [3, 3, 3])\n",
    "stargazer.rename_covariates({'z': 'Treat', 'hi': 'High', 'z_hi': 'Treat*High'})\n",
    "stargazer.show_degrees_of_freedom(False)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.covariate_order(['z', 'hi', 'z_hi'])\n",
    "# add p-values as a rows \n",
    "stargazer.add_line('P-value T + TH = 0', pvals['z+z_hi'])\n",
    "stargazer.add_line('P-value Treat', pvals['z'])\n",
    "stargazer.add_line('P-value Treat Bootstrap', bootstrap_pvals['z'])\n",
    "stargazer.add_line('P-value High', pvals['hi'])\n",
    "stargazer.add_line('P-value High Bootstrap', bootstrap_pvals['hi'])\n",
    "stargazer.add_line('P-value Treat*High', pvals['z_hi'])\n",
    "stargazer.add_line('P-value Treat*High Bootstrap', bootstrap_pvals['z_hi'])\n",
    "\n",
    "\n",
    "latex_table7 = stargazer.render_latex()\n",
    "\n",
    "# edit the latex table to add row for telling if Y1 Y2 or Pooled after \\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) & (6) & (7) & (8) & (9) \\\\\n",
    "latex_table7 = latex_table7.replace(\"\\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) & (6) & (7) & (8) & (9) \\\\\",\n",
    "                                \"\\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) & (6) & (7) & (8) & (9) \\n \\\\\\ & Y1 & Y2 & Pooled & Y1 & Y2 & Pooled & Y1 & Y2 & Pooled \\\\\")\n",
    "latex_table7 = latex_table7.replace(\"Adjusted $R^2$\", \"% Adjusted $R^2$\")\n",
    "latex_table7 = latex_table7.replace(\"Residual Std. Error\", \"% Residual Std. Error\")\n",
    "latex_table7 = latex_table7.replace(\"F Statistic\", \"% F Statistic\")\n",
    "latex_table7 = latex_table7.replace(\"\\\\textit{\",\"% \\\\textit{\")\n",
    "\n",
    "print(latex_table7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
