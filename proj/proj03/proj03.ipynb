{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import of packages\n",
    "from proj03 import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.weightstats import ttest_ind\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from stargazer.stargazer import Stargazer\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "# autoreload for easier debugging\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "baseline = pd.read_stata('data/baseline.dta')\n",
    "bok_inflation = pd.read_stata('data/BOK_inflation.dta')\n",
    "cleanpricedata_y1y2 = pd.read_stata('data/cleanPriceData_Y1Y2.dta')\n",
    "intensity_obs_short = pd.read_stata('data/intensity_obs_short.dta')\n",
    "lrfu_select_dataset = pd.read_stata('data/LRFU_select_dataset.dta')\n",
    "ms1ms2_pooled = pd.read_stata('data/MS1MS2_pooled.dta')\n",
    "repayment_datay1 = pd.read_stata('data/repayment_dataY1.dta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Table 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by cleaning the ms1ms2_pooled and baseline data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2993\n",
      "1019\n"
     ]
    }
   ],
   "source": [
    "# clean ms1ms2_pooled (drop if MS !=2, keep columns oafid and treatMS1MS2, group by oafid and take mean and rename) \n",
    "ms1ms2_pooled_clean = ms1ms2_pooled[ms1ms2_pooled['MS']==2]\n",
    "ms1ms2_pooled_clean = ms1ms2_pooled_clean[['oafid', 'treatMS1MS2']]\n",
    "print(ms1ms2_pooled_clean.shape[0])\n",
    "ms1ms2_pooled_clean = ms1ms2_pooled_clean.groupby('oafid', as_index=False).mean()\n",
    "ms1ms2_pooled_clean.rename(columns={'treatMS1MS2': 'treat13'}, inplace=True)\n",
    "print(ms1ms2_pooled_clean.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the baseline data we note that some of the columns have already been renamed with the suffix `_base` however and thus need to account for this. We however, assume that the data have not been altered in any other way compared to what the do in the `do` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yw/jsw5n53s1cb1s2q6tt0msrm00000gn/T/ipykernel_96399/232695012.py:20: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  baseline_clean.loc[baseline_clean['treatment2012'] == '', 'treat12'] = np.nan\n"
     ]
    }
   ],
   "source": [
    "# clean baseline data (the stata code indicates that the variables columns 'businessprofitmonth' and 'delta' should be kept, however they have already been renamed to 'businessprofitmonth_base' and 'delta_base')\n",
    "base_cols = ['oafid', 'logtotcons_base', 'male', 'num_adults', 'num_schoolchildren', 'finished_primary',\n",
    "                   'finished_secondary', 'cropland', 'num_rooms', 'schoolfees', 'totcons_base', 'logpercapcons_base',\n",
    "                   'total_cash_savings_base', 'total_cash_savings_trimmed', 'has_savings_acct', 'taken_bank_loan',\n",
    "                   'taken_informal_loan', 'liquidWealth', 'wagepay', 'businessprofitmonth_base', 'price_avg_diff_pct',\n",
    "                   'price_expect_diff_pct', 'harvest2011', 'netrevenue2011', 'netseller2011', 'autarkic2011',\n",
    "                   'maizelostpct2011', 'harvest2012', 'correct_interest', 'digit_recall', 'maizegiver', 'delta_base', 'treatment']\n",
    "baseline_clean = baseline[base_cols].copy()\n",
    "\n",
    "\"\"\" WE SURE ABOUT THIS? \"\"\"\n",
    "# we assume that the variable 'delta_base' does not already have the correct value thus the following is not commented out\n",
    "baseline['delta_base'] = 1 - baseline['delta_base']\n",
    "\n",
    "# rename columns\n",
    "baseline_clean.columns = [col + '_base' if not col.endswith('_base') and col != 'oafid' and col != 'treatment' else col for col in baseline_clean.columns]\n",
    "baseline_clean.rename(columns={'treatment': 'treatment2012'}, inplace=True)\n",
    "\n",
    "# generate treat12 as bool for treatment and control in 2012\n",
    "baseline_clean['treat12'] = baseline_clean['treatment2012'].apply(lambda x: x in ['T1', 'T2'])\n",
    "baseline_clean.loc[baseline_clean['treatment2012'] == '', 'treat12'] = np.nan\n",
    "\n",
    "base_ms1ms2_pool = pd.merge(baseline_clean, ms1ms2_pooled_clean, on='oafid', how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can merge the two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge baseline_clean and ms1ms2_pooled_clean on oafid\n",
    "# base_ms1ms2_pool = pd.merge(baseline_clean, ms1ms2_pooled_clean, on='oafid', how='left')\n",
    "\n",
    "#  # The rest of the code is not what is done in Stata but it I believe it is not used for table 1 (and I believe it is not used for only 'in_sample_Y2' is only used for Table F.1 – the join should just be a left join)\n",
    "# base_ms1ms2_pool = pd.merge(baseline_clean, ms1ms2_pooled_clean, on='oafid', how='outer', indicator=True)\n",
    "\n",
    "# # Drop rows that are only in the using dataset (equivalent to 'merge_base == 2' in Stata)\n",
    "# base_ms1ms2_pool = base_ms1ms2_pool[base_ms1ms2_pool['_merge'] != 'right_only']\n",
    "\n",
    "# # Generate bool in_sample_Y2\n",
    "# base_ms1ms2_pool['in_sample_Y2'] = (base_ms1ms2_pool['_merge'] == 'both')\n",
    "\n",
    "# # WHY DO THIS – RIGHT_ONLY IS REMOVED SO NO DATA???\n",
    "# # Generate bool newin13\n",
    "# base_ms1ms2_pool['newin13'] = (base_ms1ms2_pool['_merge'] == 'right_only')\n",
    "\n",
    "# # Generate bool attrit13\n",
    "# base_ms1ms2_pool['attrit13'] = (base_ms1ms2_pool['_merge'] == 'left_only')\n",
    "\n",
    "# base_ms1ms2_pool.drop(columns=['_merge'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Table 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "Variable & Treat Mean & Control Mean & Observations & Std Diff & P-value \\\\\n",
      "\\midrule\n",
      "male_base & 0.296 & 0.334 & 1589 & -0.083 & 0.109 \\\\\n",
      "num_adults_base & 3.004 & 3.196 & 1510 & -0.099 & 0.067 \\\\\n",
      "num_schoolchildren_base & 2.998 & 3.072 & 1589 & -0.038 & 0.454 \\\\\n",
      "finished_primary_base & 0.718 & 0.772 & 1490 & -0.122 & 0.019 \\\\\n",
      "finished_secondary_base & 0.253 & 0.270 & 1490 & -0.039 & 0.460 \\\\\n",
      "cropland_base & 2.441 & 2.398 & 1512 & 0.014 & 0.796 \\\\\n",
      "num_rooms_base & 3.073 & 3.252 & 1511 & -0.072 & 0.219 \\\\\n",
      "schoolfees_base & 27239.693 & 29813.631 & 1589 & -0.068 & 0.191 \\\\\n",
      "totcons_base & 14970.862 & 15371.378 & 1437 & -0.032 & 0.550 \\\\\n",
      "logpercapcons_base & 7.975 & 7.963 & 1434 & 0.019 & 0.721 \\\\\n",
      "total_cash_savings_base & 5157.396 & 8021.499 & 1572 & -0.128 & 0.028 \\\\\n",
      "total_cash_savings_trimmed_base & 4731.623 & 5389.836 & 1572 & -0.050 & 0.343 \\\\\n",
      "has_savings_acct_base & 0.419 & 0.425 & 1589 & -0.012 & 0.815 \\\\\n",
      "taken_bank_loan_base & 0.079 & 0.083 & 1589 & -0.018 & 0.730 \\\\\n",
      "taken_informal_loan_base & 0.244 & 0.249 & 1589 & -0.011 & 0.836 \\\\\n",
      "liquidWealth_base & 93878.938 & 97280.922 & 1491 & -0.032 & 0.547 \\\\\n",
      "wagepay_base & 3916.817 & 3797.480 & 1589 & 0.010 & 0.854 \\\\\n",
      "businessprofitmonth_base & 2302.588 & 1801.685 & 1589 & 0.051 & 0.265 \\\\\n",
      "price_avg_diff_pct_base & 133.495 & 133.178 & 1504 & 0.004 & 0.939 \\\\\n",
      "price_expect_diff_pct_base & 124.680 & 117.255 & 1510 & 0.075 & 0.103 \\\\\n",
      "harvest2011_base & 9.364 & 9.025 & 1511 & 0.022 & 0.670 \\\\\n",
      "netrevenue2011_base & -3303.691 & -4088.622 & 1428 & 0.017 & 0.716 \\\\\n",
      "netseller2011_base & 0.324 & 0.303 & 1428 & 0.046 & 0.393 \\\\\n",
      "autarkic2011_base & 0.068 & 0.060 & 1589 & 0.034 & 0.506 \\\\\n",
      "maizelostpct2011_base & 0.016 & 0.013 & 1428 & 0.030 & 0.563 \\\\\n",
      "harvest2012_base & 11.181 & 11.030 & 1484 & 0.018 & 0.733 \\\\\n",
      "correct_interest_base & 0.715 & 0.730 & 1580 & -0.034 & 0.502 \\\\\n",
      "digit_recall_base & 4.568 & 4.576 & 1504 & -0.007 & 0.890 \\\\\n",
      "maizegiver_base & 0.261 & 0.261 & 1589 & -0.001 & 0.985 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_tab1 = base_ms1ms2_pool.copy()\n",
    "df_tab1['schoolfees_base'] = df_tab1['schoolfees_base']*1000\n",
    "\n",
    "# var list for table 1\n",
    "vars_list = [\n",
    "    \"male_base\", \"num_adults_base\", \"num_schoolchildren_base\", \"finished_primary_base\",\n",
    "    \"finished_secondary_base\", \"cropland_base\", \"num_rooms_base\", \"schoolfees_base\",\n",
    "    \"totcons_base\", \"logpercapcons_base\", \"total_cash_savings_base\",\n",
    "    \"total_cash_savings_trimmed_base\", \"has_savings_acct_base\", \"taken_bank_loan_base\",\n",
    "    \"taken_informal_loan_base\", \"liquidWealth_base\", \"wagepay_base\",\n",
    "    \"businessprofitmonth_base\", \"price_avg_diff_pct_base\",\n",
    "    \"price_expect_diff_pct_base\", \"harvest2011_base\", \"netrevenue2011_base\",\n",
    "    \"netseller2011_base\", \"autarkic2011_base\", \"maizelostpct2011_base\",\n",
    "    \"harvest2012_base\", \"correct_interest_base\", \"digit_recall_base\",\n",
    "    \"maizegiver_base\"\n",
    "]\n",
    "\n",
    "\n",
    "# AGAIN THE FOLLOWING IS DONE IN STATA BUT IS NOT NECESSARY (AT ALL!) SHOULD NOT BE NEEDED AS RIGHT_ONLY IS REMOVED\n",
    "# Filter the DataFrame\n",
    "# df_tab1 = base_ms1ms2_pool[base_ms1ms2_pool['newin13'] != True]\n",
    "\n",
    "# Function to perform t-tests\n",
    "def t_test_by_group(df, var, group_var='treat12'):\n",
    "    group1 = df[df[group_var] == 0][var].dropna()\n",
    "    group2 = df[df[group_var] == 1][var].dropna()\n",
    "    t_stat, p_val = stats.ttest_ind(group1, group2, equal_var=False)\n",
    "    return group1.mean(), group2.mean(), len(group1) + len(group2), t_stat, p_val\n",
    "\n",
    "# Applying t-tests and collecting results\n",
    "results = []\n",
    "for var in vars_list:\n",
    "    control_mean, treat_mean, obs, t_stat, p_val = t_test_by_group(df_tab1, var)\n",
    "    std_diff = (treat_mean - control_mean) / np.sqrt(((len(df_tab1[df_tab1['treat12'] == 0][var]) - 1) * np.std(df_tab1[df_tab1['treat12'] == 0][var], ddof=1) ** 2 + (len(df_tab1[df_tab1['treat12'] == 1][var]) - 1) * np.std(df_tab1[df_tab1['treat12'] == 1][var], ddof=1) ** 2) / (len(df_tab1[df_tab1['treat12'] == 0][var]) + len(df_tab1[df_tab1['treat12'] == 1][var]) - 2))\n",
    "    results.append([var, treat_mean, control_mean, obs, std_diff, p_val])\n",
    "\n",
    "# Convert results to DataFrame for easier LaTeX conversion\n",
    "results_df = pd.DataFrame(results, columns=['Variable', 'Treat Mean', 'Control Mean', 'Observations', 'Std Diff', 'P-value'])\n",
    "\n",
    "\n",
    "latex_table1 = results_df.to_latex(index=False, float_format=\"%.3f\")\n",
    "print(latex_table1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating table 2, 3 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms1ms2_pooled_tab2 = ms1ms2_pooled.copy()\n",
    "\n",
    "ms1ms2_pooled_tab2['strata_group'] = np.where(\n",
    "    ms1ms2_pooled_tab2['MS'] == 2,\n",
    "    ms1ms2_pooled_tab2['groupstrata'] + ms1ms2_pooled_tab2['strata_group'].max(),\n",
    "    ms1ms2_pooled_tab2['strata_group']\n",
    ")\n",
    "\n",
    "ms1ms2_pooled_tab2['oafid'] = np.where(ms1ms2_pooled_tab2['MS'] == 2, \n",
    "                                       ms1ms2_pooled_tab2['fr_id'], \n",
    "                                       ms1ms2_pooled_tab2['oafid']\n",
    "                                       )\n",
    "\n",
    "ms1ms2_pooled_tab2 = ms1ms2_pooled_tab2.drop(columns=['purchaseval_trim', 'salesval_trim'])\n",
    "\n",
    "for column in ['purchaseval', 'salesval', 'purchasequant', 'salesquant']:\n",
    "    ms1ms2_pooled_tab2 = trim_quantiles(ms1ms2_pooled_tab2, column)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Table 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the raw data and create columns for treatment and interaction variable\n",
    "ms1ms2_pooled_tab7 = ms1ms2_pooled.copy()\n",
    "ms1ms2_pooled_tab7['z'] = pd.NA\n",
    "ms1ms2_pooled_tab7['z_hi'] = pd.NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the first set of regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of treaments\n",
    "treatments = ['treat12', 'treat13', 'treatMS1MS2']\n",
    "\n",
    "# list of dependent variables\n",
    "dependent_vars = ['inventory_trim', 'netrevenue_trim', 'logtotcons_trim']\n",
    "\n",
    "# list of changeing independent variables depending on the treatment\n",
    "independent_vars = {\n",
    "    'treat12': 'Y1round2 + Y1round3',\n",
    "    'treat13': 'Y2round2 + Y2round3',\n",
    "    'treatMS1MS2': 'Y1round2 + Y1round3 + Y2round1 + Y2round2 + Y2round3'\n",
    "    }\n",
    "\n",
    "# empty dictionary to store results\n",
    "results = {}\n",
    "pvals = {var: [] for var in ['z', 'hi', 'z_hi','z+z_hi']}\n",
    "\n",
    "# Simulating the loop to replace variables and run regressions\n",
    "for dv in dependent_vars:\n",
    "    for treat in treatments:\n",
    "        # Stata automatically omits the missing values in the regression – here we have to do it manually so we copy the data and drop variables\n",
    "        df = ms1ms2_pooled_tab7.copy(deep=True)\n",
    "        df = df.dropna(subset=[dv, treat, 'hi', 'subloc','interviewdate'])\n",
    "        \n",
    "        # setting treament variable\n",
    "        df['z'] = df[treat] # setting z to the treatment variable\n",
    "        \n",
    "        # setting interaction variable\n",
    "        df['z_hi'] = df[treat]*df['hi'] # setting z_hi to the interaction of the treatment hi saturation\n",
    "        \n",
    "        # setting the formula to run the regression\n",
    "        formula = f'{dv} ~ z + hi + z_hi + interviewdate + {independent_vars[treat]}'\n",
    "\n",
    "        # Run the regression\n",
    "        i = dependent_vars.index(dv)*len(treatments) + treatments.index(treat)\n",
    "        results[f'model_{i}'] = smf.ols(formula, data=df).fit(cov_type='cluster', cov_kwds={'groups': df['subloc']})\n",
    "        # print(results[f'model_{i}'].summary())\n",
    "\n",
    "        # test the hypothesis that z + z_hi = 0\n",
    "        hypothesis = 'z + z_hi = 0'\n",
    "        t_test = results[f'model_{i}'].t_test(hypothesis)\n",
    "\n",
    "        # store p-value round to 3 decimals\n",
    "        pvals['z+z_hi'].append(np.round(t_test.pvalue,3))\n",
    "        pvals['z'].append(np.round(results[f'model_{i}'].pvalues['z'],3))\n",
    "        pvals['hi'].append(np.round(results[f'model_{i}'].pvalues['hi'],3))\n",
    "        pvals['z_hi'].append(np.round(results[f'model_{i}'].pvalues['z_hi'],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running bootstrap regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating the loop to replace variables and run regressions\n",
    "n_bootstraps = 1000\n",
    "\n",
    "bootstrap_pvals = {key: {var: [] for var in ['z', 'hi', 'z_hi']} for key in results.keys()}\n",
    "\n",
    "for dv in dependent_vars:\n",
    "    for treat in treatments:\n",
    "        # copying the raw data and dropping missing values\n",
    "        df = ms1ms2_pooled_tab7.copy(deep=True)\n",
    "        df = df.dropna(subset=[dv, treat, 'hi', 'subloc','interviewdate'])\n",
    "\n",
    "        # setting the formula for the regression\n",
    "        formula = f'{dv} ~ z + hi + z_hi + interviewdate + {independent_vars[treat]}'\n",
    "\n",
    "        # update the model key\n",
    "        i = dependent_vars.index(dv)*len(treatments) + treatments.index(treat)\n",
    "        model_key = f'model_{i}'\n",
    "\n",
    "        df['z'] = df[treat] # setting z to the treatment variable\n",
    "        df['z_hi'] = df[treat]*df['hi'] # setting z_hi to the interaction of the treatment hi saturation\n",
    "\n",
    "        for j in range(n_bootstraps):\n",
    "            # resample the data\n",
    "            sample = resample(df, n_samples=len(df))\n",
    "\n",
    "            # Run the regression\n",
    "            model = smf.ols(formula, data=sample).fit(cov_type='cluster', cov_kwds={'groups': sample['subloc']})\n",
    "\n",
    "            # add to array\n",
    "            bootstrap_pvals[model_key]['z'].append(model.pvalues['z'])\n",
    "            bootstrap_pvals[model_key]['hi'].append(model.pvalues['hi'])\n",
    "            bootstrap_pvals[model_key]['z_hi'].append(model.pvalues['z_hi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap = {'z': [], 'hi': [], 'z_hi': []}\n",
    "\n",
    "# Combine the averaging and new structure population in one loop\n",
    "for model_data in bootstrap_pvals.values():\n",
    "    for var in ['z', 'hi', 'z_hi']:\n",
    "        mean_pval = np.mean(model_data[var])\n",
    "        model_data[var] = mean_pval  # This line modifies the original dictionary, if preserving it is needed, handle appropriately\n",
    "        bootstrap[var].append(mean_pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output code to LaTeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[!htbp] \\centering\n",
      "  \\caption{Inventory, net revenues, and HH consumption effects}\n",
      "\\begin{tabular}{@{\\extracolsep{5pt}}lccccccccc}\n",
      "\\\\[-1.8ex]\\hline\n",
      "\\hline \\\\[-1.8ex]\n",
      "\\\\[-1.8ex] & \\multicolumn{3}{c}{Inventory} & \\multicolumn{3}{c}{Net Revenues} & \\multicolumn{3}{c}{Consumption}  \\\\\n",
      "\\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) & (6) & (7) & (8) & (9) \n",
      " \\\\ & Y1 & Y2 & Pooled & Y1 & Y2 & Pooled & Y1 & Y2 & Pooled \\\\\n",
      "\\hline \\\\[-1.8ex]\n",
      " Treat & 0.759$^{***}$ & 0.546$^{***}$ & 0.740$^{***}$ & 1059.602$^{**}$ & 1193.768$^{*}$ & 1101.389$^{**}$ & 0.012$^{}$ & -0.051$^{}$ & -0.011$^{}$ \\\\\n",
      "& (0.189) & (0.185) & (0.155) & (437.732) & (685.048) & (430.091) & (0.040) & (0.040) & (0.023) \\\\\n",
      " High & 0.124$^{}$ & -0.028$^{}$ & 0.017$^{}$ & 533.903$^{}$ & -152.603$^{}$ & 164.936$^{}$ & -0.003$^{}$ & -0.084$^{}$ & -0.047$^{}$ \\\\\n",
      "& (0.355) & (0.219) & (0.241) & (551.179) & (558.948) & (479.685) & (0.051) & (0.053) & (0.043) \\\\\n",
      " Treat*High & -0.333$^{}$ & -0.065$^{}$ & -0.291$^{}$ & -1114.628$^{**}$ & -555.215$^{}$ & -816.770$^{}$ & -0.013$^{}$ & 0.174$^{***}$ & 0.067$^{*}$ \\\\\n",
      "& (0.229) & (0.255) & (0.192) & (535.594) & (804.864) & (520.036) & (0.052) & (0.055) & (0.037) \\\\\n",
      " P-value T + TH = 0 & 0.002 & 0.006 & 0.002 & 0.861 & 0.125 & 0.396 & 0.969 & 0.001 & 0.063 \\\\\n",
      " P-value Treat & 0.0 & 0.003 & 0.0 & 0.015 & 0.081 & 0.01 & 0.764 & 0.209 & 0.621 \\\\\n",
      " P-value Treat Bootstrap & 0.022962067423342808 & 0.05660570679471233 & 0.0034387563225824077 & 0.09531645203418047 & 0.1968822694265969 & 0.06250778320211921 & 0.5516069049924025 & 0.42355024749164505 & 0.5623272696997963 \\\\\n",
      " P-value High & 0.726 & 0.899 & 0.944 & 0.333 & 0.785 & 0.731 & 0.961 & 0.115 & 0.279 \\\\\n",
      " P-value High Bootstrap & 0.666902513995113 & 0.6882320687957031 & 0.7210563826829719 & 0.4302511449931974 & 0.6551323698634807 & 0.6172333409987791 & 0.6562897907266201 & 0.22276736262527916 & 0.37009041571253376 \\\\\n",
      " P-value Treat*High & 0.146 & 0.799 & 0.13 & 0.037 & 0.49 & 0.116 & 0.798 & 0.002 & 0.072 \\\\\n",
      " P-value Treat*High Bootstrap & 0.340285292798592 & 0.5943896205833539 & 0.3041367265917343 & 0.1512840316326296 & 0.5388851753965668 & 0.23983466934053116 & 0.6005038579409563 & 0.05176069388595858 & 0.2167412530402731 \\\\\n",
      "\\hline \\\\[-1.8ex]\n",
      " Observations & 3836 & 2944 & 6780 & 3795 & 2935 & 6730 & 3792 & 2944 & 6736 \\\\\n",
      " $R^2$ & 0.346 & 0.184 & 0.293 & 0.009 & 0.043 & 0.091 & 0.002 & 0.017 & 0.025 \\\\\n",
      " % Adjusted $R^2$ & 0.345 & 0.182 & 0.292 & 0.008 & 0.041 & 0.090 & 0.000 & 0.015 & 0.024 \\\\\n",
      " % Residual Std. Error & 3.015 & 2.793 & 2.947 & 6188.647 & 6410.741 & 6286.767 & 0.621 & 0.647 & 0.633 \\\\\n",
      " % F Statistic & 369.556$^{***}$ & 93.029$^{***}$ & 364.779$^{***}$ & 2.004$^{*}$ & 19.627$^{***}$ & 119.335$^{***}$ & 0.616$^{}$ & 4.496$^{***}$ & 16.477$^{***}$ \\\\\n",
      "\\hline\n",
      "\\hline \\\\[-1.8ex]\n",
      "\\textit{Note:} & \\multicolumn{9}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\\\\n",
      "\\end{tabular}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "# use stargazer to create a table\n",
    "result_list = list(results.values())\n",
    "stargazer = Stargazer(result_list)\n",
    "\n",
    "# configure Stargazer object for output\n",
    "stargazer.title(\"Inventory, net revenues, and HH consumption effects\")\n",
    "stargazer.custom_columns(['Inventory', 'Net Revenues', 'Consumption'], [3, 3, 3])\n",
    "stargazer.rename_covariates({'z': 'Treat', 'hi': 'High', 'z_hi': 'Treat*High'})\n",
    "stargazer.show_degrees_of_freedom(False)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.covariate_order(['z', 'hi', 'z_hi'])\n",
    "# add p-values as a rows \n",
    "stargazer.add_line('P-value T + TH = 0', pvals['z+z_hi'])\n",
    "stargazer.add_line('P-value Treat', pvals['z'])\n",
    "stargazer.add_line('P-value Treat Bootstrap', bootstrap['z'])\n",
    "stargazer.add_line('P-value High', pvals['hi'])\n",
    "stargazer.add_line('P-value High Bootstrap', bootstrap['hi'])\n",
    "stargazer.add_line('P-value Treat*High', pvals['z_hi'])\n",
    "stargazer.add_line('P-value Treat*High Bootstrap', bootstrap['z_hi'])\n",
    "\n",
    "\n",
    "latex_table7 = stargazer.render_latex()\n",
    "\n",
    "# edit the latex table to add row for telling if Y1 Y2 or Pooled after \\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) & (6) & (7) & (8) & (9) \\\\\n",
    "latex_table7 = latex_table7.replace(\"\\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) & (6) & (7) & (8) & (9) \\\\\",\n",
    "                                \"\\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) & (6) & (7) & (8) & (9) \\n \\\\\\ & Y1 & Y2 & Pooled & Y1 & Y2 & Pooled & Y1 & Y2 & Pooled \\\\\")\n",
    "latex_table7 = latex_table7.replace(\"Adjusted $R^2$\", \"% Adjusted $R^2$\")\n",
    "latex_table7 = latex_table7.replace(\"Residual Std. Error\", \"% Residual Std. Error\")\n",
    "latex_table7 = latex_table7.replace(\"F Statistic\", \"% F Statistic\")\n",
    "\n",
    "print(latex_table7)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
