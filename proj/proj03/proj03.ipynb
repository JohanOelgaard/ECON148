{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0oyPnEQIxpq"
      },
      "source": [
        "# Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nE0qteMlufaZ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<contextlib.ExitStack at 0x140e7ab50>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import statsmodels.formula.api as smf\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "from stargazer.stargazer import Stargazer\n",
        "\n",
        "\n",
        "from proj03 import cgmwildboot\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# turn off interactive plotting for the notebook\n",
        "%matplotlib inline\n",
        "plt.ioff()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgzJ03RhI4Go"
      },
      "source": [
        "# Import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtyS2XfKKJKd",
        "outputId": "87946a65-6548-4a57-ff18-e9086fb3063e"
      },
      "outputs": [],
      "source": [
        "# import data\n",
        "baseline = pd.read_stata('data/baseline.dta')\n",
        "cleanpricedata_y1y2 = pd.read_stata('data/cleanPriceData_Y1Y2.dta')\n",
        "ms1ms2_pooled = pd.read_stata('data/MS1MS2_pooled.dta')\n",
        "\n",
        "# this data is not needed for our analysis\n",
        "# bok_inflation = pd.read_stata('data/BOK_inflation.dta')\n",
        "# intensity_obs_short = pd.read_stata('data/intensity_obs_short.dta')\n",
        "# lrfu_select_dataset = pd.read_stata('data/LRFU_select_dataset.dta')\n",
        "# repayment_datay1 = pd.read_stata('data/repayment_dataY1.dta')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ufa1dpjdPM4N"
      },
      "source": [
        "# Recreating the tables from the paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLR-EsZmPhnZ"
      },
      "source": [
        "## Table 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDod8jI8PmcV"
      },
      "source": [
        "We start by cleaning the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27C6MkYfPjWZ",
        "outputId": "be660654-5f0b-4bc5-e9a6-9cd83ea3455b"
      },
      "outputs": [],
      "source": [
        "# clean ms1ms2_pooled (drop if MS !=2, keep columns oafid and treatMS1MS2, group by oafid and take mean and rename)\n",
        "ms1ms2_pooled_tab1 = ms1ms2_pooled[ms1ms2_pooled['MS']==2]\n",
        "ms1ms2_pooled_tab1 = ms1ms2_pooled_tab1[['oafid', 'treatMS1MS2']]\n",
        "ms1ms2_pooled_tab1 = ms1ms2_pooled_tab1.groupby('oafid', as_index=False).mean()\n",
        "ms1ms2_pooled_tab1.rename(columns={'treatMS1MS2': 'treat13'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NDAHBMLAPxQM"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/yw/jsw5n53s1cb1s2q6tt0msrm00000gn/T/ipykernel_95370/2284489521.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
            "  baseline_clean.loc[baseline_clean['treatment2012'] == '', 'treat12'] = np.nan\n"
          ]
        }
      ],
      "source": [
        "# clean baseline data (the stata code indicates that the variables columns 'businessprofitmonth' and 'delta' should be kept, however they have already been renamed to 'businessprofitmonth_base' and 'delta_base')\n",
        "base_cols = ['oafid', 'logtotcons_base', 'male', 'num_adults', 'num_schoolchildren', 'finished_primary',\n",
        "                   'finished_secondary', 'cropland', 'num_rooms', 'schoolfees', 'totcons_base', 'logpercapcons_base',\n",
        "                   'total_cash_savings_base', 'total_cash_savings_trimmed', 'has_savings_acct', 'taken_bank_loan',\n",
        "                   'taken_informal_loan', 'liquidWealth', 'wagepay', 'businessprofitmonth_base', 'price_avg_diff_pct',\n",
        "                   'price_expect_diff_pct', 'harvest2011', 'netrevenue2011', 'netseller2011', 'autarkic2011',\n",
        "                   'maizelostpct2011', 'harvest2012', 'correct_interest', 'digit_recall', 'maizegiver', 'delta_base', 'treatment']\n",
        "baseline_clean = baseline[base_cols].copy()\n",
        "\n",
        "# rename columns\n",
        "baseline_clean.columns = [col + '_base' if not col.endswith('_base') and col != 'oafid' and col != 'treatment' else col for col in baseline_clean.columns]\n",
        "baseline_clean.rename(columns={'treatment': 'treatment2012'}, inplace=True)\n",
        "\n",
        "# generate treat12 as bool for treatment and control in 2012\n",
        "baseline_clean['treat12'] = baseline_clean['treatment2012'].apply(lambda x: x in ['T1', 'T2'])\n",
        "baseline_clean.loc[baseline_clean['treatment2012'] == '', 'treat12'] = np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NLEtoCbkPzAN"
      },
      "outputs": [],
      "source": [
        "# merge baseline_clean and ms1ms2_pooled_clean on oafid\n",
        "base_ms1ms2_pool = pd.merge(baseline_clean, ms1ms2_pooled_tab1, on='oafid', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        },
        "id": "69_xFPsuQTmG",
        "outputId": "279489ba-6e05-4d96-caca-5214d7b4ab53"
      },
      "outputs": [],
      "source": [
        "# create table 1\n",
        "# copy in case we need this later\n",
        "df_tab1 = base_ms1ms2_pool.copy()\n",
        "df_tab1['schoolfees_base'] = df_tab1['schoolfees_base']*1000\n",
        "\n",
        "# var list for table 1\n",
        "vars_list = [\n",
        "    \"male_base\", \"num_adults_base\", \"num_schoolchildren_base\", \"finished_primary_base\",\n",
        "    \"finished_secondary_base\", \"cropland_base\", \"num_rooms_base\", \"schoolfees_base\",\n",
        "    \"totcons_base\", \"logpercapcons_base\", \"total_cash_savings_base\",\n",
        "    \"total_cash_savings_trimmed_base\", \"has_savings_acct_base\", \"taken_bank_loan_base\",\n",
        "    \"taken_informal_loan_base\", \"liquidWealth_base\", \"wagepay_base\",\n",
        "    \"businessprofitmonth_base\", \"price_avg_diff_pct_base\",\n",
        "    \"price_expect_diff_pct_base\", \"harvest2011_base\", \"netrevenue2011_base\",\n",
        "    \"netseller2011_base\", \"autarkic2011_base\", \"maizelostpct2011_base\",\n",
        "    \"harvest2012_base\", \"correct_interest_base\", \"digit_recall_base\",\n",
        "    \"maizegiver_base\"\n",
        "]\n",
        "\n",
        "renaming = {\n",
        "    \"male_base\": \"Male\",\n",
        "    \"num_adults_base\": \"Number of adults\",\n",
        "    \"num_schoolchildren_base\": \"Children in school\",\n",
        "    \"finished_primary_base\": \"Finished primary school\",\n",
        "    \"finished_secondary_base\": \"Finished secondary school\",\n",
        "    \"cropland_base\": \"Total cropland (acres)\",\n",
        "    \"num_rooms_base\": \"Number of rooms in household\",\n",
        "    \"schoolfees_base\": \"Total school fees\",\n",
        "    \"totcons_base\": \"Average monthly consumption (Ksh)\",\n",
        "    \"logpercapcons_base\": \"Average monthly consumption/capita (log)\",\n",
        "    \"total_cash_savings_base\": \"Total cash savings (Ksh)\",\n",
        "    \"total_cash_savings_trimmed_base\": \"Total cash savings (trim)\",\n",
        "    \"has_savings_acct_base\": \"Has bank savings acct\",\n",
        "    \"taken_bank_loan_base\": \"Taken bank loan\",\n",
        "    \"taken_informal_loan_base\": \"Taken informal loan\",\n",
        "    \"liquidWealth_base\": \"Liquid wealth (Ksh)\",\n",
        "    \"wagepay_base\": \"Off-farm wages (Ksh)\",\n",
        "    \"businessprofitmonth_base\": \"Business profit (Ksh)\",\n",
        "    \"price_avg_diff_pct_base\": \"Avg $\\%\\Delta$ price Sep-Jun\",\n",
        "    \"price_expect_diff_pct_base\": \"Expect $\\%\\Delta$ price Sep12-Jun13\",\n",
        "    \"harvest2011_base\": \"2011 LR harvest (bags)\",\n",
        "    \"netrevenue2011_base\": \"Net revenue 2011 (Ksh)\",\n",
        "    \"netseller2011_base\": \"Net seller 2011\",\n",
        "    \"autarkic2011_base\": \"Autarkic 2011\",\n",
        "    \"maizelostpct2011_base\": \"\\% maize lost 2011\",\n",
        "    \"harvest2012_base\": \"2012 LR harvest (bags)\",\n",
        "    \"correct_interest_base\": \"Calculated interest correctly\",\n",
        "    \"digit_recall_base\": \"Digit span recall\",\n",
        "    \"maizegiver_base\": \"Maize giver\"\n",
        "}\n",
        "\n",
        "# function to perform t-tests\n",
        "def t_test_by_group(df, var, group_var='treat12'):\n",
        "    group1 = df[df[group_var] == 0][var].dropna()\n",
        "    group2 = df[df[group_var] == 1][var].dropna()\n",
        "    t_stat, p_val = stats.ttest_ind(group1, group2, equal_var=True)\n",
        "    return group1.mean(), group2.mean(), len(group1) + len(group2), t_stat, p_val\n",
        "\n",
        "# applying t-tests and collecting results\n",
        "results = []\n",
        "for var in vars_list:\n",
        "    control_mean, treat_mean, obs, t_stat, p_val = t_test_by_group(df_tab1, var)\n",
        "    std_diff = (treat_mean - control_mean) / np.std(df_tab1[df_tab1['treat12'] == 0][var])\n",
        "    results.append([var, treat_mean, control_mean, obs, std_diff, p_val])\n",
        "\n",
        "# convert results to a df to use pandas output to latex\n",
        "results_df = pd.DataFrame(results, columns=['Variable', 'Treat Mean', 'Control Mean', 'Observations', 'Std Diff', 'P-value'])\n",
        "results_df['Variable'] = results_df['Variable'].map(renaming)\n",
        "results_df = results_df.rename(columns={\n",
        "    'Variable':'Baseline characteristic', \n",
        "    'Treat Mean':'Treat', \n",
        "    'Control Mean':'Control', \n",
        "    'Observations':'Obs', \n",
        "    'Std Diff':'Std diff', \n",
        "    'P-value':'P-val'})\n",
        "\n",
        "latex_table1 = results_df.to_latex(index=False, float_format=\"%.3f\")\n",
        "latex_table1 = latex_table1.replace('\\\\toprule', '\\\\\\[-1.8ex]\\hline \\n \\hline \\\\\\[-1.8ex]')\n",
        "latex_table1 = latex_table1.replace('\\\\bottomrule', '\\\\\\[-1.8ex]\\hline \\n \\hline \\\\\\[-1.8ex]')\n",
        "\n",
        "with open('tables/table1.tex','w') as file:\n",
        "    file.write(latex_table1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running the model for tables 2 through 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "treatments = ['treat12', 'treat13', 'treatMS1MS2']\n",
        "dependent_vars = ['inventory_trim', 'netrevenue_trim','logtotcons_trim']\n",
        "\n",
        "mean_df = pd.DataFrame()\n",
        "std_df = pd.DataFrame()\n",
        "pval_df = pd.DataFrame()\n",
        "pval_rd_df = pd.DataFrame()\n",
        "\n",
        "results = {'netsales': {'overall': None, 'by_round':None}}\n",
        "\n",
        "for dv in dependent_vars:\n",
        "    for treat in treatments:\n",
        "        # create df for each treatment\n",
        "        if treat == 'treatMS1MS2':\n",
        "            df1 = ms1ms2_pooled.loc[:, [dv,'treat12', 'Y1round1', 'Y1round2', 'Y1round3', 'treatMS1MS2', 'interviewdate', 'groupnum', 'strata_group']].copy(deep=True).dropna()\n",
        "            df2 = ms1ms2_pooled.loc[:, [dv,'treat13', 'Y2round1', 'Y2round2', 'Y2round3', 'treatMS1MS2', 'interviewdate', 'groupnum', 'strata_group']].copy(deep=True).dropna()\n",
        "            df1['inter_R1'] = df1['Y1round1'] * df1[f'treat12']\n",
        "            df1['inter_R2'] = df1['Y1round2'] * df1[f'treat12']\n",
        "            df1['inter_R3'] = df1['Y1round3'] * df1[f'treat12']\n",
        "            df2['inter_R1'] = df2['Y2round1'] * df2[f'treat13']\n",
        "            df2['inter_R2'] = df2['Y2round2'] * df2[f'treat13']\n",
        "            df2['inter_R3'] = df2['Y2round3'] * df2[f'treat13']\n",
        "            df = pd.concat([df1, df2], ignore_index=True).fillna(0)\n",
        "\n",
        "            # model specification by round\n",
        "            formula_by_round = f'{dv} ~ inter_R1 + inter_R2 + inter_R3 + interviewdate + C(Y1round1) + C(Y1round2) + C(Y1round3) + C(Y2round1) + C(Y2round2) + C(Y2round3) + C(strata_group)'\n",
        "        else:\n",
        "            if treat == 'treat12':\n",
        "                year = 1\n",
        "            else:\n",
        "                year = 2\n",
        "            df = ms1ms2_pooled.loc[:, [dv,treat, f'Y{year}round1', f'Y{year}round2', f'Y{year}round3', 'treatMS1MS2', 'interviewdate', 'groupnum', 'strata_group']].copy(deep=True).dropna()\n",
        "            df['inter_R1'] = df[f'Y{year}round1'] * df[f'{treat}']\n",
        "            df['inter_R2'] = df[f'Y{year}round2'] * df[f'{treat}']\n",
        "            df['inter_R3'] = df[f'Y{year}round3'] * df[f'{treat}']\n",
        "\n",
        "\n",
        "            # model specification by round\n",
        "            formula_by_round = f'{dv} ~ inter_R1 + inter_R2 + inter_R3 + interviewdate + C(Y{year}round1) + C(Y{year}round2) + C(Y{year}round3) + C(strata_group)'\n",
        "        \n",
        "        df['z'] = df[treat]\n",
        "\n",
        "        # specify overall model\n",
        "        formula_overall = f'{dv} ~ z + interviewdate + C(strata_group)'\n",
        "\n",
        "        # fit models\n",
        "        model_overall = smf.ols(formula_overall, data=df).fit(cov_type='cluster', cov_kwds={'groups': df['groupnum']})\n",
        "        model_by_round = smf.ols(formula_by_round, data=df).fit(cov_type='cluster', cov_kwds={'groups': df['groupnum']})\n",
        "\n",
        "        # store models in dictionary\n",
        "        results[f'{treat}_{dv}'] = {f'overall': model_overall, f'by_round': model_by_round}\n",
        "        # extract necessary statistics\n",
        "        mean_df.loc[dv, treat] = df[dv].mean()\n",
        "        std_df.loc[dv, treat] = df[dv].std()\n",
        "        pval_df.loc[dv, treat] = 2 * (1 - stats.t.cdf(np.abs(model_overall.params['z']/model_overall.bse['z']),df=df['groupnum'].nunique()-1))\n",
        "\n",
        "        for var in ['inter_R1', 'inter_R2', 'inter_R3']:\n",
        "            pval_rd_df.loc[f'{dv}_{var}', f'{treat}_rd'] = 2 * (1 - stats.t.cdf(np.abs(model_by_round.params[var]/model_by_round.bse[var]),df=df['groupnum'].nunique()-1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adding table 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Clean the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "ms1ms2_pooled_tab5 = ms1ms2_pooled.copy(deep=True)\n",
        "max_strata_group = ms1ms2_pooled_tab5['strata_group'].max()\n",
        "ms1ms2_pooled_tab5.loc[ms1ms2_pooled_tab5['MS'] == 2, 'strata_group'] = ms1ms2_pooled_tab5['groupstrata'] + max_strata_group\n",
        "\n",
        "ms1ms2_pooled_tab5.loc[ms1ms2_pooled_tab5['MS'] == 2, 'oafid'] = ms1ms2_pooled_tab5['fr_id']\n",
        "\n",
        "ms1ms2_pooled_tab5['purchasequant2'] = ms1ms2_pooled_tab5['purchasequant']\n",
        "ms1ms2_pooled_tab5.loc[(ms1ms2_pooled_tab5['purchaseval']==0)&(ms1ms2_pooled_tab5['purchasequant'].isna()),'purchasequant2'] = 0\n",
        "ms1ms2_pooled_tab5['netsales'] = ms1ms2_pooled_tab5['salesquant'] - ms1ms2_pooled_tab5['purchasequant2']\n",
        "\n",
        "ms1ms2_pooled_tab5.drop(columns=['netsales_trim','purchaseval_trim','salesval_trim'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# trim outliers\n",
        "for x in ['purchaseval', 'salesval', 'purchasequant', 'salesquant']:\n",
        "    quantile = np.quantile(ms1ms2_pooled_tab5[ms1ms2_pooled_tab5[x].notna()][x],[0.99],method='closest_observation')\n",
        "    ms1ms2_pooled_tab5[f'{x}_trim'] = ms1ms2_pooled_tab5[x]\n",
        "    ms1ms2_pooled_tab5.loc[ms1ms2_pooled_tab5[f'{x}_trim'] > quantile[0],f'{x}_trim'] = np.nan\n",
        "\n",
        "quantile = np.quantile(ms1ms2_pooled_tab5[ms1ms2_pooled_tab5['netsales'].notna()]['netsales'],[0.005, 0.995],method='closest_observation')\n",
        "ms1ms2_pooled_tab5['netsales_trim'] = ms1ms2_pooled_tab5['netsales']\n",
        "ms1ms2_pooled_tab5.loc[(ms1ms2_pooled_tab5['netsales_trim'] <= quantile[0]) | (ms1ms2_pooled_tab5['netsales_trim'] > quantile[1]) , 'netsales_trim'] = np.nan\n",
        "\n",
        "# create id\n",
        "ms1ms2_pooled_tab5['id'] = ms1ms2_pooled_tab5['oafid'].fillna(ms1ms2_pooled_tab5['fr_id'])\n",
        "\n",
        "# create effective prices\n",
        "trim_vars = ['salesquant_trim', 'purchasequant_trim', 'salesval_trim', 'purchaseval_trim']\n",
        "for var in trim_vars:\n",
        "    ms1ms2_pooled_tab5[f'tot_{var}'] = ms1ms2_pooled_tab5.groupby(['id', 'MS'])[var].transform('sum')\n",
        "\n",
        "for x in ['purchase', 'sales']:\n",
        "    ms1ms2_pooled_tab5[f'effective_{x}_price'] = ms1ms2_pooled_tab5[f'tot_{x}val_trim'] / ms1ms2_pooled_tab5[f'tot_{x}quant_trim']\n",
        "    ms1ms2_pooled_tab5.loc[ms1ms2_pooled_tab5[f'tot_{x}quant_trim']== 0,f'effective_{x}_price'] = np.nan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Net sales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/yw/jsw5n53s1cb1s2q6tt0msrm00000gn/T/ipykernel_95370/2051522561.py:21: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.4208270957978571' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
            "  mean_df.loc[dv, treat] = df.loc[df['treatMS1MS2'] == 0, dv].mean().astype(float)\n"
          ]
        }
      ],
      "source": [
        "# define variable\n",
        "dv = 'netsales_trim'\n",
        "independent_vars = ['z', 'treatMS1MS2_1 + treatMS1MS2_2 + treatMS1MS2_3']\n",
        "\n",
        "for i, var in enumerate(independent_vars):\n",
        "    df = ms1ms2_pooled_tab5.copy(deep=True)\n",
        "    df['z'] = df['treatMS1MS2']\n",
        "    if var == 'z':\n",
        "        df.dropna(subset=[dv,'z','interviewdate','Y1round2','Y1round3','Y2round1','Y2round2','Y2round3','strata_group','groupnum'], inplace=True)\n",
        "    else:\n",
        "        df.dropna(subset=[dv,'treatMS1MS2_1','treatMS1MS2_2','treatMS1MS2_3','interviewdate','Y1round2','Y1round3','Y2round1','Y2round2','Y2round3','strata_group','groupnum'], inplace=True)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    formula = f'{dv} ~ {var} + interviewdate + Y1round2 + Y1round3 + Y2round1 + Y2round2 + Y2round3 + C(strata_group)'\n",
        "    model = smf.ols(formula, df).fit(cov_type='cluster', cov_kwds={'groups': df['groupnum']})\n",
        "    if i == 0:\n",
        "        results['netsales']['overall'] = model\n",
        "    else:\n",
        "        results['netsales']['by_round'] = model\n",
        "    \n",
        "    mean_df.loc[dv, treat] = df.loc[df['treatMS1MS2'] == 0, dv].mean().astype(float)\n",
        "    std_df.loc[dv, treat] = df.loc[df['treatMS1MS2'] == 0, dv].std()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Effective Price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/yw/jsw5n53s1cb1s2q6tt0msrm00000gn/T/ipykernel_95370/1060375524.py:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2774.7609839746265' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
            "  mean_df.loc[dv, treat] = df.loc[df['z'] == 0, f'effective_{dv}_price'].mean()\n",
            "/var/folders/yw/jsw5n53s1cb1s2q6tt0msrm00000gn/T/ipykernel_95370/1060375524.py:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2858.969741383102' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
            "  mean_df.loc[dv, treat] = df.loc[df['z'] == 0, f'effective_{dv}_price'].mean()\n"
          ]
        }
      ],
      "source": [
        "for dv in ['purchase', 'sales']:\n",
        "    for i, treat in enumerate(['treat12', 'treat13', 'treatMS1MS2']):\n",
        "        df = ms1ms2_pooled_tab5.copy(deep=True)\n",
        "        df['z'] = df[treat]\n",
        "        df = df.drop_duplicates(subset=['id', 'MS'], keep='first')\n",
        "        df.dropna(subset=[f'effective_{dv}_price','z','groupnum'], inplace=True)\n",
        "        if treat == 'treatMS1MS2':\n",
        "            formula = f'effective_{dv}_price ~ z + C(strata_group)'\n",
        "        else:\n",
        "            df = df[df['MS'] == i+1]\n",
        "            formula = f'effective_{dv}_price ~ z + C(strata_group)'\n",
        "        model = smf.ols(formula, data=df).fit(cov_type='cluster', cov_kwds={'groups': df['groupnum']})\n",
        "        results[f'{treat}_{dv}'] = {'overall':model}\n",
        "        \n",
        "        mean_df.loc[dv, treat] = df.loc[df['z'] == 0, f'effective_{dv}_price'].mean()\n",
        "        std_df.loc[dv, treat] = df.loc[df['z'] == 0, f'effective_{dv}_price'].std()\n",
        "        pval_df.loc[dv, treat] = 2 * (1 - stats.t.cdf(np.abs(model.params['z']/model.bse['z']),df=df['groupnum'].nunique()-1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calculating FWER and pvals and getting dataframes ready for output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "for treat in ['treat12', 'treat13', 'treatMS1MS2']:        \n",
        "    fwer_pvals = multipletests(pval_df[treat], alpha=0.05, method='fdr_bh')[1]\n",
        "    for i, dv in enumerate(pval_df.index):\n",
        "        pval_df.loc[dv, f'{treat}_fwer'] = fwer_pvals[i]\n",
        "    fwer_pvals_rd = multipletests(pval_rd_df[f'{treat}_rd'], alpha=0.05, method='fdr_bh')[1]\n",
        "    for i, indx in enumerate(pval_rd_df.index):\n",
        "        pval_rd_df.loc[indx, f'{treat}_fwer_rd'] = fwer_pvals_rd[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# combine the p-values and split into two dfs\n",
        "pvals = pd.concat([pval_df, pval_rd_df], axis=0)\n",
        "pvals = pvals.map(lambda x: '<0.001' if x < 0.0005 else np.round(x,3))\n",
        "pval_fwer = pvals[['treat12_fwer','treat12_fwer_rd','treat13_fwer','treat13_fwer_rd','treatMS1MS2_fwer','treatMS1MS2_fwer_rd']]\n",
        "pval = pvals[['treat12','treat12_rd','treat13','treat13_rd','treatMS1MS2','treatMS1MS2_rd']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# adjust the mean and std dfs to be ready for output\n",
        "for treat in mean_df.columns:\n",
        "    mean_df[f'{treat}_rd'] = mean_df[treat]\n",
        "    std_df[f'{treat}_rd'] = std_df[treat]\n",
        "\n",
        "# sort the dfs\n",
        "mean_df = mean_df[['treat12','treat12_rd','treat13','treat13_rd','treatMS1MS2','treatMS1MS2_rd']].map(lambda x: np.round(x,3))\n",
        "std_df = std_df[['treat12','treat12_rd','treat13','treat13_rd','treatMS1MS2','treatMS1MS2_rd']].map(lambda x: np.round(x,3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Output table to LaTeX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tables 2,3 and 4 to LaTeX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 37, but rank is 36\n",
            "  warnings.warn('covariance of constraints does not have full '\n",
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 37, but rank is 36\n",
            "  warnings.warn('covariance of constraints does not have full '\n",
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 63, but rank is 62\n",
            "  warnings.warn('covariance of constraints does not have full '\n",
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 71, but rank is 68\n",
            "  warnings.warn('covariance of constraints does not have full '\n",
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 37, but rank is 36\n",
            "  warnings.warn('covariance of constraints does not have full '\n",
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 37, but rank is 36\n",
            "  warnings.warn('covariance of constraints does not have full '\n",
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 63, but rank is 62\n",
            "  warnings.warn('covariance of constraints does not have full '\n",
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 71, but rank is 68\n",
            "  warnings.warn('covariance of constraints does not have full '\n",
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 37, but rank is 36\n",
            "  warnings.warn('covariance of constraints does not have full '\n",
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 37, but rank is 36\n",
            "  warnings.warn('covariance of constraints does not have full '\n",
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 63, but rank is 62\n",
            "  warnings.warn('covariance of constraints does not have full '\n",
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 71, but rank is 68\n",
            "  warnings.warn('covariance of constraints does not have full '\n"
          ]
        }
      ],
      "source": [
        "latex_tables = []\n",
        "for i, dv in enumerate(['inventory_trim', 'netrevenue_trim', 'logtotcons_trim']):\n",
        "    tables = []\n",
        "    for treat in ['treat12', 'treat13', 'treatMS1MS2']:\n",
        "        overall = results[f'{treat}_{dv}']['overall']\n",
        "        by_rd = results[f'{treat}_{dv}']['by_round']\n",
        "        tables.append(overall)\n",
        "        tables.append(by_rd)\n",
        "    stargazer = Stargazer(tables)\n",
        "    stargazer.custom_columns(['Y1', 'Y2','Pooled'], [2,2,2])\n",
        "    stargazer.significant_digits(3)\n",
        "    stargazer.rename_covariates({'z': 'Treat', 'inter_R1': 'Treat - R1', 'inter_R2': 'Treat - R2', 'inter_R3': 'Treat - R3'})\n",
        "    stargazer.covariate_order(['z', 'inter_R1', 'inter_R2', 'inter_R3'])\n",
        "    stargazer.show_adj_r2 = False\n",
        "    stargazer.show_f_statistic = False\n",
        "    stargazer.show_residual_std_err = False\n",
        "    stargazer.show_notes = False\n",
        "    \n",
        "    # adding custom rows with mean, sd, and p-values\n",
        "    stargazer.add_line('Mean DV', mean_df.loc[dv].tolist(),location='fb')\n",
        "    stargazer.add_line('SD DV', std_df.loc[dv].tolist(),location='fb')\n",
        "    stargazer.add_line('P-Val Treat', pval.loc[dv].tolist(),location='fb')\n",
        "    stargazer.add_line('P-Val Treat FWER', pval_fwer.loc[dv].tolist(),location='fb')\n",
        "    stargazer.add_line('P-Val Treat - R1', pval.loc[f'{dv}_inter_R1'].tolist(),location='fb')\n",
        "    stargazer.add_line('P-Val Treat - R1 FWER', pval_fwer.loc[f'{dv}_inter_R1'].tolist(),location='fb')\n",
        "    stargazer.add_line('P-Val Treat - R2', pval.loc[f'{dv}_inter_R2'].tolist(),location='fb')\n",
        "    stargazer.add_line('P-Val Treat - R2 FWER', pval_fwer.loc[f'{dv}_inter_R2'].tolist(),location='fb')\n",
        "    stargazer.add_line('P-Val Treat - R3', pval.loc[f'{dv}_inter_R3'].tolist(),location='fb')\n",
        "    stargazer.add_line('P-Val Treat - R3 FWER', pval_fwer.loc[f'{dv}_inter_R3'].tolist(),location='fb')\n",
        "    \n",
        "    latex_table = stargazer.render_latex()\n",
        "\n",
        "    # general formatting\n",
        "    latex_table = latex_table.replace(\"\\\\textit{Note\",\"% \\\\textit{Note\")\n",
        "    latex_table = latex_table.replace(\"nan\",\"\")\n",
        "    latex_table = latex_table.replace(\"\\\\begin{table}[!htbp] \\\\centering\", \"\")\n",
        "    latex_table = latex_table.replace(\"\\\\end{table}\", \"\")\n",
        "\n",
        "    # renaming variables\n",
        "    latex_table = latex_table.replace(\"\\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) & (6) \\\\\",\n",
        "                                \"\\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) & (6) \\n \\\\\\ & Overall & By rd & Overall & By rd & Overall & By rd \\\\\")\n",
        "    latex_table = latex_table.replace(\"netrevenue_trim\",\"Net Revenue Trim\")\n",
        "    latex_table = latex_table.replace(\"inventory_trim\",\"Inventory Trim\")\n",
        "    latex_table = latex_table.replace(\"logtotcons_trim\",\"Log Total HH Consumption Trim\")\n",
        "\n",
        "    latex_tables.append(latex_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Saving Tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# write to file\n",
        "with open('tables/table2.tex','w') as file:\n",
        "    file.write(latex_tables[0])\n",
        "\n",
        "with open('tables/table3.tex','w') as file:\n",
        "    file.write(latex_tables[1])\n",
        "\n",
        "with open('tables/table4.tex','w') as file:\n",
        "    file.write(latex_tables[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Table 5 to LaTeX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 68, but rank is 66\n",
            "  warnings.warn('covariance of constraints does not have full '\n",
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 70, but rank is 68\n",
            "  warnings.warn('covariance of constraints does not have full '\n",
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 62, but rank is 61\n",
            "  warnings.warn('covariance of constraints does not have full '\n",
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 62, but rank is 61\n",
            "  warnings.warn('covariance of constraints does not have full '\n"
          ]
        }
      ],
      "source": [
        "tables = [results['netsales']['overall'], results['netsales']['by_round'],results['treatMS1MS2_purchase']['overall'], results['treatMS1MS2_sales']['overall']]\n",
        "\n",
        "stargazer = Stargazer(tables)\n",
        "stargazer.custom_columns(['Net Sales', 'Effective Price'], [2, 2])\n",
        "stargazer.rename_covariates({'z': 'Treat','treatMS1MS2_1':'Treat - R1', 'treatMS1MS2_2':'Treat - R2', 'treatMS1MS2_3':'Treat - R3'})\n",
        "stargazer.significant_digits(3)\n",
        "stargazer.covariate_order(['z', 'treatMS1MS2_1', 'treatMS1MS2_2', 'treatMS1MS2_3'])\n",
        "stargazer.show_adj_r2 = False\n",
        "stargazer.show_f_statistic = False\n",
        "stargazer.show_residual_std_err = False\n",
        "stargazer.show_notes = False\n",
        "\n",
        "# adding p-values\n",
        "stargazer.add_line('Mean DV', mean_df.loc[['netsales_trim','netsales_trim','purchase','sales'],'treatMS1MS2'].tolist(),location='fb')\n",
        "stargazer.add_line('SD DV', std_df.loc[['netsales_trim','netsales_trim','purchase','sales'],'treatMS1MS2'].tolist(),location='fb')\n",
        "stargazer.add_line('P-Val Treat', ['','']+pval.loc[['purchase','sales'],'treatMS1MS2'].tolist(),location='fb')\n",
        "stargazer.add_line('P-Val Treat FWER', ['','']+pval_fwer.loc[['purchase','sales'],'treatMS1MS2_fwer'].tolist(),location='fb')\n",
        "\n",
        "latex_table5 = stargazer.render_latex()\n",
        "\n",
        "# general formatting\n",
        "latex_table5 = latex_table5.replace(\"nan\",\"\")\n",
        "latex_table5 = latex_table5.replace(\"\\\\begin{table}[!htbp] \\\\centering\", \"\")\n",
        "latex_table5 = latex_table5.replace(\"\\\\end{table}\", \"\")\n",
        "\n",
        "# renaming variables\n",
        "latex_table5 = latex_table5.replace(\"\\\\[-1.8ex] & (1) & (2) & (3) & (4) \\\\\",\n",
        "                                \"\\\\[-1.8ex] & (1) & (2) & (3) & (4) \\n \\\\\\ & Overall & By rd & Purchase & Sales \\\\\")\n",
        "\n",
        "\n",
        "with open('tables/table5.tex','w') as file:\n",
        "    file.write(latex_table5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA65rIF8J8Bc"
      },
      "source": [
        "## Table 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clean data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "bxbZzoqaJ373"
      },
      "outputs": [],
      "source": [
        "cleanpricedata_y1y2_tab6 = cleanpricedata_y1y2.copy(deep=True)\n",
        "cleanpricedata_y1y2_tab6 = cleanpricedata_y1y2_tab6[['salesPrice_trim','hi_1km_wt','hi_3km_wt','hi_5km_wt','monthnum','subloc_1km_wt_grp','subloc_3km_wt_grp','subloc_5km_wt_grp', 'in_sample','MS','lean']]\n",
        "cleanpricedata_y1y2_tab6['hi'] = pd.NA\n",
        "cleanpricedata_y1y2_tab6['interact'] = pd.NA\n",
        "cleanpricedata_y1y2_tab6['interact_lean'] = pd.NA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run first set of regressions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "l2T6HDAFA_Ji"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "for dist in ['1km_wt', '3km_wt', '5km_wt']:\n",
        "    df = cleanpricedata_y1y2_tab6.copy(deep=True)\n",
        "    df.dropna(subset=[f'hi_{dist}','salesPrice_trim','monthnum'], inplace=True)\n",
        "    mean_price = df[(df['monthnum'] == 0) & (df[f'hi_{dist}'] == 0)]['salesPrice_trim'].mean()\n",
        "    norm = 100 / mean_price\n",
        "\n",
        "    # normalize price\n",
        "    df['salesPrice_trim_norm'] = df['salesPrice_trim'] * norm\n",
        "\n",
        "    # create hi variable\n",
        "    df['hi'] = df[f'hi_{dist}']\n",
        "    df['interact'] = df['monthnum'] * df['hi']\n",
        "\n",
        "    # regression\n",
        "    formula = 'salesPrice_trim_norm ~ hi + monthnum + interact'\n",
        "    \n",
        "    for ms in [1,2,3]: # 3 is pooled\n",
        "        if ms == 3:\n",
        "            df_filt = df[(df['in_sample'] == 1)]\n",
        "        else:\n",
        "            df_filt = df[(df['MS'] == ms) & (df['in_sample'] == 1)]\n",
        "        model = smf.ols(formula=formula, data=df_filt).fit(cov_type='cluster', cov_kwds={'groups': df_filt[f'subloc_{dist}_grp']})\n",
        "        results[(dist, ms)] = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vSZoETpyBBMy"
      },
      "outputs": [],
      "source": [
        "pvals = pd.DataFrame()\n",
        "# calculating the adjusted p-values using the t-statistic with cluster-1 degrees of freedom\n",
        "for dv in ['hi', 'monthnum', 'interact']:\n",
        "    pval = {(k[0], k[1]): 2 * (1 - stats.t.cdf(abs(v.params[dv] / v.bse[dv]),df=cleanpricedata_y1y2_tab6[f'subloc_{k[0]}_grp'].nunique()-1)) for k, v in results.items()}\n",
        "    pvals[dv] = pd.Series(pval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run bootstrap iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_bootstraps = 5000 # reported data is based on 5000 iterations\n",
        "bootstrap_ests = {}\n",
        "bootstrap_pvals = pd.DataFrame(index=pd.MultiIndex.from_product([['1km_wt', '3km_wt', '5km_wt'], [1, 2, 3]], names=['dist', 'ms']), columns=['hi', 'monthnum', 'interact'])\n",
        "bootstrap_pvals_test = pd.DataFrame(index=pd.MultiIndex.from_product([['1km_wt', '3km_wt', '5km_wt'], [1, 2, 3]], names=['dist', 'ms']), columns=['hi', 'monthnum', 'interact'])\n",
        "\n",
        "for dist  in ['1km_wt', '3km_wt', '5km_wt']:\n",
        "    df = cleanpricedata_y1y2_tab6.copy(deep=True)\n",
        "    df.dropna(subset=[f'hi_{dist}','salesPrice_trim','monthnum'], inplace=True)\n",
        "    mean_price = df[(df['monthnum'] == 0) & (df[f'hi_{dist}'] == 0)]['salesPrice_trim'].mean()\n",
        "    norm = 100 / mean_price\n",
        "\n",
        "    # normalize price\n",
        "    df['salesPrice_trim_norm'] = df['salesPrice_trim'] * norm\n",
        "    df['salesPrice_trim_norm'] = df['salesPrice_trim_norm'].astype(float)\n",
        "\n",
        "    # create hi variable\n",
        "    df['hi'] = df[f'hi_{dist}']\n",
        "    df['interact'] = df['monthnum'] * df['hi']\n",
        "\n",
        "    # regression\n",
        "    formula = 'salesPrice_trim_norm ~ hi + monthnum + interact'\n",
        "\n",
        "    for ms in [1,2,3]: # 3 is pooled\n",
        "        if ms == 3:\n",
        "            df_filt = df[(df['in_sample'] == 1)]\n",
        "        else:\n",
        "            df_filt = df[(df['MS'] == ms) & (df['in_sample'] == 1)]\n",
        "        \n",
        "        model = results[(dist, ms)]\n",
        "        \n",
        "        boot_ests, boot_pval = cgmwildboot(df_filt, model,n_bootstraps, f'subloc_{dist}_grp',f'subloc_{dist}_grp',seed=5005)\n",
        "        bootstrap_ests[(dist,ms)] = boot_ests\n",
        "        bootstrap_pvals.loc[(dist,ms)] = boot_pval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adjusting pval tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# keep only columns 3km_wt and 3rd column in 1km_wt and 5km_wt\n",
        "pvals = pvals.T\n",
        "pvals = pvals[[('3km_wt', 1), ('3km_wt', 2), ('3km_wt', 3), ('1km_wt', 3), ('5km_wt', 3)]]\n",
        "pvals = pvals.map(lambda x: '<0.001' if x < 0.0005 else np.round(x,3))\n",
        "\n",
        "bootstrap_pvals = bootstrap_pvals.T\n",
        "bootstrap_pvals = bootstrap_pvals[[('3km_wt', 1), ('3km_wt', 2), ('3km_wt', 3), ('1km_wt', 3), ('5km_wt', 3)]]\n",
        "bootstrap_pvals = bootstrap_pvals.map(lambda x: '<0.001' if x < 0.0005 else np.round(x,3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ouput to LaTeX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv9ZnKRtBNWU",
        "outputId": "ebb52c56-42a9-4730-e51a-d6659f6b1520"
      },
      "outputs": [],
      "source": [
        "# use stargazer to create a table\n",
        "result_list = [results[('3km_wt', 1)], results[('3km_wt', 2)], results[('3km_wt', 3)], results[('1km_wt', 3)], results[('5km_wt', 3)]]\n",
        "stargazer = Stargazer(result_list)\n",
        "\n",
        "# configure Stargazer object for output\n",
        "stargazer.custom_columns(['Main Specification (3km)', 'Robustness (Pooled)'], [3, 2])\n",
        "stargazer.rename_covariates({'hi': 'High', 'monthnum': 'Month', 'interact': 'High x Month'})\n",
        "stargazer.show_degrees_of_freedom(False)\n",
        "stargazer.significant_digits(3)\n",
        "stargazer.covariate_order(['hi', 'monthnum', 'interact'])\n",
        "stargazer.show_adj_r2 = False\n",
        "stargazer.show_f_statistic = False\n",
        "stargazer.show_residual_std_err = False\n",
        "stargazer.show_notes = False\n",
        "\n",
        "# adding custom rows with p-values\n",
        "stargazer.add_line('P-value High', pvals.loc['hi'].values.tolist(),location='fb')\n",
        "stargazer.add_line('P-value High Bootstrap', bootstrap_pvals.loc['hi'].values.tolist(),location='fb')\n",
        "stargazer.add_line('P-value Month', pvals.loc['monthnum'].values.tolist(),location='fb')\n",
        "stargazer.add_line('P-value High Bootstrap', bootstrap_pvals.loc['monthnum'].values.tolist(),location='fb')\n",
        "stargazer.add_line('P-value High x Month', pvals.loc['interact'].values.tolist(),location='fb')\n",
        "stargazer.add_line('P-value High x Month Bootstrap', bootstrap_pvals.loc['interact'].values.tolist(),location='fb')\n",
        "\n",
        "latex_table6 = stargazer.render_latex()\n",
        "\n",
        "# edit the latex tables\n",
        "latex_table6 = latex_table6.replace(\"\\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) \\\\\",\n",
        "                                \"\\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) \\n \\\\\\ & Y1 & Y2 & Pooled & 1km & 5km \\\\\")\n",
        "latex_table6 = latex_table6.replace(\"salesPrice_trim_norm\",\"Sales Price Trim\")\n",
        "latex_table6 = latex_table6.replace(\"\\\\begin{table}[!htbp] \\\\centering\", \"\")\n",
        "latex_table6 = latex_table6.replace(\"\\\\end{table}\", \"\")\n",
        "\n",
        "# mannually adjust the significant stars as updated p-values are not reflected in the table\n",
        "latex_table6 = latex_table6.replace(\"4.410$^{**}$\", \"4.410$^{*}$\")\n",
        "latex_table6 = latex_table6.replace(\"3.766$^{**}$\", \"3.766$^{*}$\")\n",
        "\n",
        "with open('tables/table6.tex','w') as file:\n",
        "    file.write(latex_table6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Appendix figure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot distribution of bootstrapped coefficients\n",
        "fig, axs = plt.subplots(3, 3, figsize=(15, 15))\n",
        "for i, dist in enumerate(['1km_wt', '3km_wt', '5km_wt']):\n",
        "    for j, ms in enumerate([1, 2, 3]):\n",
        "        for k, var in enumerate(['hi', 'monthnum', 'interact']):\n",
        "            coef = bootstrap_ests[(dist, ms)][:, k]\n",
        "            mu = np.mean(coef)\n",
        "            sigma = np.std(coef)\n",
        "            x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n",
        "            axs[i, j].hist(coef, bins=50, alpha=0.5, label=var, density=True)\n",
        "            axs[i, j].plot(x, stats.t.pdf(x, df=16, loc=mu, scale=sigma))\n",
        "            if ms == 3:\n",
        "                axs[i, j].set_title(f'{dist} - Pooled')\n",
        "            else:\n",
        "                axs[i, j].set_title(f'{dist} - Y{ms}')\n",
        "            axs[i, j].set_xlabel('Coefficient')\n",
        "            axs[i, j].set_ylabel('Frequency')\n",
        "            axs[i, j].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('figures/boot_dist_tab6.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXsVtSIyyW_w"
      },
      "source": [
        "## Table 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "hRr_Mp-DyYTi"
      },
      "outputs": [],
      "source": [
        "# copy the raw data and create columns for treatment and interaction variable\n",
        "ms1ms2_pooled_tab7 = ms1ms2_pooled.copy(deep=True)\n",
        "# filter relevant columns\n",
        "ms1ms2_pooled_tab7 = ms1ms2_pooled_tab7[['oafid', # id\n",
        "                                         'treat12', 'treat13', 'treatMS1MS2', # treatment variables\n",
        "                                         'inventory_trim', 'netrevenue_trim', 'logtotcons_trim', # outcome variables\n",
        "                                         'Y1round2', 'Y1round3', 'Y2round1', 'Y2round2', 'Y2round3','hi','subloc','interviewdate']] # independent variables\n",
        "\n",
        "ms1ms2_pooled_tab7.sort_index(inplace=True)\n",
        "ms1ms2_pooled_tab7['z'] = pd.NA\n",
        "ms1ms2_pooled_tab7['z_hi'] = pd.NA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EjJ8Mj1g3ND"
      },
      "source": [
        "### Running the first set of regressions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tb7xZ1W4yiA9",
        "outputId": "eabe3d8f-7a16-48be-a95b-c3f29b145855"
      },
      "outputs": [],
      "source": [
        "\n",
        "# list of treaments\n",
        "treatments = ['treat12', 'treat13', 'treatMS1MS2']\n",
        "\n",
        "# list of dependent variables\n",
        "dependent_vars = ['inventory_trim', 'netrevenue_trim', 'logtotcons_trim']\n",
        "\n",
        "# empty dataframes to store mean and std for output\n",
        "mean_std_df = pd.DataFrame(index=pd.MultiIndex.from_product([dependent_vars,treatments], names=['dv','treat']), columns=['mean','std'])\n",
        "\n",
        "# list of changeing independent variables depending on the treatment\n",
        "independent_vars = {\n",
        "    'treat12': 'Y1round2 + Y1round3',\n",
        "    'treat13': 'Y2round2 + Y2round3',\n",
        "    'treatMS1MS2': 'Y1round2 + Y1round3 + Y2round1 + Y2round2 + Y2round3'\n",
        "    }\n",
        "\n",
        "# empty dictionary to store results\n",
        "results = {}\n",
        "pvals = {var: [] for var in ['z', 'hi', 'z_hi','z+z_hi']}\n",
        "\n",
        "# Simulating the loop to replace variables and run regressions\n",
        "for dv in dependent_vars:\n",
        "    for treat in treatments:\n",
        "        # Stata automatically omits the missing values in the regression – here we have to do it manually so we copy the data and drop variables\n",
        "        df = ms1ms2_pooled_tab7.copy(deep=True)\n",
        "        df = df.dropna(subset=[dv, treat, 'hi', 'subloc','interviewdate'])\n",
        "\n",
        "        # store mean and std for output\n",
        "        mean_std_df.loc[(dv, treat),'mean'] = df.loc[df[treat] == 0, dv].mean()\n",
        "        mean_std_df.loc[(dv, treat),'std'] = df.loc[df[treat] == 0, dv].std()\n",
        "        \n",
        "        # setting treament variable\n",
        "        df['z'] = df[treat] # setting z to the treatment variable\n",
        "\n",
        "        # setting interaction variable\n",
        "        df['z_hi'] = df[treat]*df['hi'] # setting z_hi to the interaction of the treatment hi saturation\n",
        "\n",
        "        # setting the formula to run the regression\n",
        "        formula = f'{dv} ~ z + hi + z_hi + interviewdate + {independent_vars[treat]}'\n",
        "\n",
        "        # Run the regression\n",
        "        model_key = f'model_{dependent_vars.index(dv)*len(treatments) + treatments.index(treat)}'\n",
        "        results[model_key] = smf.ols(formula, data=df).fit(cov_type='cluster', cov_kwds={'groups': df['subloc']})\n",
        "\n",
        "        # test the hypothesis that z + z_hi = 0\n",
        "        hypothesis = 'z + z_hi = 0'\n",
        "        t_test = results[model_key].t_test(hypothesis, use_t=True)\n",
        "\n",
        "        # store p-value round to 3 decimals\n",
        "        pvals['z+z_hi'].append(t_test.pvalue)\n",
        "        \n",
        "        # calculate t-test p-values for z, hi, z_hi\n",
        "        for var in ['z', 'hi', 'z_hi']:\n",
        "            pval = 2 * (1 - stats.t.cdf(abs(results[model_key].params[var] / results[model_key].bse[var]),df=df[f'subloc'].nunique()-1))\n",
        "            pvals[var].append(pval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "pvals = pd.DataFrame(pvals).T\n",
        "pvals = pvals.map(lambda x: '<0.001' if x < 0.0005 else np.round(x,3))\n",
        "\n",
        "mean_std_df['mean'] = mean_std_df['mean'].astype(float).round(3)\n",
        "mean_std_df['std'] = mean_std_df['std'].astype(float).round(3)\n",
        "mean_std_df = mean_std_df.T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOjQSC-NhbD7"
      },
      "source": [
        "### Running boostrap regressions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "rtNR18qGhgM5"
      },
      "outputs": [],
      "source": [
        "n_bootstraps = 5000  # reported data is based on 5000 iterations\n",
        "bootstrap_ests = {}\n",
        "bootstrap_pvals = pd.DataFrame(index=pd.MultiIndex.from_product([dependent_vars, treatments], names=['treatment', 'dep_var']), columns=['z','hi','z_hi'])\n",
        "\n",
        "for dv in dependent_vars:\n",
        "    for treat in treatments:\n",
        "        df = ms1ms2_pooled_tab7.copy(deep=True)\n",
        "        df = df.dropna(subset=[dv, treat, 'hi', 'interviewdate','subloc'])\n",
        "        df['z'] = df[treat]\n",
        "        df['z_hi'] = df[treat] * df['hi']\n",
        "        df[dv] = df[dv].astype(float)\n",
        "\n",
        "        formula = f'{dv} ~ z + hi + z_hi + interviewdate + {independent_vars[treat]}'\n",
        "        model_key = f'model_{dependent_vars.index(dv)*len(treatments) + treatments.index(treat)}'\n",
        "        model = results[model_key]\n",
        "\n",
        "        # Wild bootstrap        \n",
        "        boot_ests, boot_pval = cgmwildboot(df, model,n_bootstraps, 'subloc','subloc',seed=5005)\n",
        "        bootstrap_ests[(dv,treat)] = boot_ests\n",
        "\n",
        "        for i, var in enumerate(['z', 'hi', 'z_hi']):\n",
        "            bootstrap_pvals.loc[(dv,treat),var] = boot_pval[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "bootstrap_pvals = bootstrap_pvals.T\n",
        "bootstrap_pvals = bootstrap_pvals.map(lambda x: '<0.001' if x < 0.0005 else np.round(x,3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UdXeJZAhhEo"
      },
      "source": [
        "### Output to LaTeX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "DOQVwnBvwMBm"
      },
      "outputs": [],
      "source": [
        "# use stargazer to create a table\n",
        "result_list = list(results.values())\n",
        "stargazer = Stargazer(result_list)\n",
        "\n",
        "# configure Stargazer object for output\n",
        "stargazer.custom_columns(['Inventory', 'Net Revenues', 'Consumption'], [3, 3, 3])\n",
        "stargazer.rename_covariates({'z': 'Treat', 'hi': 'High', 'z_hi': 'Treat x High'})\n",
        "stargazer.show_degrees_of_freedom(False)\n",
        "stargazer.significant_digits(3)\n",
        "stargazer.covariate_order(['z', 'hi', 'z_hi'])\n",
        "stargazer.show_adj_r2 = False\n",
        "stargazer.show_f_statistic = False\n",
        "stargazer.show_residual_std_err = False\n",
        "stargazer.show_notes = False\n",
        "\n",
        "# adding custom rows with mean, sd, and p-values\n",
        "stargazer.add_line('Mean DV', mean_std_df.loc['mean'].tolist(),location='fb')\n",
        "stargazer.add_line('SD DV', mean_std_df.loc['std'].tolist(),location='fb')\n",
        "stargazer.add_line('P-value T + TH = 0', pvals.loc['z+z_hi'].tolist(),location='fb')\n",
        "stargazer.add_line('P-value Treat', pvals.loc['z'].tolist(),location='fb')\n",
        "stargazer.add_line('P-value Treat Bootstrap', bootstrap_pvals.loc['z'].tolist(),location='fb')\n",
        "stargazer.add_line('P-value High', pvals.loc['hi'].tolist(),location='fb')\n",
        "stargazer.add_line('P-value High Bootstrap', bootstrap_pvals.loc['hi'].tolist(),location='fb')\n",
        "stargazer.add_line('P-value Treat x High', pvals.loc['z_hi'].tolist())\n",
        "stargazer.add_line('P-value Treat x High Bootstrap', bootstrap_pvals.loc['z_hi'].tolist(),location='fb')\n",
        "\n",
        "latex_table7 = stargazer.render_latex()\n",
        "\n",
        "# edit the latex table to add row for telling if Y1 Y2 or Pooled after \\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) & (6) & (7) & (8) & (9) \\\\\n",
        "latex_table7 = latex_table7.replace(\"\\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) & (6) & (7) & (8) & (9) \\\\\",\n",
        "                                \"\\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) & (6) & (7) & (8) & (9) \\n \\\\\\ & Y1 & Y2 & Pooled & Y1 & Y2 & Pooled & Y1 & Y2 & Pooled \\\\\")\n",
        "latex_table7 = latex_table7.replace(\"\\\\begin{table}[!htbp] \\\\centering\", \"\")\n",
        "latex_table7 = latex_table7.replace(\"\\\\end{table}\", \"\")\n",
        "\n",
        "# mannually adjust the significant stars as updated p-values are not reflected in the table\n",
        "latex_table7 = latex_table7.replace(\"1193.768$^{*}$\", \"1193.768$^{}$\")\n",
        "latex_table7 = latex_table7.replace(\"-1114.628$^{**}$\", \"-1114.628$^{*}$\")\n",
        "\n",
        "with open('tables/table7.tex','w') as file:\n",
        "    file.write(latex_table7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating Appendix Figure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot distribution of bootstrapped coefficients\n",
        "fig, axs = plt.subplots(3, 3, figsize=(15, 15))\n",
        "for i, dv in enumerate(['inventory_trim', 'netrevenue_trim', 'logtotcons_trim']):\n",
        "    for j, treat in enumerate(['treat12', 'treat13', 'treatMS1MS2']):\n",
        "        for k, var in enumerate(['z', 'hi', 'z_hi']):\n",
        "            coef = bootstrap_ests[(dv, treat)][:, k]\n",
        "            mu = np.mean(coef)\n",
        "            sigma = np.std(coef)\n",
        "            x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n",
        "            axs[i, j].hist(coef, bins=50, alpha=0.5, label=var, density=True)\n",
        "            axs[i, j].plot(x, stats.t.pdf(x, df=ms1ms2_pooled_tab7['subloc'].nunique()-1, loc=mu, scale=sigma))\n",
        "            if j == 2:\n",
        "                axs[i, j].set_title(f'{dv} - Pooled')\n",
        "            else:\n",
        "                axs[i, j].set_title(f'{dv} - Y{j+1}')\n",
        "            axs[i, j].set_xlabel('Coefficient')\n",
        "            axs[i, j].set_ylabel('Frequency')\n",
        "            axs[i, j].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('figures/boot_dist_tab7.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F11Z5SCUQyO_"
      },
      "source": [
        "## Table 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ocrbGi-hmfA",
        "outputId": "ef6091c5-aada-4e72-da7a-5d91243def0c"
      },
      "outputs": [],
      "source": [
        "# As specified in appendix B\n",
        "# Total population (HH) in the study area\n",
        "A1 = 7105.0\n",
        "# % of population in low saturation areas\n",
        "A2 = 0.5\n",
        "# % of population member of OAF\n",
        "A3 = 0.3\n",
        "# % of OAF members enrolled in study in a low saturation areas and b high saturation areas\n",
        "A4a = 0.4\n",
        "A4b = 0.8\n",
        "# % in each sublocation assigned to receive treatment\n",
        "A5 = 0.58\n",
        "\n",
        "# Annualized coefficients\n",
        "beta1 = results['model_5'].params['z']*3\n",
        "beta2 = results['model_5'].params['hi']*3\n",
        "beta3 = results['model_5'].params['z_hi']*3\n",
        "\n",
        "table_8 = {\n",
        "    \"1. Direct gains/HH (Ksh)\": [beta1, beta1+beta3],\n",
        "    \"2. Indirect gains/HH (Ksh)\": [0, beta2],\n",
        "    \"3. Ratio of indirect to direct gains\": [0, beta2 / (beta1+beta3)],\n",
        "    \"4. Direct beneficiary population (HH)\": [A1*A2*A3*A4a*A5, A1*(1-A2)*A3*A4b*A5],\n",
        "    \"5. Total local population (HH)\": [A1*A2, A1*(1-A2)]\n",
        "}\n",
        "\n",
        "# convert to DataFrame and perform final calculations\n",
        "table_8_df = pd.DataFrame(table_8, index=[\"Low Saturation\", \"High Saturation\"]).T\n",
        "\n",
        "table_8_df.loc['6. Total direct gains (Ksh)'] = table_8_df.loc['1. Direct gains/HH (Ksh)']*table_8_df.loc['4. Direct beneficiary population (HH)']\n",
        "table_8_df.loc['7. Total indirect gains (Ksh)'] = table_8_df.loc['2. Indirect gains/HH (Ksh)']*table_8_df.loc['4. Direct beneficiary population (HH)']\n",
        "table_8_df.loc['8. Total gains (direct + indirect; Ksh)'] = table_8_df.loc['6. Total direct gains (Ksh)'] + table_8_df.loc['7. Total indirect gains (Ksh)']\n",
        "table_8_df.loc['9. Fraction of gains direct'] = table_8_df.loc['6. Total direct gains (Ksh)'] / table_8_df.loc['8. Total gains (direct + indirect; Ksh)']\n",
        "table_8_df.loc['10. Fraction of gains indirect'] = table_8_df.loc['7. Total indirect gains (Ksh)'] / table_8_df.loc['8. Total gains (direct + indirect; Ksh)']\n",
        "\n",
        "table_8_df = table_8_df.map(lambda x: np.round(x, 3))\n",
        "\n",
        "latex_table8 = table_8_df.to_latex(index=True, float_format=\"%.3f\") \n",
        "latex_table8 = latex_table8.replace('\\\\toprule', '\\\\\\[-1.8ex]\\hline \\n \\hline \\\\\\[-1.8ex]')\n",
        "latex_table8 = latex_table8.replace('\\\\bottomrule', '\\\\\\[-1.8ex]\\hline \\n \\hline \\\\\\[-1.8ex]')\n",
        "\n",
        "with open('tables/table8.tex','w') as file:\n",
        "    file.write(latex_table8)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "NLR-EsZmPhnZ",
        "J2Kt7J_ve0Jr",
        "MapKqTx56PLs",
        "EFcatyv4Dk08",
        "iFWCk0Ja1NUj",
        "eXsVtSIyyW_w"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
