{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0oyPnEQIxpq"
      },
      "source": [
        "# Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "nE0qteMlufaZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn.linear_model as lm\n",
        "from statsmodels.stats.weightstats import ttest_ind\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from datetime import datetime\n",
        "from sklearn.utils import resample\n",
        "from random import choices\n",
        "from statsmodels.stats.multitest import multipletests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwtx6H3aAHvv",
        "outputId": "d807dc77-f5f1-4672-d325-17ff5ed669e8"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  from stargazer.stargazer import Stargazer\n",
        "except ImportError:\n",
        "  %pip install stargazer\n",
        "  from stargazer.stargazer import Stargazer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgzJ03RhI4Go"
      },
      "source": [
        "# Import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtyS2XfKKJKd",
        "outputId": "87946a65-6548-4a57-ff18-e9086fb3063e"
      },
      "outputs": [],
      "source": [
        "# import data\n",
        "baseline = pd.read_stata('data/baseline.dta')\n",
        "cleanpricedata_y1y2 = pd.read_stata('data/cleanPriceData_Y1Y2.dta')\n",
        "ms1ms2_pooled = pd.read_stata('data/MS1MS2_pooled.dta')\n",
        "\n",
        "# this data is not needed for our analysis\n",
        "# bok_inflation = pd.read_stata('data/BOK_inflation.dta')\n",
        "# intensity_obs_short = pd.read_stata('data/intensity_obs_short.dta')\n",
        "# lrfu_select_dataset = pd.read_stata('data/LRFU_select_dataset.dta')\n",
        "# repayment_datay1 = pd.read_stata('data/repayment_dataY1.dta')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ufa1dpjdPM4N"
      },
      "source": [
        "# Recreating the tables from the paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLR-EsZmPhnZ"
      },
      "source": [
        "## Table 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDod8jI8PmcV"
      },
      "source": [
        "We start by cleaning the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27C6MkYfPjWZ",
        "outputId": "be660654-5f0b-4bc5-e9a6-9cd83ea3455b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1019\n"
          ]
        }
      ],
      "source": [
        "# clean ms1ms2_pooled (drop if MS !=2, keep columns oafid and treatMS1MS2, group by oafid and take mean and rename)\n",
        "ms1ms2_pooled_tab1 = ms1ms2_pooled[ms1ms2_pooled['MS']==2]\n",
        "ms1ms2_pooled_tab1 = ms1ms2_pooled_tab1[['oafid', 'treatMS1MS2']]\n",
        "ms1ms2_pooled_tab1 = ms1ms2_pooled_tab1.groupby('oafid', as_index=False).mean()\n",
        "ms1ms2_pooled_tab1.rename(columns={'treatMS1MS2': 'treat13'}, inplace=True)\n",
        "print(ms1ms2_pooled_tab1.shape[0]) # checking we have the right number of observations as described in the original article"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "NDAHBMLAPxQM"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/yw/jsw5n53s1cb1s2q6tt0msrm00000gn/T/ipykernel_46631/2284489521.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
            "  baseline_clean.loc[baseline_clean['treatment2012'] == '', 'treat12'] = np.nan\n"
          ]
        }
      ],
      "source": [
        "# clean baseline data (the stata code indicates that the variables columns 'businessprofitmonth' and 'delta' should be kept, however they have already been renamed to 'businessprofitmonth_base' and 'delta_base')\n",
        "base_cols = ['oafid', 'logtotcons_base', 'male', 'num_adults', 'num_schoolchildren', 'finished_primary',\n",
        "                   'finished_secondary', 'cropland', 'num_rooms', 'schoolfees', 'totcons_base', 'logpercapcons_base',\n",
        "                   'total_cash_savings_base', 'total_cash_savings_trimmed', 'has_savings_acct', 'taken_bank_loan',\n",
        "                   'taken_informal_loan', 'liquidWealth', 'wagepay', 'businessprofitmonth_base', 'price_avg_diff_pct',\n",
        "                   'price_expect_diff_pct', 'harvest2011', 'netrevenue2011', 'netseller2011', 'autarkic2011',\n",
        "                   'maizelostpct2011', 'harvest2012', 'correct_interest', 'digit_recall', 'maizegiver', 'delta_base', 'treatment']\n",
        "baseline_clean = baseline[base_cols].copy()\n",
        "\n",
        "# rename columns\n",
        "baseline_clean.columns = [col + '_base' if not col.endswith('_base') and col != 'oafid' and col != 'treatment' else col for col in baseline_clean.columns]\n",
        "baseline_clean.rename(columns={'treatment': 'treatment2012'}, inplace=True)\n",
        "\n",
        "# generate treat12 as bool for treatment and control in 2012\n",
        "baseline_clean['treat12'] = baseline_clean['treatment2012'].apply(lambda x: x in ['T1', 'T2'])\n",
        "baseline_clean.loc[baseline_clean['treatment2012'] == '', 'treat12'] = np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "NLEtoCbkPzAN"
      },
      "outputs": [],
      "source": [
        "# merge baseline_clean and ms1ms2_pooled_clean on oafid\n",
        "base_ms1ms2_pool = pd.merge(baseline_clean, ms1ms2_pooled_tab1, on='oafid', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        },
        "id": "69_xFPsuQTmG",
        "outputId": "279489ba-6e05-4d96-caca-5214d7b4ab53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\begin{tabular}{lrrrrr}\n",
            "\\toprule\n",
            "Baseline characteristic & Treat & Control & Obs & Std diff & P-val \\\\\n",
            "\\midrule\n",
            "Male & 0.296 & 0.334 & 1589 & -0.083 & 0.109 \\\\\n",
            "Number of adults & 3.004 & 3.196 & 1510 & -0.099 & 0.067 \\\\\n",
            "Children in school & 2.998 & 3.072 & 1589 & -0.038 & 0.454 \\\\\n",
            "Finished primary school & 0.718 & 0.772 & 1490 & -0.122 & 0.019 \\\\\n",
            "Finished secondary school & 0.253 & 0.270 & 1490 & -0.039 & 0.460 \\\\\n",
            "Total cropland (acres) & 2.441 & 2.398 & 1512 & 0.014 & 0.796 \\\\\n",
            "Number of rooms in household & 3.073 & 3.252 & 1511 & -0.072 & 0.219 \\\\\n",
            "Total school fees & 27239.693 & 29813.631 & 1589 & -0.068 & 0.191 \\\\\n",
            "Average monthly consumption (Ksh) & 14970.862 & 15371.378 & 1437 & -0.032 & 0.550 \\\\\n",
            "Average monthly consumption/capita (log) & 7.975 & 7.963 & 1434 & 0.019 & 0.721 \\\\\n",
            "Total cash savings (Ksh) & 5157.396 & 8021.499 & 1572 & -0.128 & 0.028 \\\\\n",
            "Total cash savings (trim) & 4731.623 & 5389.836 & 1572 & -0.050 & 0.343 \\\\\n",
            "Has bank savings acct & 0.419 & 0.425 & 1589 & -0.012 & 0.815 \\\\\n",
            "Taken bank loan & 0.079 & 0.083 & 1589 & -0.018 & 0.730 \\\\\n",
            "Taken informal loan & 0.244 & 0.249 & 1589 & -0.011 & 0.836 \\\\\n",
            "Liquid wealth (Ksh) & 93878.938 & 97280.922 & 1491 & -0.032 & 0.547 \\\\\n",
            "Off-farm wages (Ksh) & 3916.817 & 3797.480 & 1589 & 0.010 & 0.854 \\\\\n",
            "Business profit (Ksh) & 2302.588 & 1801.685 & 1589 & 0.051 & 0.265 \\\\\n",
            "Avg $\\%\\Delta$ price Sep-Jun & 133.495 & 133.178 & 1504 & 0.004 & 0.939 \\\\\n",
            "Expect $\\%\\Delta$ price Sep12-Jun13 & 124.680 & 117.255 & 1510 & 0.075 & 0.103 \\\\\n",
            "2011 LR harvest (bags) & 9.364 & 9.025 & 1511 & 0.022 & 0.670 \\\\\n",
            "Net revenue 2011 (Ksh) & -3303.691 & -4088.622 & 1428 & 0.017 & 0.716 \\\\\n",
            "Net seller 2011 & 0.324 & 0.303 & 1428 & 0.046 & 0.393 \\\\\n",
            "Autarkic 2011 & 0.068 & 0.060 & 1589 & 0.034 & 0.506 \\\\\n",
            "\\% maize lost 2011 & 0.016 & 0.013 & 1428 & 0.030 & 0.563 \\\\\n",
            "2012 LR harvest (bags) & 11.181 & 11.030 & 1484 & 0.018 & 0.733 \\\\\n",
            "Calculated interest correctly & 0.715 & 0.730 & 1580 & -0.034 & 0.502 \\\\\n",
            "Digit span recall & 4.568 & 4.576 & 1504 & -0.007 & 0.890 \\\\\n",
            "Maize giver & 0.261 & 0.261 & 1589 & -0.001 & 0.985 \\\\\n",
            "\\bottomrule\n",
            "\\end{tabular}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# create table 1\n",
        "# copy in case we need this later\n",
        "df_tab1 = base_ms1ms2_pool.copy()\n",
        "df_tab1['schoolfees_base'] = df_tab1['schoolfees_base']*1000\n",
        "\n",
        "# var list for table 1\n",
        "vars_list = [\n",
        "    \"male_base\", \"num_adults_base\", \"num_schoolchildren_base\", \"finished_primary_base\",\n",
        "    \"finished_secondary_base\", \"cropland_base\", \"num_rooms_base\", \"schoolfees_base\",\n",
        "    \"totcons_base\", \"logpercapcons_base\", \"total_cash_savings_base\",\n",
        "    \"total_cash_savings_trimmed_base\", \"has_savings_acct_base\", \"taken_bank_loan_base\",\n",
        "    \"taken_informal_loan_base\", \"liquidWealth_base\", \"wagepay_base\",\n",
        "    \"businessprofitmonth_base\", \"price_avg_diff_pct_base\",\n",
        "    \"price_expect_diff_pct_base\", \"harvest2011_base\", \"netrevenue2011_base\",\n",
        "    \"netseller2011_base\", \"autarkic2011_base\", \"maizelostpct2011_base\",\n",
        "    \"harvest2012_base\", \"correct_interest_base\", \"digit_recall_base\",\n",
        "    \"maizegiver_base\"\n",
        "]\n",
        "\n",
        "renaming = {\n",
        "    \"male_base\": \"Male\",\n",
        "    \"num_adults_base\": \"Number of adults\",\n",
        "    \"num_schoolchildren_base\": \"Children in school\",\n",
        "    \"finished_primary_base\": \"Finished primary school\",\n",
        "    \"finished_secondary_base\": \"Finished secondary school\",\n",
        "    \"cropland_base\": \"Total cropland (acres)\",\n",
        "    \"num_rooms_base\": \"Number of rooms in household\",\n",
        "    \"schoolfees_base\": \"Total school fees\",\n",
        "    \"totcons_base\": \"Average monthly consumption (Ksh)\",\n",
        "    \"logpercapcons_base\": \"Average monthly consumption/capita (log)\",\n",
        "    \"total_cash_savings_base\": \"Total cash savings (Ksh)\",\n",
        "    \"total_cash_savings_trimmed_base\": \"Total cash savings (trim)\",\n",
        "    \"has_savings_acct_base\": \"Has bank savings acct\",\n",
        "    \"taken_bank_loan_base\": \"Taken bank loan\",\n",
        "    \"taken_informal_loan_base\": \"Taken informal loan\",\n",
        "    \"liquidWealth_base\": \"Liquid wealth (Ksh)\",\n",
        "    \"wagepay_base\": \"Off-farm wages (Ksh)\",\n",
        "    \"businessprofitmonth_base\": \"Business profit (Ksh)\",\n",
        "    \"price_avg_diff_pct_base\": \"Avg $\\%\\Delta$ price Sep-Jun\",\n",
        "    \"price_expect_diff_pct_base\": \"Expect $\\%\\Delta$ price Sep12-Jun13\",\n",
        "    \"harvest2011_base\": \"2011 LR harvest (bags)\",\n",
        "    \"netrevenue2011_base\": \"Net revenue 2011 (Ksh)\",\n",
        "    \"netseller2011_base\": \"Net seller 2011\",\n",
        "    \"autarkic2011_base\": \"Autarkic 2011\",\n",
        "    \"maizelostpct2011_base\": \"\\% maize lost 2011\",\n",
        "    \"harvest2012_base\": \"2012 LR harvest (bags)\",\n",
        "    \"correct_interest_base\": \"Calculated interest correctly\",\n",
        "    \"digit_recall_base\": \"Digit span recall\",\n",
        "    \"maizegiver_base\": \"Maize giver\"\n",
        "}\n",
        "\n",
        "# function to perform t-tests\n",
        "def t_test_by_group(df, var, group_var='treat12'):\n",
        "    group1 = df[df[group_var] == 0][var].dropna()\n",
        "    group2 = df[df[group_var] == 1][var].dropna()\n",
        "    t_stat, p_val = stats.ttest_ind(group1, group2, equal_var=False)\n",
        "    return group1.mean(), group2.mean(), len(group1) + len(group2), t_stat, p_val\n",
        "\n",
        "# applying t-tests and collecting results\n",
        "results = []\n",
        "for var in vars_list:\n",
        "    control_mean, treat_mean, obs, t_stat, p_val = t_test_by_group(df_tab1, var)\n",
        "    std_diff = (treat_mean - control_mean) / np.sqrt(((len(df_tab1[df_tab1['treat12'] == 0][var]) - 1) * np.std(df_tab1[df_tab1['treat12'] == 0][var], ddof=1) ** 2 + (len(df_tab1[df_tab1['treat12'] == 1][var]) - 1) * np.std(df_tab1[df_tab1['treat12'] == 1][var], ddof=1) ** 2) / (len(df_tab1[df_tab1['treat12'] == 0][var]) + len(df_tab1[df_tab1['treat12'] == 1][var]) - 2))\n",
        "    results.append([var, treat_mean, control_mean, obs, std_diff, p_val])\n",
        "\n",
        "# convert results to a df to use pandas output to latex\n",
        "results_df = pd.DataFrame(results, columns=['Variable', 'Treat Mean', 'Control Mean', 'Observations', 'Std Diff', 'P-value'])\n",
        "results_df['Variable'] = results_df['Variable'].map(renaming)\n",
        "results_df = results_df.rename(columns={\n",
        "    'Variable':'Baseline characteristic', \n",
        "    'Treat Mean':'Treat', \n",
        "    'Control Mean':'Control', \n",
        "    'Observations':'Obs', \n",
        "    'Std Diff':'Std diff', \n",
        "    'P-value':'P-val'})\n",
        "\n",
        "latex_table1 = results_df.to_latex(index=False, float_format=\"%.3f\")\n",
        "print(latex_table1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2Kt7J_ve0Jr"
      },
      "source": [
        "## Table 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "2X1_xA0QR_xZ"
      },
      "outputs": [],
      "source": [
        "# year 1 overall\n",
        "ms1ms2_clean1 = ms1ms2_pooled.loc[:, ['treat12', 'interviewdate1', 'interviewdate', 'Y1round1', 'Y1round2', 'Y1round3', 'treatMS1MS2', 'inventory_trim', 'groupnum', 'strata_group', 'round']].dropna()\n",
        "ms1ms2_clean1['inter_R1'] = ms1ms2_clean1['Y1round1'] * ms1ms2_clean1['treat12']\n",
        "ms1ms2_clean1['inter_R2'] = ms1ms2_clean1['Y1round2'] * ms1ms2_clean1['treat12']\n",
        "ms1ms2_clean1['inter_R3'] = ms1ms2_clean1['Y1round3'] * ms1ms2_clean1['treat12']\n",
        "\n",
        "# model specification with fixed effects for strata_group\n",
        "model = smf.ols('inventory_trim ~ treat12 + interviewdate + C(strata_group)', data=ms1ms2_clean1)\n",
        "\n",
        "# fitting the model with robust standard errors clustered by 'groupnum'\n",
        "results1 = model.fit(cov_type='cluster', cov_kwds={'groups': ms1ms2_clean1['groupnum']})\n",
        "\n",
        "# extract necessary statistics\n",
        "model_params1 = results1.params\n",
        "model_pvalues1 = results1.pvalues\n",
        "mean_dv1 = ms1ms2_clean1['inventory_trim'].mean()\n",
        "sd_dv1 = ms1ms2_clean1['inventory_trim'].std()\n",
        "\n",
        "# calculating the Bonferroni corrections for the p-values\n",
        "bonferroni_pvalues1 = {key: multipletests(results1.pvalues[key], method='fdr_bh')[1] for key, val in model_pvalues1.items() if key in ['treat12', 'inter_R1', 'inter_R2', 'inter_R3']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "yrx7OVblFQI5"
      },
      "outputs": [],
      "source": [
        "# year 1 by round\n",
        "model_interactions = smf.ols('inventory_trim ~ inter_R1 + inter_R2 + inter_R3 + interviewdate + C(Y1round1) + C(Y1round2) + C(Y1round3) + C(strata_group)', data=ms1ms2_clean1)\n",
        "results2 = model_interactions.fit(cov_type='cluster', cov_kwds={'groups': ms1ms2_clean1['groupnum']})\n",
        "\n",
        "# extract necessary statistics\n",
        "model_params2 = results2.params\n",
        "model_pvalues2 = results2.pvalues\n",
        "mean_dv2 = ms1ms2_clean1['inventory_trim'].mean()\n",
        "sd_dv2 = ms1ms2_clean1['inventory_trim'].std()\n",
        "\n",
        "# number of tests, include only treat12 and its interaction terms if they exist\n",
        "num_tests = 1 + ('inter_R1' in model_params2) + ('inter_R2' in model_params2) + ('inter_R3' in model_params2)\n",
        "\n",
        "# calculating the Bonferroni corrections for the p-values\n",
        "bonferroni_pvalues2 = {key: multipletests(results2.pvalues[key], method='fdr_bh')[1] for key, val in model_pvalues2.items() if key in ['treat12', 'inter_R1', 'inter_R2', 'inter_R3']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "9om7TsFHfcnZ"
      },
      "outputs": [],
      "source": [
        "# year 2 overall\n",
        "ms1ms2_clean2 = ms1ms2_pooled.loc[:, ['treat13', 'Y2round1', 'Y2round2', 'Y2round3', 'treatMS1MS2', 'inventory_trim', 'interviewdate', 'date', 'strata_group', 'groupnum']].dropna()\n",
        "ms1ms2_clean2['inter_R1'] = ms1ms2_clean2['Y2round1'] * ms1ms2_clean2['treat13']\n",
        "ms1ms2_clean2['inter_R2'] = ms1ms2_clean2['Y2round2'] * ms1ms2_clean2['treat13']\n",
        "ms1ms2_clean2['inter_R3'] = ms1ms2_clean2['Y2round3'] * ms1ms2_clean2['treat13']\n",
        "\n",
        "# model specification with fixed effects for strata_group\n",
        "model = smf.ols('inventory_trim ~ treat13 + interviewdate + C(strata_group)', data=ms1ms2_clean2)\n",
        "\n",
        "# Fitting the model with robust standard errors clustered by 'groupnum'\n",
        "results3 = model.fit(cov_type='cluster', cov_kwds={'groups': ms1ms2_clean2['groupnum']})\n",
        "\n",
        "# extract necessary statistics\n",
        "model_params3 = results3.params\n",
        "model_pvalues3 = results3.pvalues\n",
        "mean_dv3 = ms1ms2_clean2['inventory_trim'].mean()\n",
        "sd_dv3 = ms1ms2_clean2['inventory_trim'].std()\n",
        "\n",
        "# number of tests, include only treat12 and its interaction terms if they exist\n",
        "num_tests = 1 + ('inter_R1' in model_params3) + ('inter_R2' in model_params3) + ('inter_R3' in model_params3)\n",
        "\n",
        "# calculating the Bonferroni corrections for the p-values\n",
        "bonferroni_pvalues3 = {key: multipletests(results3.pvalues[key], method='fdr_bh')[1] for key, val in model_pvalues3.items() if key in ['treat13', 'inter_R1', 'inter_R2', 'inter_R3']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "6B_uPtaZstiu"
      },
      "outputs": [],
      "source": [
        "# year 2 by round\n",
        "model_interactions = smf.ols('inventory_trim ~ inter_R1 + inter_R2 + inter_R3 + interviewdate + C(Y2round1) + C(Y2round2) + C(Y2round3) + C(strata_group)', data=ms1ms2_clean2)\n",
        "results4 = model_interactions.fit(cov_type='cluster', cov_kwds={'groups': ms1ms2_clean2['groupnum']})\n",
        "\n",
        "# extract necessary statistics\n",
        "model_params4 = results4.params\n",
        "model_pvalues4 = results4.pvalues\n",
        "mean_dv4 = ms1ms2_clean2['inventory_trim'].mean()\n",
        "sd_dv4 = ms1ms2_clean2['inventory_trim'].std()\n",
        "\n",
        "# number of tests, include only treat12 and its interaction terms if they exist\n",
        "num_tests = 1 + ('inter_R1' in model_params4) + ('inter_R2' in model_params4) + ('inter_R3' in model_params4)\n",
        "\n",
        "# calculating the Bonferroni corrections for the p-values\n",
        "bonferroni_pvalues4 = {key: multipletests(results4.pvalues[key], method='fdr_bh')[1] for key, val in model_pvalues4.items() if key in ['treat13', 'inter_R1', 'inter_R2', 'inter_R3']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "q01gay6Tm4ts"
      },
      "outputs": [],
      "source": [
        "# pooled overall\n",
        "ms1ms2_clean3 = pd.concat([ms1ms2_clean1, ms1ms2_clean2], ignore_index=True).fillna(0)\n",
        "ms1ms2_clean3.sort_values(by='interviewdate')\n",
        "\n",
        "# model specification with fixed effects for strata_group\n",
        "model = smf.ols('inventory_trim ~ treatMS1MS2 + interviewdate + C(strata_group)', data=ms1ms2_clean3)\n",
        "\n",
        "# fitting the model with robust standard errors clustered by 'groupnum'\n",
        "results5 = model.fit(cov_type='cluster', cov_kwds={'groups': ms1ms2_clean3['groupnum']})\n",
        "\n",
        "# extract necessary statistics\n",
        "model_params5 = results5.params\n",
        "model_pvalues5 = results5.pvalues\n",
        "mean_dv5 = ms1ms2_clean3['inventory_trim'].mean()\n",
        "sd_dv5 = ms1ms2_clean3['inventory_trim'].std()\n",
        "# number of tests, include only treat12 and its interaction terms if they exist\n",
        "num_tests = 1 + ('inter_R1' in model_params5) + ('inter_R2' in model_params5) + ('inter_R3' in model_params5)\n",
        "\n",
        "# calculating the Bonferroni corrections for the p-values\n",
        "bonferroni_pvalues5 = {key: multipletests(results5.pvalues[key], method='fdr_bh')[1] for key, val in model_pvalues5.items() if key in ['treatMS1MS2', 'inter_R1', 'inter_R2', 'inter_R3']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "mw77nJqfxRK4"
      },
      "outputs": [],
      "source": [
        "# pooled by round\n",
        "# model specification with fixed effects for strata_group\n",
        "model = smf.ols('inventory_trim ~ inter_R1 + inter_R2 + inter_R3 + interviewdate + C(Y1round1) + C(Y1round2) + C(Y1round3) + C(Y2round1) + C(Y2round2) + C(Y2round3) + C(strata_group)', data=ms1ms2_clean3)\n",
        "\n",
        "# fitting the model with robust standard errors clustered by 'groupnum'\n",
        "results6 = model.fit(cov_type='cluster', cov_kwds={'groups': ms1ms2_clean3['groupnum']})\n",
        "\n",
        "# Extract necessary statistics\n",
        "model_params6 = results6.params\n",
        "model_pvalues6 = results6.pvalues\n",
        "mean_dv6 = ms1ms2_clean3['inventory_trim'].mean()\n",
        "sd_dv6 = ms1ms2_clean3['inventory_trim'].std()\n",
        "\n",
        "# number of tests, include only treat12 and its interaction terms if they exist\n",
        "num_tests = 1 + ('inter_R1' in model_params6) + ('inter_R2' in model_params6) + ('inter_R3' in model_params6)\n",
        "\n",
        "# calculating the Bonferroni corrections for the p-values\n",
        "bonferroni_pvalues6 = {key: multipletests(results6.pvalues[key], method='fdr_bh')[1] for key, val in model_pvalues6.items() if key in ['treatMS1MS2', 'inter_R1', 'inter_R2', 'inter_R3']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "V4XchsWdCzhq"
      },
      "outputs": [],
      "source": [
        "# collecting p-values in tables to easily add them to the latex table\n",
        "results_tab2 = [results1,results2,results3,results4,results5,results6]\n",
        "\n",
        "# get p-values for treat12, treat13, treatMS1MS2, inter_R1, inter_R2, inter_R3\n",
        "p_values = {}\n",
        "for result in results_tab2:\n",
        "    p_values[result] = np.round(result.pvalues,3)\n",
        "    p_values_df= pd.DataFrame(p_values)\n",
        "\n",
        "p_values_df = p_values_df.loc[['treat12', 'treat13', 'treatMS1MS2', 'inter_R1', 'inter_R2', 'inter_R3']]\n",
        "p_values_df.columns = ['(1)', '(2)', '(3)', '(4)', '(5)', '(6)']\n",
        "p_values_df.loc['Treat'] = p_values_df.loc[['treat12', 'treat13', 'treatMS1MS2']].mean()\n",
        "p_values_df.drop(['treat12', 'treat13', 'treatMS1MS2'], inplace=True)\n",
        "\n",
        "# fwer correction\n",
        "fwer_p_values = [bonferroni_pvalues1, bonferroni_pvalues2, bonferroni_pvalues3, bonferroni_pvalues4, bonferroni_pvalues5, bonferroni_pvalues6]\n",
        "\n",
        "# get p-values for treat12, treat13, treatMS1MS2, inter_R1, inter_R2, inter_R3\n",
        "p_values_fwer = {}\n",
        "for i, p_values in enumerate(fwer_p_values):\n",
        "    p_values_fwer[i] = p_values\n",
        "    p_values_df_fwer = pd.DataFrame(p_values_fwer)\n",
        "\n",
        "p_values_df_fwer.loc['Treat'] = p_values_df_fwer.loc[['treat12', 'treat13', 'treatMS1MS2']].mean()\n",
        "p_values_df_fwer.drop(['treat12', 'treat13', 'treatMS1MS2'], inplace=True)\n",
        "\n",
        "# changeing everything to numeric and rounding\n",
        "def to_numeric(x):\n",
        "    if isinstance(x, np.ndarray) and x.size == 1:\n",
        "        return x.item()  # Converts a one-element array to a scalar\n",
        "    return x\n",
        "\n",
        "p_values_df_fwer = p_values_df_fwer.map(to_numeric).round(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6La6m6trvPF",
        "outputId": "82e74c0b-e89f-41d0-8543-117a07eab5b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\\begin{tabular}{@{\\extracolsep{5pt}}lcccccc}\n",
            "\\\\[-1.8ex]\\hline\n",
            "\\hline \\\\[-1.8ex]\n",
            "& \\multicolumn{6}{c}{\\textit{Dependent variable: Inventory Trim}} \\\n",
            "\\cr \\cline{2-7}\n",
            "\\\\[-1.8ex] & \\multicolumn{2}{c}{Y1} & \\multicolumn{2}{c}{Y2} & \\multicolumn{2}{c}{Pooled}  \\\\\n",
            "\\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) & (6) \n",
            " \\\\ & Overall & By rd & Overall & By rd & Overall & By rd \\\\\n",
            "\\hline \\\\[-1.8ex]\n",
            " Treat & 0.574$^{***}$ & & & & & \\\\\n",
            "& (0.140) & & & & & \\\\\n",
            " Treat & & & 0.546$^{***}$ & & & \\\\\n",
            "& & & (0.129) & & & \\\\\n",
            " Treat & & & & & 0.565$^{***}$ & \\\\\n",
            "& & & & & (0.097) & \\\\\n",
            " Treat - R1 & & 0.872$^{***}$ & & 1.242$^{***}$ & & 1.050$^{***}$ \\\\\n",
            "& & (0.276) & & (0.235) & & (0.184) \\\\\n",
            " Treat - R2 & & 0.753$^{***}$ & & 0.304$^{*}$ & & 0.546$^{***}$ \\\\\n",
            "& & (0.171) & & (0.166) & & (0.120) \\\\\n",
            " Treat - R3 & & 0.111$^{}$ & & 0.082$^{}$ & & 0.094$^{}$ \\\\\n",
            "& & (0.083) & & (0.344) & & (0.162) \\\\\n",
            " P-Val Treat & 0.0 &  & 0.0 &  & 0.0 &  \\\\\n",
            " P-Val Treat FWER & 0.0 &  & 0.0 &  & 0.0 &  \\\\\n",
            " P-Val Treat - R1 &  & 0.002 &  & 0.0 &  & 0.0 \\\\\n",
            " P-Val Treat - R1 FWER &  & 0.002 &  & 0.0 &  & 0.0 \\\\\n",
            " P-Val Treat - R2 &  & 0.0 &  & 0.066 &  & 0.0 \\\\\n",
            " P-Val Treat - R2 FWER &  & 0.0 &  & 0.066 &  & 0.0 \\\\\n",
            " P-Val Treat - R3 &  & 0.182 &  & 0.812 &  & 0.561 \\\\\n",
            " P-Val Treat - R3 FWER &  & 0.182 &  & 0.812 &  & 0.561 \\\\\n",
            "\\hline \\\\[-1.8ex]\n",
            " Observations & 3836 & 3836 & 2944 & 2944 & 6780 & 6780 \\\\\n",
            " $R^2$ & 0.365 & 0.368 & 0.098 & 0.215 & 0.144 & 0.329 \\\\\n",
            " % Adjusted $R^2$ & 0.360 & 0.362 & 0.088 & 0.205 & 0.136 & 0.322 \\\\\n",
            " % Residual Std. Error & 2.982 (df=3803) & 2.975 (df=3799) & 2.950 (df=2911) & 2.754 (df=2907) & 3.256 (df=6716) & 2.884 (df=6710) \\\\\n",
            " % F Statistic & 69.431$^{***}$ (df=32; 3803) & 84.886$^{***}$ (df=36; 3799) & 64.996$^{***}$ (df=32; 2911) & 57.574$^{***}$ (df=36; 2907) & 52.508$^{***}$ (df=63; 6716) & 56.147$^{***}$ (df=69; 6710) \\\\\n",
            "\\hline\n",
            "\\hline \\\\[-1.8ex]\n",
            "% \\textit{Note:} & \\multicolumn{6}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\\\\n",
            "\\end{tabular}\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 37, but rank is 36\n",
            "  warnings.warn('covariance of constraints does not have full '\n",
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 37, but rank is 36\n",
            "  warnings.warn('covariance of constraints does not have full '\n",
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 63, but rank is 62\n",
            "  warnings.warn('covariance of constraints does not have full '\n",
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 71, but rank is 68\n",
            "  warnings.warn('covariance of constraints does not have full '\n"
          ]
        }
      ],
      "source": [
        "# creating latex table\n",
        "stargazer_tab2 = Stargazer(results_tab2)\n",
        "\n",
        "stargazer_tab2.custom_columns(['Y1', 'Y2','Pooled'], [2,2,2])\n",
        "stargazer_tab2.significant_digits(3)\n",
        "stargazer_tab2.rename_covariates({'treat12': 'Treat','treat13': 'Treat', 'treatMS1MS2': 'Treat', 'inter_R1': 'Treat - R1', 'inter_R2': 'Treat - R2', 'inter_R3': 'Treat - R3'})\n",
        "stargazer_tab2.covariate_order(['treat12', 'treat13', 'treatMS1MS2', 'inter_R1', 'inter_R2', 'inter_R3'])\n",
        "# adding p-values\n",
        "stargazer_tab2.add_line('P-Val Treat',p_values_df.loc['Treat'].tolist())\n",
        "stargazer_tab2.add_line('P-Val Treat FWER',p_values_df_fwer.loc['Treat'].tolist())\n",
        "stargazer_tab2.add_line('P-Val Treat - R1',p_values_df.loc['inter_R1'].tolist())\n",
        "stargazer_tab2.add_line('P-Val Treat - R1 FWER',p_values_df_fwer.loc['inter_R1'].tolist())\n",
        "stargazer_tab2.add_line('P-Val Treat - R2',p_values_df.loc['inter_R2'].tolist())\n",
        "stargazer_tab2.add_line('P-Val Treat - R2 FWER',p_values_df_fwer.loc['inter_R2'].tolist())\n",
        "stargazer_tab2.add_line('P-Val Treat - R3',p_values_df.loc['inter_R3'].tolist())\n",
        "stargazer_tab2.add_line('P-Val Treat - R3 FWER',p_values_df_fwer.loc['inter_R3'].tolist())\n",
        "\n",
        "\n",
        "latex_table2 = stargazer_tab2.render_latex()\n",
        "\n",
        "latex_table2 = latex_table2.replace(\"\\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) & (6) \\\\\",\n",
        "                                \"\\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) & (6) \\n \\\\\\ & Overall & By rd & Overall & By rd & Overall & By rd \\\\\")\n",
        "latex_table2 = latex_table2.replace(\"Adjusted $R^2$\", \"% Adjusted $R^2$\")\n",
        "latex_table2 = latex_table2.replace(\"Residual Std. Error\", \"% Residual Std. Error\")\n",
        "latex_table2 = latex_table2.replace(\"F Statistic\", \"% F Statistic\")\n",
        "latex_table2 = latex_table2.replace(\"\\\\textit{Note\",\"% \\\\textit{Note\")\n",
        "latex_table2 = latex_table2.replace(\"nan\",\"\")\n",
        "latex_table2 = latex_table2.replace(\"inventory_trim\",\"Inventory Trim\")\n",
        "latex_table2 = latex_table2.replace(\"\\\\begin{table}[!htbp] \\\\centering\", \"\")\n",
        "latex_table2 = latex_table2.replace(\"\\\\end{table}\", \"\")\n",
        "\n",
        "print(latex_table2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MapKqTx56PLs"
      },
      "source": [
        "## Table 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "XUZo0TFS6V_S"
      },
      "outputs": [],
      "source": [
        "# year 1 overall\n",
        "ms1ms2_clean1 = ms1ms2_pooled.loc[:, ['treat12', 'interviewdate1', 'interviewdate', 'Y1round1', 'Y1round2', 'Y1round3', 'treatMS1MS2', 'netrevenue_trim', 'groupnum', 'strata_group', 'round']].dropna()\n",
        "ms1ms2_clean1['inter_R1'] = ms1ms2_clean1['Y1round1'] * ms1ms2_clean1['treat12']\n",
        "ms1ms2_clean1['inter_R2'] = ms1ms2_clean1['Y1round2'] * ms1ms2_clean1['treat12']\n",
        "ms1ms2_clean1['inter_R3'] = ms1ms2_clean1['Y1round3'] * ms1ms2_clean1['treat12']\n",
        "\n",
        "# Example of running a regression for 'inventory_trim' against 'treat12' with control\n",
        "# variables and fixed effects for strata_group and clustering by groupnum\n",
        "\n",
        "# model specification with fixed effects for strata_group\n",
        "model = smf.ols('netrevenue_trim ~ treat12 + interviewdate + C(strata_group)', data=ms1ms2_clean1)\n",
        "\n",
        "# fitting the model with robust standard errors clustered by 'groupnum'\n",
        "results1 = model.fit(cov_type='cluster', cov_kwds={'groups': ms1ms2_clean1['groupnum']})\n",
        "\n",
        "# extract necessary statistics\n",
        "model_params1 = results1.params\n",
        "model_pvalues1 = results1.pvalues\n",
        "mean_dv1 = ms1ms2_clean1['netrevenue_trim'].mean()\n",
        "sd_dv1 = ms1ms2_clean1['netrevenue_trim'].std()\n",
        "\n",
        "# number of tests, include only treat12 and its interaction terms if they exist\n",
        "num_tests = 1 + ('inter_R1' in model_params1) + ('inter_R2' in model_params1) + ('inter_R3' in model_params1)\n",
        "\n",
        "# calculating the Bonferroni corrections for the p-values\n",
        "bonferroni_pvalues1 = {key: multipletests(results1.pvalues[key], method='fdr_bh')[1] for key, val in model_pvalues1.items() if key in ['treat12', 'inter_R1', 'inter_R2', 'inter_R3']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qQhGrlEf66e1"
      },
      "outputs": [],
      "source": [
        "# year 1 by rounds\n",
        "# Similarly, for the models with the interactions (inter_Y1R1, inter_Y1R2, inter_Y1R3):\n",
        "model_interactions = smf.ols('netrevenue_trim ~ inter_R1 + inter_R2 + inter_R3 + interviewdate + C(Y1round1) + C(Y1round2) + C(Y1round3) + C(strata_group)', data=ms1ms2_clean1)\n",
        "results2 = model_interactions.fit(cov_type='cluster', cov_kwds={'groups': ms1ms2_clean1['groupnum']})\n",
        "\n",
        "# extract necessary statistics\n",
        "model_params2 = results2.params\n",
        "model_pvalues2 = results2.pvalues\n",
        "mean_dv2 = ms1ms2_clean1['netrevenue_trim'].mean()\n",
        "sd_dv2 = ms1ms2_clean1['netrevenue_trim'].std()\n",
        "\n",
        "# number of tests, include only treat12 and its interaction terms if they exist\n",
        "num_tests = 1 + ('inter_R1' in model_params2) + ('inter_R2' in model_params2) + ('inter_R3' in model_params2)\n",
        "\n",
        "# calculating the Bonferroni corrections for the p-values\n",
        "bonferroni_pvalues2 = {key: multipletests(results2.pvalues[key], method='fdr_bh')[1] for key, val in model_pvalues2.items() if key in ['inter_R1', 'inter_R2', 'inter_R3']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "2S1aDTrk7kB3"
      },
      "outputs": [],
      "source": [
        "# year 2 overall\n",
        "ms1ms2_clean2 = ms1ms2_pooled.loc[:, ['treat13', 'Y2round1', 'Y2round2', 'Y2round3', 'treatMS1MS2', 'netrevenue_trim', 'interviewdate', 'date', 'strata_group', 'groupnum']].dropna()\n",
        "ms1ms2_clean2['inter_R1'] = ms1ms2_clean2['Y2round1'] * ms1ms2_clean2['treat13']\n",
        "ms1ms2_clean2['inter_R2'] = ms1ms2_clean2['Y2round2'] * ms1ms2_clean2['treat13']\n",
        "ms1ms2_clean2['inter_R3'] = ms1ms2_clean2['Y2round3'] * ms1ms2_clean2['treat13']\n",
        "\n",
        "# model specification with fixed effects for strata_group\n",
        "model = smf.ols('netrevenue_trim ~ treat13 + interviewdate + C(strata_group)', data=ms1ms2_clean2)\n",
        "\n",
        "# fitting the model with robust standard errors clustered by 'groupnum'\n",
        "results3 = model.fit(cov_type='cluster', cov_kwds={'groups': ms1ms2_clean2['groupnum']})\n",
        "\n",
        "# extract necessary statistics\n",
        "model_params3 = results3.params\n",
        "model_pvalues3 = results3.pvalues\n",
        "mean_dv3 = ms1ms2_clean2['netrevenue_trim'].mean()\n",
        "sd_dv3 = ms1ms2_clean2['netrevenue_trim'].std()\n",
        "\n",
        "# number of tests, include only treat12 and its interaction terms if they exist\n",
        "num_tests = 1 + ('inter_R1' in model_params3) + ('inter_R2' in model_params3) + ('inter_R3' in model_params3)\n",
        "\n",
        "# calculating the Bonferroni corrections for the p-values\n",
        "bonferroni_pvalues3 = {key: multipletests(results3.pvalues[key], method='fdr_bh')[1] for key, val in model_pvalues3.items() if key in ['treat13', 'inter_R1', 'inter_R2', 'inter_R3']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ZeiW7KK18ZVa"
      },
      "outputs": [],
      "source": [
        "# year 2 by round\n",
        "# Similarly, for the models with the interactions (inter_Y1R1, inter_Y1R2, inter_Y1R3):\n",
        "model_interactions = smf.ols('netrevenue_trim ~ inter_R1 + inter_R2 + inter_R3 + interviewdate + C(Y2round1) + C(Y2round2) + C(Y2round3) + C(strata_group)', data=ms1ms2_clean2)\n",
        "results4 = model_interactions.fit(cov_type='cluster', cov_kwds={'groups': ms1ms2_clean2['groupnum']})\n",
        "# results4.summary()\n",
        "\n",
        "# extract necessary statistics\n",
        "model_params4 = results4.params\n",
        "model_pvalues4 = results4.pvalues\n",
        "mean_dv4 = ms1ms2_clean2['netrevenue_trim'].mean()\n",
        "sd_dv4 = ms1ms2_clean2['netrevenue_trim'].std()\n",
        "\n",
        "# number of tests, include only treat12 and its interaction terms if they exist\n",
        "num_tests = 1 + ('inter_R1' in model_params4) + ('inter_R2' in model_params4) + ('inter_R3' in model_params4)\n",
        "\n",
        "# calculating the Bonferroni corrections for the p-values\n",
        "bonferroni_pvalues4 = {key: multipletests(results4.pvalues[key], method='fdr_bh')[1] for key, val in model_pvalues4.items() if key in ['treat13', 'inter_R1', 'inter_R2', 'inter_R3']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "84MnerBV_AFO"
      },
      "outputs": [],
      "source": [
        "# pooled overall\n",
        "ms1ms2_clean3 = pd.concat([ms1ms2_clean1, ms1ms2_clean2], ignore_index=True).fillna(0)\n",
        "ms1ms2_clean3.sort_values(by='interviewdate')\n",
        "\n",
        "# model specification with fixed effects for strata_group\n",
        "model = smf.ols('netrevenue_trim ~ treatMS1MS2 + interviewdate + C(strata_group)', data=ms1ms2_clean3)\n",
        "\n",
        "# fitting the model with robust standard errors clustered by 'groupnum'\n",
        "results5 = model.fit(cov_type='cluster', cov_kwds={'groups': ms1ms2_clean3['groupnum']})\n",
        "\n",
        "# extract necessary statistics\n",
        "model_params5 = results5.params\n",
        "model_pvalues5 = results5.pvalues\n",
        "mean_dv5 = ms1ms2_clean3['netrevenue_trim'].mean()\n",
        "sd_dv5 = ms1ms2_clean3['netrevenue_trim'].std()\n",
        "\n",
        "# number of tests, include only treat12 and its interaction terms if they exist\n",
        "num_tests = 1 + ('inter_R1' in model_params5) + ('inter_R2' in model_params5) + ('inter_R3' in model_params5)\n",
        "\n",
        "# calculating the Bonferroni corrections for the p-values\n",
        "bonferroni_pvalues5 = {key: multipletests(results5.pvalues[key], method='fdr_bh')[1] for key, val in model_pvalues5.items() if key in ['treatMS1MS2', 'inter_R1', 'inter_R2', 'inter_R3']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "P729F96J_dkm"
      },
      "outputs": [],
      "source": [
        "# pooled by round\n",
        "# model specification with fixed effects for strata_group\n",
        "model = smf.ols('netrevenue_trim ~ inter_R1 + inter_R2 + inter_R3 + interviewdate + C(Y1round1) + C(Y1round2) + C(Y1round3) + C(Y2round1) + C(Y2round2) + C(Y2round3) + C(strata_group)', data=ms1ms2_clean3)\n",
        "\n",
        "# fitting the model with robust standard errors clustered by 'groupnum'\n",
        "results6 = model.fit(cov_type='cluster', cov_kwds={'groups': ms1ms2_clean3['groupnum']})\n",
        "\n",
        "# extract necessary statistics\n",
        "model_params6 = results6.params\n",
        "model_pvalues6 = results6.pvalues\n",
        "mean_dv6 = ms1ms2_clean3['netrevenue_trim'].mean()\n",
        "sd_dv6 = ms1ms2_clean3['netrevenue_trim'].std()\n",
        "\n",
        "# number of tests, include only treat12 and its interaction terms if they exist\n",
        "num_tests = 1 + ('inter_R1' in model_params6) + ('inter_R2' in model_params6) + ('inter_R3' in model_params6)\n",
        "\n",
        "# calculating the Bonferroni corrections for the p-values\n",
        "bonferroni_pvalues6 = {key: multipletests(results6.pvalues[key], method='fdr_bh')[1] for key, val in model_pvalues6.items() if key in ['inter_R1', 'inter_R2', 'inter_R3']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9K-vg4NuEB3F"
      },
      "outputs": [],
      "source": [
        "# collecting p-values in tables to easily add them to the latex table\n",
        "results_tab3 = [results1,results2,results3,results4,results5,results6]\n",
        "\n",
        "# get p-values for treat12, treat13, treatMS1MS2, inter_R1, inter_R2, inter_R3\n",
        "p_values = {}\n",
        "for result in results_tab3:\n",
        "    p_values[result] = np.round(result.pvalues,3)\n",
        "    p_values_df= pd.DataFrame(p_values)\n",
        "\n",
        "p_values_df = p_values_df.loc[['treat12', 'treat13', 'treatMS1MS2', 'inter_R1', 'inter_R2', 'inter_R3']]\n",
        "p_values_df.columns = ['(1)', '(2)', '(3)', '(4)', '(5)', '(6)']\n",
        "p_values_df.loc['Treat'] = p_values_df.loc[['treat12', 'treat13', 'treatMS1MS2']].mean()\n",
        "p_values_df.drop(['treat12', 'treat13', 'treatMS1MS2'], inplace=True)\n",
        "\n",
        "# fwer correction\n",
        "fwer_p_values = [bonferroni_pvalues1, bonferroni_pvalues2, bonferroni_pvalues3, bonferroni_pvalues4, bonferroni_pvalues5, bonferroni_pvalues6]\n",
        "\n",
        "# get p-values for treat12, treat13, treatMS1MS2, inter_R1, inter_R2, inter_R3\n",
        "p_values_fwer = {}\n",
        "for i, p_values in enumerate(fwer_p_values):\n",
        "    p_values_fwer[i] = p_values\n",
        "    p_values_df_fwer = pd.DataFrame(p_values_fwer)\n",
        "\n",
        "p_values_df_fwer.loc['Treat'] = p_values_df_fwer.loc[['treat12', 'treat13', 'treatMS1MS2']].mean()\n",
        "p_values_df_fwer.drop(['treat12', 'treat13', 'treatMS1MS2'], inplace=True)\n",
        "\n",
        "\n",
        "p_values_df_fwer = p_values_df_fwer.map(to_numeric).round(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nW2kizOwEFRG",
        "outputId": "8799a5e6-268d-4ed0-daf6-a494bb96d624"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\\begin{tabular}{@{\\extracolsep{5pt}}lcccccc}\n",
            "\\\\[-1.8ex]\\hline\n",
            "\\hline \\\\[-1.8ex]\n",
            "& \\multicolumn{6}{c}{\\textit{Dependent variable: Netrevenue Trim}} \\\n",
            "\\cr \\cline{2-7}\n",
            "\\\\[-1.8ex] & \\multicolumn{2}{c}{Y1} & \\multicolumn{2}{c}{Y2} & \\multicolumn{2}{c}{Pooled}  \\\\\n",
            "\\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) & (6) \n",
            " \\\\ & Overall & By rd & Overall & By rd & Overall & By rd \\\\\n",
            "\\hline \\\\[-1.8ex]\n",
            " Treat & 263.790$^{}$ & & & & & \\\\\n",
            "& (255.661) & & & & & \\\\\n",
            " Treat & & & 854.114$^{***}$ & & & \\\\\n",
            "& & & (303.802) & & & \\\\\n",
            " Treat & & & & & 531.358$^{***}$ & \\\\\n",
            "& & & & & (196.315) & \\\\\n",
            " Treat - R1 & & -1164.574$^{***}$ & & 16.478$^{}$ & & -613.581$^{**}$ \\\\\n",
            "& & (322.956) & & (444.957) & & (271.653) \\\\\n",
            " Treat - R2 & & 509.851$^{}$ & & 1994.923$^{***}$ & & 1187.967$^{***}$ \\\\\n",
            "& & (446.928) & & (503.696) & & (337.460) \\\\\n",
            " Treat - R3 & & 1370.344$^{***}$ & & 565.438$^{}$ & & 998.665$^{***}$ \\\\\n",
            "& & (412.602) & & (403.307) & & (291.103) \\\\\n",
            " P-Val Treat & 0.302 &  & 0.005 &  & 0.007 &  \\\\\n",
            " P-Val Treat FWER & 0.302 &  & 0.005 &  & 0.007 &  \\\\\n",
            " P-Val Treat - R1 &  & 0.0 &  & 0.97 &  & 0.024 \\\\\n",
            " P-Val Treat - R1 FWER &  & 0.0 &  & 0.97 &  & 0.024 \\\\\n",
            " P-Val Treat - R2 &  & 0.254 &  & 0.0 &  & 0.0 \\\\\n",
            " P-Val Treat - R2 FWER &  & 0.254 &  & 0.0 &  & 0.0 \\\\\n",
            " P-Val Treat - R3 &  & 0.001 &  & 0.161 &  & 0.001 \\\\\n",
            " P-Val Treat - R3 FWER &  & 0.001 &  & 0.161 &  & 0.001 \\\\\n",
            "\\hline \\\\[-1.8ex]\n",
            " Observations & 3795 & 3795 & 2935 & 2935 & 6730 & 6730 \\\\\n",
            " $R^2$ & 0.025 & 0.038 & 0.074 & 0.079 & 0.107 & 0.119 \\\\\n",
            " % Adjusted $R^2$ & 0.017 & 0.029 & 0.064 & 0.067 & 0.099 & 0.110 \\\\\n",
            " % Residual Std. Error & 6160.285 (df=3762) & 6123.381 (df=3758) & 6332.926 (df=2902) & 6321.436 (df=2898) & 6257.097 (df=6666) & 6218.002 (df=6660) \\\\\n",
            " % F Statistic & 4.652$^{***}$ (df=32; 3762) & 5.786$^{***}$ (df=36; 3758) & 30.217$^{***}$ (df=32; 2902) & 29.094$^{***}$ (df=36; 2898) & 27.156$^{***}$ (df=63; 6666) & 10478661843.432$^{***}$ (df=69; 6660) \\\\\n",
            "\\hline\n",
            "\\hline \\\\[-1.8ex]\n",
            "% \\textit{Note:} & \\multicolumn{6}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\\\\n",
            "\\end{tabular}\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 37, but rank is 36\n",
            "  warnings.warn('covariance of constraints does not have full '\n",
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 37, but rank is 36\n",
            "  warnings.warn('covariance of constraints does not have full '\n",
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 63, but rank is 62\n",
            "  warnings.warn('covariance of constraints does not have full '\n",
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 71, but rank is 68\n",
            "  warnings.warn('covariance of constraints does not have full '\n"
          ]
        }
      ],
      "source": [
        "# creating latex table\n",
        "stargazer_tab3 = Stargazer(results_tab3)\n",
        "\n",
        "stargazer_tab3.custom_columns(['Y1', 'Y2','Pooled'], [2,2,2])\n",
        "stargazer_tab3.significant_digits(3)\n",
        "stargazer_tab3.rename_covariates({'treat12': 'Treat','treat13': 'Treat', 'treatMS1MS2': 'Treat', 'inter_R1': 'Treat - R1', 'inter_R2': 'Treat - R2', 'inter_R3': 'Treat - R3'})\n",
        "stargazer_tab3.covariate_order(['treat12', 'treat13', 'treatMS1MS2', 'inter_R1', 'inter_R2', 'inter_R3'])\n",
        "# adding p-values\n",
        "stargazer_tab3.add_line('P-Val Treat',p_values_df.loc['Treat'].tolist())\n",
        "stargazer_tab3.add_line('P-Val Treat FWER',p_values_df_fwer.loc['Treat'].tolist())\n",
        "stargazer_tab3.add_line('P-Val Treat - R1',p_values_df.loc['inter_R1'].tolist())\n",
        "stargazer_tab3.add_line('P-Val Treat - R1 FWER',p_values_df_fwer.loc['inter_R1'].tolist())\n",
        "stargazer_tab3.add_line('P-Val Treat - R2',p_values_df.loc['inter_R2'].tolist())\n",
        "stargazer_tab3.add_line('P-Val Treat - R2 FWER',p_values_df_fwer.loc['inter_R2'].tolist())\n",
        "stargazer_tab3.add_line('P-Val Treat - R3',p_values_df.loc['inter_R3'].tolist())\n",
        "stargazer_tab3.add_line('P-Val Treat - R3 FWER',p_values_df_fwer.loc['inter_R3'].tolist())\n",
        "\n",
        "\n",
        "latex_table3 = stargazer_tab3.render_latex()\n",
        "\n",
        "latex_table3 = latex_table3.replace(\"\\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) & (6) \\\\\",\n",
        "                                \"\\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) & (6) \\n \\\\\\ & Overall & By rd & Overall & By rd & Overall & By rd \\\\\")\n",
        "latex_table3 = latex_table3.replace(\"Adjusted $R^2$\", \"% Adjusted $R^2$\")\n",
        "latex_table3 = latex_table3.replace(\"Residual Std. Error\", \"% Residual Std. Error\")\n",
        "latex_table3 = latex_table3.replace(\"F Statistic\", \"% F Statistic\")\n",
        "latex_table3 = latex_table3.replace(\"\\\\textit{Note\",\"% \\\\textit{Note\")\n",
        "latex_table3 = latex_table3.replace(\"nan\",\"\")\n",
        "latex_table3 = latex_table3.replace(\"netrevenue_trim\",\"Netrevenue Trim\")\n",
        "latex_table3 = latex_table3.replace(\"\\\\begin{table}[!htbp] \\\\centering\", \"\")\n",
        "latex_table3 = latex_table3.replace(\"\\\\end{table}\", \"\")\n",
        "\n",
        "print(latex_table3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFcatyv4Dk08"
      },
      "source": [
        "## Table 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "vm-n7nFMDiSQ"
      },
      "outputs": [],
      "source": [
        "# year 1 overall\n",
        "ms1ms2_clean1 = ms1ms2_pooled.loc[:, ['treat12', 'interviewdate1', 'interviewdate', 'Y1round1', 'Y1round2', 'Y1round3', 'treatMS1MS2', 'logtotcons_trim', 'groupnum', 'strata_group', 'round']].dropna()\n",
        "ms1ms2_clean1['inter_R1'] = ms1ms2_clean1['Y1round1'] * ms1ms2_clean1['treat12']\n",
        "ms1ms2_clean1['inter_R2'] = ms1ms2_clean1['Y1round2'] * ms1ms2_clean1['treat12']\n",
        "ms1ms2_clean1['inter_R3'] = ms1ms2_clean1['Y1round3'] * ms1ms2_clean1['treat12']\n",
        "\n",
        "# model specification with fixed effects for strata_group\n",
        "model = smf.ols('logtotcons_trim ~ treat12 + interviewdate + C(strata_group)', data=ms1ms2_clean1)\n",
        "\n",
        "# fitting the model with robust standard errors clustered by 'groupnum'\n",
        "results1 = model.fit(cov_type='cluster', cov_kwds={'groups': ms1ms2_clean1['groupnum']})\n",
        "\n",
        "# Extract necessary statistics\n",
        "model_params1 = results1.params\n",
        "model_pvalues1 = results1.pvalues\n",
        "mean_dv1 = ms1ms2_clean1['logtotcons_trim'].mean()\n",
        "sd_dv1 = ms1ms2_clean1['logtotcons_trim'].std()\n",
        "\n",
        "# Number of tests, include only treat12 and its interaction terms if they exist\n",
        "num_tests = 1 + ('inter_R1' in model_params1) + ('inter_R2' in model_params1) + ('inter_R3' in model_params1)\n",
        "\n",
        "# Calculating the Bonferroni corrections for the p-values\n",
        "bonferroni_pvalues1 = {key: multipletests(results1.pvalues[key], method='fdr_bh')[1] for key, val in model_pvalues1.items() if key in ['treat12', 'inter_R1', 'inter_R2', 'inter_R3']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "emC8iS0mNYWb"
      },
      "outputs": [],
      "source": [
        "# year 1 by round\n",
        "model_interactions = smf.ols('logtotcons_trim ~ inter_R1 + inter_R2 + inter_R3 + interviewdate + C(Y1round1) + C(Y1round2) + C(Y1round3) + C(strata_group)', data=ms1ms2_clean1)\n",
        "results2 = model_interactions.fit(cov_type='cluster', cov_kwds={'groups': ms1ms2_clean1['groupnum']})\n",
        "\n",
        "# Extract necessary statistics\n",
        "model_params2 = results2.params\n",
        "model_pvalues2 = results2.pvalues\n",
        "mean_dv2 = ms1ms2_clean1['logtotcons_trim'].mean()\n",
        "sd_dv2 = ms1ms2_clean1['logtotcons_trim'].std()\n",
        "\n",
        "# Number of tests, include only treat12 and its interaction terms if they exist\n",
        "num_tests = 1 + ('inter_R1' in model_params2) + ('inter_R2' in model_params2) + ('inter_R3' in model_params2)\n",
        "\n",
        "# Calculating the Bonferroni corrections for the p-values\n",
        "bonferroni_pvalues2 = {key: multipletests(results2.pvalues[key], method='fdr_bh')[1] for key, val in model_pvalues2.items() if key in ['inter_R1', 'inter_R2', 'inter_R3']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "6Jy74NvxNqmO"
      },
      "outputs": [],
      "source": [
        "# year 2 overall\n",
        "ms1ms2_clean2 = ms1ms2_pooled.loc[:, ['treat13', 'Y2round1', 'Y2round2', 'Y2round3', 'treatMS1MS2', 'logtotcons_trim', 'interviewdate', 'date', 'strata_group', 'groupnum']].dropna()\n",
        "ms1ms2_clean2['inter_R1'] = ms1ms2_clean2['Y2round1'] * ms1ms2_clean2['treat13']\n",
        "ms1ms2_clean2['inter_R2'] = ms1ms2_clean2['Y2round2'] * ms1ms2_clean2['treat13']\n",
        "ms1ms2_clean2['inter_R3'] = ms1ms2_clean2['Y2round3'] * ms1ms2_clean2['treat13']\n",
        "\n",
        "# model specification with fixed effects for strata_group\n",
        "model = smf.ols('logtotcons_trim ~ treat13 + interviewdate + C(strata_group)', data=ms1ms2_clean2)\n",
        "\n",
        "# fitting the model with robust standard errors clustered by 'groupnum'\n",
        "results3 = model.fit(cov_type='cluster', cov_kwds={'groups': ms1ms2_clean2['groupnum']})\n",
        "\n",
        "# Extract necessary statistics\n",
        "model_params3 = results3.params\n",
        "model_pvalues3 = results3.pvalues\n",
        "mean_dv3 = ms1ms2_clean2['logtotcons_trim'].mean()\n",
        "sd_dv3 = ms1ms2_clean2['logtotcons_trim'].std()\n",
        "\n",
        "# number of tests, include only treat12 and its interaction terms if they exist\n",
        "num_tests = 1 + ('inter_R1' in model_params3) + ('inter_R2' in model_params3) + ('inter_R3' in model_params3)\n",
        "\n",
        "# calculating the Bonferroni corrections for the p-values\n",
        "bonferroni_pvalues3 = {key: multipletests(results3.pvalues[key], method='fdr_bh')[1] for key, val in model_pvalues3.items() if key in ['treat13', 'inter_R1', 'inter_R2', 'inter_R3']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "wjdhLgKJNx38"
      },
      "outputs": [],
      "source": [
        "# year 2 by round\n",
        "model_interactions = smf.ols('logtotcons_trim ~ inter_R1 + inter_R2 + inter_R3 + interviewdate + C(Y2round1) + C(Y2round2) + C(Y2round3) + C(strata_group)', data=ms1ms2_clean2)\n",
        "results4 = model_interactions.fit(cov_type='cluster', cov_kwds={'groups': ms1ms2_clean2['groupnum']})\n",
        "\n",
        "# extract necessary statistics\n",
        "model_params4 = results4.params\n",
        "model_pvalues4 = results4.pvalues\n",
        "mean_dv4 = ms1ms2_clean2['logtotcons_trim'].mean()\n",
        "sd_dv4 = ms1ms2_clean2['logtotcons_trim'].std()\n",
        "\n",
        "# number of tests, include only treat12 and its interaction terms if they exist\n",
        "num_tests = 1 + ('inter_R1' in model_params4) + ('inter_R2' in model_params4) + ('inter_R3' in model_params4)\n",
        "\n",
        "# calculating the Bonferroni corrections for the p-values\n",
        "bonferroni_pvalues4 = {key: multipletests(results4.pvalues[key], method='fdr_bh')[1] for key, val in model_pvalues4.items() if key in ['treat13', 'inter_R1', 'inter_R2', 'inter_R3']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "NhjKAz2sOUlj"
      },
      "outputs": [],
      "source": [
        "# pooled overall\n",
        "ms1ms2_clean3 = pd.concat([ms1ms2_clean1, ms1ms2_clean2], ignore_index=True).fillna(0)\n",
        "ms1ms2_clean3.sort_values(by='interviewdate')\n",
        "\n",
        "# model specification with fixed effects for strata_group\n",
        "model = smf.ols('logtotcons_trim ~ treatMS1MS2 + interviewdate + C(strata_group)', data=ms1ms2_clean3)\n",
        "\n",
        "# fitting the model with robust standard errors clustered by 'groupnum'\n",
        "results5 = model.fit(cov_type='cluster', cov_kwds={'groups': ms1ms2_clean3['groupnum']})\n",
        "\n",
        "\n",
        "# extract necessary statistics\n",
        "model_params5 = results5.params\n",
        "observations5 = len(ms1ms2_clean3)\n",
        "mean_dv5 = ms1ms2_clean3['logtotcons_trim'].mean()\n",
        "sd_dv5 = ms1ms2_clean3['logtotcons_trim'].std()\n",
        "\n",
        "# number of tests, include only treat12 and its interaction terms if they exist\n",
        "num_tests = 1 + ('inter_R1' in model_params5) + ('inter_R2' in model_params5) + ('inter_R3' in model_params5)\n",
        "\n",
        "# calculating the Bonferroni corrections for the p-values\n",
        "bonferroni_pvalues5 = {key: multipletests(results5.pvalues[key], method='fdr_bh')[1] for key, val in model_pvalues5.items() if key in ['treatMS1MS2', 'inter_R1', 'inter_R2', 'inter_R3']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "8SlQkenSOeUc"
      },
      "outputs": [],
      "source": [
        "# pooled by round\n",
        "# model specification with fixed effects for strata_group\n",
        "model = smf.ols('logtotcons_trim ~ inter_R1 + inter_R2 + inter_R3 + interviewdate + C(Y1round1) + C(Y1round2) + C(Y1round3) + C(Y2round1) + C(Y2round2) + C(Y2round3) + C(strata_group)', data=ms1ms2_clean3)\n",
        "\n",
        "# fitting the model with robust standard errors clustered by 'groupnum'\n",
        "results6 = model.fit(cov_type='cluster', cov_kwds={'groups': ms1ms2_clean3['groupnum']})\n",
        "\n",
        "# extract necessary statistics\n",
        "model_params6 = results6.params\n",
        "model_pvalues6 = results6.pvalues\n",
        "mean_dv6 = ms1ms2_clean3['logtotcons_trim'].mean()\n",
        "sd_dv6 = ms1ms2_clean3['logtotcons_trim'].std()\n",
        "\n",
        "# number of tests, include only treat12 and its interaction terms if they exist\n",
        "num_tests = 1 + ('inter_R1' in model_params6) + ('inter_R2' in model_params6) + ('inter_R3' in model_params6)\n",
        "\n",
        "# calculating the Bonferroni corrections for the p-values\n",
        "bonferroni_pvalues6 = {key: multipletests(results6.pvalues[key], method='fdr_bh')[1] for key, val in model_pvalues6.items() if key in ['inter_R1', 'inter_R2', 'inter_R3']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "wot_lavVE979"
      },
      "outputs": [],
      "source": [
        "# collecting p-values in tables to easily add them to the latex table\n",
        "results_tab4 = [results1,results2,results3,results4,results5,results6]\n",
        "\n",
        "# get p-values for treat12, treat13, treatMS1MS2, inter_R1, inter_R2, inter_R3\n",
        "p_values = {}\n",
        "for result in results_tab4:\n",
        "    p_values[result] = np.round(result.pvalues,3)\n",
        "    p_values_df= pd.DataFrame(p_values)\n",
        "\n",
        "p_values_df = p_values_df.loc[['treat12', 'treat13', 'treatMS1MS2', 'inter_R1', 'inter_R2', 'inter_R3']]\n",
        "p_values_df.columns = ['(1)', '(2)', '(3)', '(4)', '(5)', '(6)']\n",
        "p_values_df.loc['Treat'] = p_values_df.loc[['treat12', 'treat13', 'treatMS1MS2']].mean()\n",
        "p_values_df.drop(['treat12', 'treat13', 'treatMS1MS2'], inplace=True)\n",
        "\n",
        "# fwer correction\n",
        "fwer_p_values = [bonferroni_pvalues1, bonferroni_pvalues2, bonferroni_pvalues3, bonferroni_pvalues4, bonferroni_pvalues5, bonferroni_pvalues6]\n",
        "\n",
        "# get p-values for treat12, treat13, treatMS1MS2, inter_R1, inter_R2, inter_R3\n",
        "p_values_fwer = {}\n",
        "for i, p_values in enumerate(fwer_p_values):\n",
        "    p_values_fwer[i] = p_values\n",
        "    p_values_df_fwer = pd.DataFrame(p_values_fwer)\n",
        "\n",
        "p_values_df_fwer.loc['Treat'] = p_values_df_fwer.loc[['treat12', 'treat13', 'treatMS1MS2']].mean()\n",
        "p_values_df_fwer.drop(['treat12', 'treat13', 'treatMS1MS2'], inplace=True)\n",
        "\n",
        "# changeing everything to numeric and rounding\n",
        "p_values_df_fwer = p_values_df_fwer.map(to_numeric).round(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQIGcHsYE_qW",
        "outputId": "004417c2-60a2-4a78-d98a-b9dbdcf68823"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\\begin{tabular}{@{\\extracolsep{5pt}}lcccccc}\n",
            "\\\\[-1.8ex]\\hline\n",
            "\\hline \\\\[-1.8ex]\n",
            "& \\multicolumn{6}{c}{\\textit{Dependent variable: Log Total HH Consumption Trim}} \\\n",
            "\\cr \\cline{2-7}\n",
            "\\\\[-1.8ex] & \\multicolumn{2}{c}{Y1} & \\multicolumn{2}{c}{Y2} & \\multicolumn{2}{c}{Pooled}  \\\\\n",
            "\\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) & (6) \n",
            " \\\\ & Overall & By rd & Overall & By rd & Overall & By rd \\\\\n",
            "\\hline \\\\[-1.8ex]\n",
            " Treat & 0.012$^{}$ & & & & & \\\\\n",
            "& (0.030) & & & & & \\\\\n",
            " Treat & & & 0.064$^{*}$ & & & \\\\\n",
            "& & & (0.036) & & & \\\\\n",
            " Treat & & & & & 0.036$^{}$ & \\\\\n",
            "& & & & & (0.023) & \\\\\n",
            " Treat - R1 & & -0.033$^{}$ & & 0.064$^{}$ & & 0.013$^{}$ \\\\\n",
            "& & (0.047) & & (0.047) & & (0.033) \\\\\n",
            " Treat - R2 & & 0.028$^{}$ & & 0.076$^{*}$ & & 0.049$^{*}$ \\\\\n",
            "& & (0.039) & & (0.043) & & (0.029) \\\\\n",
            " Treat - R3 & & 0.038$^{}$ & & 0.052$^{}$ & & 0.044$^{}$ \\\\\n",
            "& & (0.042) & & (0.047) & & (0.031) \\\\\n",
            " P-Val Treat & 0.683 &  & 0.08 &  & 0.126 &  \\\\\n",
            " P-Val Treat FWER & 0.683 &  & 0.08 &  & 0.126 &  \\\\\n",
            " P-Val Treat - R1 &  & 0.486 &  & 0.171 &  & 0.687 \\\\\n",
            " P-Val Treat - R1 FWER &  & 0.486 &  & 0.171 &  & 0.687 \\\\\n",
            " P-Val Treat - R2 &  & 0.481 &  & 0.075 &  & 0.088 \\\\\n",
            " P-Val Treat - R2 FWER &  & 0.481 &  & 0.075 &  & 0.088 \\\\\n",
            " P-Val Treat - R3 &  & 0.364 &  & 0.27 &  & 0.164 \\\\\n",
            " P-Val Treat - R3 FWER &  & 0.364 &  & 0.27 &  & 0.164 \\\\\n",
            "\\hline \\\\[-1.8ex]\n",
            " Observations & 3792 & 3792 & 2944 & 2944 & 6736 & 6736 \\\\\n",
            " $R^2$ & 0.026 & 0.027 & 0.051 & 0.053 & 0.055 & 0.056 \\\\\n",
            " % Adjusted $R^2$ & 0.018 & 0.018 & 0.041 & 0.041 & 0.046 & 0.046 \\\\\n",
            " % Residual Std. Error & 0.615 (df=3759) & 0.615 (df=3755) & 0.638 (df=2911) & 0.638 (df=2907) & 0.625 (df=6672) & 0.625 (df=6666) \\\\\n",
            " % F Statistic & 21.960$^{***}$ (df=32; 3759) & 21.858$^{***}$ (df=36; 3755) & 250.735$^{***}$ (df=32; 2911) & 65.033$^{***}$ (df=36; 2907) & 23.128$^{***}$ (df=63; 6672) & 21.830$^{***}$ (df=69; 6666) \\\\\n",
            "\\hline\n",
            "\\hline \\\\[-1.8ex]\n",
            "% \\textit{Note:} & \\multicolumn{6}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\\\\n",
            "\\end{tabular}\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 37, but rank is 36\n",
            "  warnings.warn('covariance of constraints does not have full '\n",
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 37, but rank is 36\n",
            "  warnings.warn('covariance of constraints does not have full '\n",
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 63, but rank is 62\n",
            "  warnings.warn('covariance of constraints does not have full '\n",
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 71, but rank is 68\n",
            "  warnings.warn('covariance of constraints does not have full '\n"
          ]
        }
      ],
      "source": [
        "# creating latex table\n",
        "stargazer_tab4 = Stargazer(results_tab4)\n",
        "\n",
        "stargazer_tab4.custom_columns(['Y1', 'Y2','Pooled'], [2,2,2])\n",
        "stargazer_tab4.significant_digits(3)\n",
        "stargazer_tab4.rename_covariates({'treat12': 'Treat','treat13': 'Treat', 'treatMS1MS2': 'Treat', 'inter_R1': 'Treat - R1', 'inter_R2': 'Treat - R2', 'inter_R3': 'Treat - R3'})\n",
        "stargazer_tab4.covariate_order(['treat12', 'treat13', 'treatMS1MS2', 'inter_R1', 'inter_R2', 'inter_R3'])\n",
        "# adding p-values\n",
        "stargazer_tab4.add_line('P-Val Treat',p_values_df.loc['Treat'].tolist())\n",
        "stargazer_tab4.add_line('P-Val Treat FWER',p_values_df_fwer.loc['Treat'].tolist())\n",
        "stargazer_tab4.add_line('P-Val Treat - R1',p_values_df.loc['inter_R1'].tolist())\n",
        "stargazer_tab4.add_line('P-Val Treat - R1 FWER',p_values_df_fwer.loc['inter_R1'].tolist())\n",
        "stargazer_tab4.add_line('P-Val Treat - R2',p_values_df.loc['inter_R2'].tolist())\n",
        "stargazer_tab4.add_line('P-Val Treat - R2 FWER',p_values_df_fwer.loc['inter_R2'].tolist())\n",
        "stargazer_tab4.add_line('P-Val Treat - R3',p_values_df.loc['inter_R3'].tolist())\n",
        "stargazer_tab4.add_line('P-Val Treat - R3 FWER',p_values_df_fwer.loc['inter_R3'].tolist())\n",
        "\n",
        "\n",
        "latex_table4 = stargazer_tab4.render_latex()\n",
        "\n",
        "latex_table4 = latex_table4.replace(\"\\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) & (6) \\\\\",\n",
        "                                \"\\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) & (6) \\n \\\\\\ & Overall & By rd & Overall & By rd & Overall & By rd \\\\\")\n",
        "latex_table4 = latex_table4.replace(\"Adjusted $R^2$\", \"% Adjusted $R^2$\")\n",
        "latex_table4 = latex_table4.replace(\"Residual Std. Error\", \"% Residual Std. Error\")\n",
        "latex_table4 = latex_table4.replace(\"F Statistic\", \"% F Statistic\")\n",
        "latex_table4 = latex_table4.replace(\"\\\\textit{Note\",\"% \\\\textit{Note\")\n",
        "latex_table4 = latex_table4.replace(\"nan\",\"\")\n",
        "latex_table4 = latex_table4.replace(\"logtotcons_trim\",\"Log Total HH Consumption Trim\")\n",
        "latex_table4 = latex_table4.replace(\"\\\\begin{table}[!htbp] \\\\centering\", \"\")\n",
        "latex_table4 = latex_table4.replace(\"\\\\end{table}\", \"\")\n",
        "\n",
        "print(latex_table4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFWCk0Ja1NUj"
      },
      "source": [
        "## Table 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zBq_dQh4f4t"
      },
      "source": [
        "### Clean the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "hKjmh5Sc4Zuu"
      },
      "outputs": [],
      "source": [
        "ms1ms2_pooled_tab5 = ms1ms2_pooled.copy(deep=True)\n",
        "max_strata_group = ms1ms2_pooled_tab5['strata_group'].max()\n",
        "ms1ms2_pooled_tab5.loc[ms1ms2_pooled_tab5['MS'] == 2, 'strata_group'] = ms1ms2_pooled_tab5['groupstrata'] + max_strata_group\n",
        "\n",
        "ms1ms2_pooled_tab5.loc[ms1ms2_pooled_tab5['MS'] == 2, 'oafid'] = ms1ms2_pooled_tab5['fr_id']\n",
        "\n",
        "ms1ms2_pooled_tab5['purchasequant2'] = ms1ms2_pooled_tab5['purchasequant']\n",
        "ms1ms2_pooled_tab5.loc[(ms1ms2_pooled_tab5['purchaseval']==0)&(ms1ms2_pooled_tab5['purchasequant'].isna()),'purchasequant2'] = 0\n",
        "ms1ms2_pooled_tab5['netsales2'] = ms1ms2_pooled_tab5['salesquant'] - ms1ms2_pooled_tab5['purchasequant2']\n",
        "ms1ms2_pooled_tab5['netsales'] = ms1ms2_pooled_tab5['netsales2']\n",
        "\n",
        "ms1ms2_pooled_tab5.drop(columns=['netsales_trim','purchaseval_trim','salesval_trim'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "CH5lm8Ib4bbO"
      },
      "outputs": [],
      "source": [
        "# trim outliers\n",
        "for x in ['purchaseval', 'salesval', 'purchasequant', 'salesquant']:\n",
        "    quantile = ms1ms2_pooled_tab5[x].quantile([0.99])\n",
        "    ms1ms2_pooled_tab5[f'{x}_trim'] = ms1ms2_pooled_tab5[x]\n",
        "    ms1ms2_pooled_tab5.loc[ms1ms2_pooled_tab5[f'{x}_trim'] > quantile[0.99],f'{x}_trim'] = np.nan\n",
        "\n",
        "quantile = ms1ms2_pooled_tab5['netsales'].quantile([0.005, 0.995])\n",
        "ms1ms2_pooled_tab5['netsales_trim'] = ms1ms2_pooled_tab5['netsales']\n",
        "ms1ms2_pooled_tab5.loc[(ms1ms2_pooled_tab5['netsales_trim'] <= quantile[0.005]) | (ms1ms2_pooled_tab5['netsales_trim'] > quantile[0.995]) , 'netsales_trim'] = np.nan\n",
        "\n",
        "# create id\n",
        "ms1ms2_pooled_tab5['id'] = ms1ms2_pooled_tab5['oafid'].fillna(ms1ms2_pooled_tab5['fr_id'])\n",
        "\n",
        "# create effective prices\n",
        "trim_vars = ['salesquant_trim', 'purchasequant_trim', 'salesval_trim', 'purchaseval_trim']\n",
        "for var in trim_vars:\n",
        "    ms1ms2_pooled_tab5[f'tot_{var}'] = ms1ms2_pooled_tab5.groupby(['id', 'MS'])[var].transform('sum')\n",
        "\n",
        "for x in ['purchase', 'sales']:\n",
        "    ms1ms2_pooled_tab5[f'effective_{x}_price'] = ms1ms2_pooled_tab5[f'tot_{x}val_trim'] / ms1ms2_pooled_tab5[f'tot_{x}quant_trim']\n",
        "    ms1ms2_pooled_tab5.loc[ms1ms2_pooled_tab5[f'tot_{x}quant_trim']== 0,f'effective_{x}_price'] = np.nan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NggiH6H4jkZ"
      },
      "source": [
        "### Net Sales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "fyNON6b14c0Q"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "\n",
        "# define variable\n",
        "dv = 'netsales_trim'\n",
        "independent_vars = ['z', 'treatMS1MS2_1 + treatMS1MS2_2 + treatMS1MS2_3']\n",
        "\n",
        "for i, var in enumerate(independent_vars):\n",
        "    df = ms1ms2_pooled_tab5.copy(deep=True)\n",
        "    df['z'] = df['treatMS1MS2']\n",
        "    if var == 'z':\n",
        "        df.dropna(subset=[dv,'z','interviewdate','Y1round2','Y1round3','Y2round1','Y2round2','Y2round3','strata_group','groupnum'], inplace=True)\n",
        "    else:\n",
        "        df.dropna(subset=[dv,'treatMS1MS2_1','treatMS1MS2_2','treatMS1MS2_3','interviewdate','Y1round2','Y1round3','Y2round1','Y2round2','Y2round3','strata_group','groupnum'], inplace=True)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    formula = f'{dv} ~ {var} + interviewdate + Y1round2 + Y1round3 + Y2round1 + Y2round2 + Y2round3 + C(strata_group)'\n",
        "    model = smf.ols(formula, df).fit(cov_type='cluster', cov_kwds={'groups': df['groupnum']})\n",
        "    mean_dev = df.loc[df['treatMS1MS2'] == 0, dv].mean()\n",
        "    std_dev = df.loc[df['treatMS1MS2'] == 0, dv].std()\n",
        "    fwer_pvals = multipletests(model.pvalues, method='fdr_bh')[1]\n",
        "    results[f'netsales_{i}'] = {'model':model, 'mean_dev':mean_dev, 'std_dev':std_dev, 'fwer_pvals':fwer_pvals}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvFmwVf04lSt"
      },
      "source": [
        "### Effective Price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "yhKee4CM4exT"
      },
      "outputs": [],
      "source": [
        "for dv in ['purchase', 'sales']:\n",
        "    for i, treat in enumerate(['treat12', 'treat13', 'treatMS1MS2']):\n",
        "        df = ms1ms2_pooled_tab5.copy(deep=True)\n",
        "        df['z'] = df[treat]\n",
        "        df = df.drop_duplicates(subset=['id', 'MS'], keep='first')\n",
        "        df.dropna(subset=[f'effective_{dv}_price','z','groupnum'], inplace=True)\n",
        "        if treat == 'treatMS1MS2':\n",
        "            formula = f'effective_{dv}_price ~ z + C(strata_group)'\n",
        "        else:\n",
        "            df = df[df['MS'] == i+1]\n",
        "            formula = f'effective_{dv}_price ~ z + C(strata_group)'\n",
        "        model = smf.ols(formula, data=df).fit(cov_type='cluster', cov_kwds={'groups': df['groupnum']})\n",
        "        mean_dev = df.loc[df['z'] == 0, f'effective_{dv}_price'].mean()\n",
        "        std_dev = df.loc[df['z'] == 0, f'effective_{dv}_price'].std()\n",
        "        fwer_pvals = multipletests(model.pvalues['z'], method='fdr_bh')[1]\n",
        "        results[f'{dv}_{treat}'] = {'model':model, 'mean_dev':mean_dev, 'std_dev':std_dev, 'fwer_pvals':fwer_pvals}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CfKLPeP4nni"
      },
      "source": [
        "### LaTeX output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "-fnaff3b4uAV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\\begin{tabular}{@{\\extracolsep{5pt}}lcccc}\n",
            "\\\\[-1.8ex]\\hline\n",
            "\\hline \\\\[-1.8ex]\n",
            "\\\\[-1.8ex] & \\multicolumn{2}{c}{Net Sales} & \\multicolumn{2}{c}{Effective Price}  \\\\\n",
            "\\\\[-1.8ex] & (1) & (2) & (3) & (4) \n",
            " \\\\ & Overall & By rd & Purchase & Sales \\\\\n",
            "\\hline \\\\[-1.8ex]\n",
            " Treat & 0.193$^{***}$ & & -57.449$^{**}$ & 145.509$^{***}$ \\\\\n",
            "& (0.064) & & (27.156) & (41.767) \\\\\n",
            " Treat - R1 & & -0.173$^{*}$ & & \\\\\n",
            "& & (0.095) & & \\\\\n",
            " Treat - R2 & & 0.376$^{***}$ & & \\\\\n",
            "& & (0.102) & & \\\\\n",
            " Treat - R3 & & 0.366$^{***}$ & & \\\\\n",
            "& & (0.091) & & \\\\\n",
            " P-value Treat &  &  & 0.034 & 0.0 \\\\\n",
            " P-value Treat FWER &  &  & 0.034 & 0.0 \\\\\n",
            "\\hline \\\\[-1.8ex]\n",
            " Observations & 6736 & 6736 & 2014 & 1428 \\\\\n",
            " $R^2$ & 0.100 & 0.104 & 0.089 & 0.066 \\\\\n",
            " % Adjusted $R^2$ & 0.091 & 0.094 & 0.060 & 0.024 \\\\\n",
            " % Residual Std. Error & 1.998 & 1.994 & 639.432 & 789.099 \\\\\n",
            " % F Statistic & 33.380$^{***}$ & 2.850$^{***}$ & 34.249$^{***}$ & 13.002$^{***}$ \\\\\n",
            "\\hline\n",
            "\\hline \\\\[-1.8ex]\n",
            "% \\textit{Note:} & \\multicolumn{4}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\\\\n",
            "\\end{tabular}\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 68, but rank is 66\n",
            "  warnings.warn('covariance of constraints does not have full '\n",
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 70, but rank is 68\n",
            "  warnings.warn('covariance of constraints does not have full '\n",
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 62, but rank is 61\n",
            "  warnings.warn('covariance of constraints does not have full '\n",
            "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 62, but rank is 61\n",
            "  warnings.warn('covariance of constraints does not have full '\n"
          ]
        }
      ],
      "source": [
        "models_list = ['netsales_0','netsales_1','purchase_treatMS1MS2','sales_treatMS1MS2']\n",
        "stargazer = Stargazer([results[model]['model'] for model in models_list])\n",
        "\n",
        "# get p-values\n",
        "pvals = np.round(pd.DataFrame({model:results[model]['model'].pvalues for model in ['purchase_treatMS1MS2','sales_treatMS1MS2']}),3)\n",
        "fwer_pvals = np.round(pd.DataFrame({model:results[model]['fwer_pvals'] for model in ['purchase_treatMS1MS2','sales_treatMS1MS2']}),3)\n",
        "# rename columns\n",
        "for i, df in enumerate([pvals, fwer_pvals]):\n",
        "    df.columns = ['Purchase', 'Sales']\n",
        "    df['Overall'] = \"\"\n",
        "    df['By rd'] = \"\"\n",
        "    # reorder columns\n",
        "    if i == 0:\n",
        "        pvals = df[['Overall', 'By rd', 'Purchase', 'Sales']]\n",
        "    else:\n",
        "        fwer_pvals = df[['Overall', 'By rd', 'Purchase', 'Sales']]\n",
        "\n",
        "# configure Stargazer object for output\n",
        "stargazer.custom_columns(['Net Sales', 'Effective Price'], [2, 2])\n",
        "stargazer.rename_covariates({'z': 'Treat','treatMS1MS2_1':'Treat - R1', 'treatMS1MS2_2':'Treat - R2', 'treatMS1MS2_3':'Treat - R3'})\n",
        "stargazer.show_degrees_of_freedom(False)\n",
        "stargazer.significant_digits(3)\n",
        "stargazer.covariate_order(['z', 'treatMS1MS2_1', 'treatMS1MS2_2', 'treatMS1MS2_3'])\n",
        "# add p-values as a rows\n",
        "stargazer.add_line('P-value Treat', pvals.loc['z'].values.tolist())\n",
        "stargazer.add_line('P-value Treat FWER', fwer_pvals.loc[0].values.tolist())\n",
        "\n",
        "latex_table5 = stargazer.render_latex()\n",
        "latex_table5 = latex_table5.replace(\"\\\\[-1.8ex] & (1) & (2) & (3) & (4) \\\\\",\n",
        "                                \"\\\\[-1.8ex] & (1) & (2) & (3) & (4) \\n \\\\\\ & Overall & By rd & Purchase & Sales \\\\\")\n",
        "latex_table5 = latex_table5.replace(\"Adjusted $R^2$\", \"% Adjusted $R^2$\")\n",
        "latex_table5 = latex_table5.replace(\"Residual Std. Error\", \"% Residual Std. Error\")\n",
        "latex_table5 = latex_table5.replace(\"F Statistic\", \"% F Statistic\")\n",
        "latex_table5 = latex_table5.replace(\"\\\\textit{Note\",\"% \\\\textit{Note\")\n",
        "latex_table5 = latex_table5.replace(\"\\\\begin{table}[!htbp] \\\\centering\", \"\")\n",
        "latex_table5 = latex_table5.replace(\"\\\\end{table}\", \"\")\n",
        "\n",
        "print(latex_table5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA65rIF8J8Bc"
      },
      "source": [
        "## Table 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "bxbZzoqaJ373"
      },
      "outputs": [],
      "source": [
        "cleanpricedata_y1y2_tab6 = cleanpricedata_y1y2.copy(deep=True)\n",
        "cleanpricedata_y1y2_tab6 = cleanpricedata_y1y2_tab6[['salesPrice_trim','hi_1km_wt','hi_3km_wt','hi_5km_wt','monthnum','subloc_1km_wt_grp','subloc_3km_wt_grp','subloc_5km_wt_grp', 'in_sample','MS','lean']]\n",
        "cleanpricedata_y1y2_tab6['hi'] = pd.NA\n",
        "cleanpricedata_y1y2_tab6['interact'] = pd.NA\n",
        "cleanpricedata_y1y2_tab6['interact_lean'] = pd.NA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "l2T6HDAFA_Ji"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "for dist in ['1km_wt', '3km_wt', '5km_wt']:\n",
        "    df = cleanpricedata_y1y2_tab6.copy(deep=True)\n",
        "    df.dropna(subset=[f'hi_{dist}','salesPrice_trim','monthnum'], inplace=True)\n",
        "    mean_price = df[(df['monthnum'] == 0) & (df[f'hi_{dist}'] == 0)]['salesPrice_trim'].mean()\n",
        "    norm = 100 / mean_price\n",
        "\n",
        "    # normalize price\n",
        "    df['salesPrice_trim_norm'] = df['salesPrice_trim'] * norm\n",
        "\n",
        "    # create hi variable\n",
        "    df['hi'] = df[f'hi_{dist}']\n",
        "    df['interact'] = df['monthnum'] * df['hi']\n",
        "\n",
        "    # regression\n",
        "    formula = 'salesPrice_trim_norm ~ hi + monthnum + interact'\n",
        "\n",
        "    for ms in [1,2,3]: # 3 is pooled\n",
        "        if ms == 3:\n",
        "            df_filt = df[(df['in_sample'] == 1)]\n",
        "        else:\n",
        "            df_filt = df[(df['MS'] == ms) & (df['in_sample'] == 1)]\n",
        "        model = smf.ols(formula=formula, data=df_filt).fit(cov_type='cluster', cov_kwds={'groups': df_filt[f'subloc_{dist}_grp']})\n",
        "        results[(dist, ms)] = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "vSZoETpyBBMy"
      },
      "outputs": [],
      "source": [
        "pvals = pd.DataFrame()\n",
        "# storeing pval in a df\n",
        "for dv in ['hi', 'monthnum', 'interact']:\n",
        "    val = {(k[0], k[1]): np.round(v.pvalues[dv],3) for k, v in results.items()}\n",
        "    pvals[dv] = pd.Series(val)\n",
        "\n",
        "# keep only columns 3km_wt and 3rd column in 1km_wt and 5km_wt\n",
        "pvals = pvals.T\n",
        "pvals = pvals[[('3km_wt', 1), ('3km_wt', 2), ('3km_wt', 3), ('1km_wt', 3), ('5km_wt', 3)]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "S5ZMLa8PBDSp"
      },
      "outputs": [],
      "source": [
        "def wild_bootstrap(data, model, n_bootstraps, dv, clust_var):\n",
        "    \"\"\"\n",
        "    Wild Cluster Bootstrap-t with random signs within clusters\n",
        "    \"\"\"\n",
        "    cluster_var = data[clust_var]\n",
        "    unique_clusters = cluster_var.unique()\n",
        "    boot_results = []\n",
        "\n",
        "    for _ in range(n_bootstraps):\n",
        "        boot_data = data.copy()\n",
        "        # resample residuals within each cluster\n",
        "        for cluster in unique_clusters:\n",
        "            cluster_indices = data[cluster_var == cluster].index\n",
        "\n",
        "            # multiply residuals by random signs, either -1 or 1, (radmacher weights)\n",
        "            signs = np.random.choice([-1, 1], size=len(cluster_indices))\n",
        "            boot_data.loc[cluster_indices, dv] = model.predict(data.loc[cluster_indices]) + signs * model.resid.loc[cluster_indices]\n",
        "\n",
        "        # Refit model on bootstrapped data\n",
        "        boot_model = smf.ols(model.model.formula, data=boot_data).fit()\n",
        "        boot_results.append(boot_model.params)\n",
        "\n",
        "    return np.array(boot_results)[:,1:4]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "JQQIwPu2BFpk"
      },
      "outputs": [],
      "source": [
        "bootstrap_res = {}\n",
        "bootstrap_pvals = pd.DataFrame(index=pd.MultiIndex.from_product([['1km_wt', '3km_wt', '5km_wt'], [1, 2, 3]], names=['dist', 'ms']), columns=['hi', 'monthnum', 'interact'])\n",
        "n_bootstraps = 9\n",
        "\n",
        "for dist  in ['1km_wt', '3km_wt', '5km_wt']:\n",
        "    df = cleanpricedata_y1y2_tab6.copy(deep=True)\n",
        "    df.dropna(subset=[f'hi_{dist}','salesPrice_trim','monthnum'], inplace=True)\n",
        "    mean_price = df[(df['monthnum'] == 0) & (df[f'hi_{dist}'] == 0)]['salesPrice_trim'].mean()\n",
        "    norm = 100 / mean_price\n",
        "\n",
        "    # normalize price\n",
        "    df['salesPrice_trim_norm'] = df['salesPrice_trim'] * norm\n",
        "    df['salesPrice_trim_norm'] = df['salesPrice_trim_norm'].astype(float)\n",
        "\n",
        "    # create hi variable\n",
        "    df['hi'] = df[f'hi_{dist}']\n",
        "    df['interact'] = df['monthnum'] * df['hi']\n",
        "\n",
        "    # regression\n",
        "    formula = 'salesPrice_trim_norm ~ hi + monthnum + interact'\n",
        "\n",
        "\n",
        "    for ms in [1,2,3]: # 3 is pooled\n",
        "        if ms == 3:\n",
        "            df_filt = df[(df['in_sample'] == 1)]\n",
        "        else:\n",
        "            df_filt = df[(df['MS'] == ms) & (df['in_sample'] == 1)]\n",
        "        res = wild_bootstrap(df_filt, results[(dist, ms)], n_bootstraps, 'salesPrice_trim_norm', f'subloc_{dist}_grp')\n",
        "        bootstrap_res[(dist,ms)] = res\n",
        "\n",
        "        model = results[(dist, ms)]\n",
        "\n",
        "        for i, var in enumerate(['hi', 'monthnum', 'interact']):\n",
        "            observed_coef = model.params[var]\n",
        "            # calculating p-values as proportion of bootstrap coefs where abs(boot_coef) >= abs(obs_coef)\n",
        "            p_value = np.round(np.mean(np.abs(bootstrap_res[(dist,ms)][:,i]) >= np.abs(observed_coef)),3)\n",
        "\n",
        "            # store p-value in df\n",
        "            bootstrap_pvals.loc[(dist,ms),var] = p_value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "PUQzZYEiBI4h"
      },
      "outputs": [],
      "source": [
        "bootstrap_pvals = bootstrap_pvals.T\n",
        "bootstrap_pvals = bootstrap_pvals[[('3km_wt', 1), ('3km_wt', 2), ('3km_wt', 3), ('1km_wt', 3), ('5km_wt', 3)]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv9ZnKRtBNWU",
        "outputId": "ebb52c56-42a9-4730-e51a-d6659f6b1520"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\\begin{tabular}{@{\\extracolsep{5pt}}lccccc}\n",
            "\\\\[-1.8ex]\\hline\n",
            "\\hline \\\\[-1.8ex]\n",
            "& \\multicolumn{5}{c}{\\textit{Dependent variable: Trimmed Sales Price}} \\\n",
            "\\cr \\cline{2-6}\n",
            "\\\\[-1.8ex] & \\multicolumn{3}{c}{Main Specification (3km)} & \\multicolumn{2}{c}{Robustness (Pooled)}  \\\\\n",
            "\\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) \n",
            " \\\\ & Y1 & Y2 & Pooled & 1km & 5km \\\\\n",
            "\\hline \\\\[-1.8ex]\n",
            " High & 4.410$^{**}$ & 2.855$^{}$ & 3.970$^{**}$ & 2.787$^{}$ & 3.766$^{**}$ \\\\\n",
            "& (2.091) & (1.992) & (1.817) & (1.719) & (1.822) \\\\\n",
            " Month & 1.189$^{***}$ & 1.224$^{***}$ & 1.364$^{***}$ & 1.327$^{***}$ & 1.537$^{***}$ \\\\\n",
            "& (0.363) & (0.377) & (0.350) & (0.339) & (0.291) \\\\\n",
            " High x Month & -0.574$^{}$ & -0.476$^{}$ & -0.573$^{}$ & -0.520$^{}$ & -0.835$^{**}$ \\\\\n",
            "& (0.422) & (0.459) & (0.386) & (0.390) & (0.366) \\\\\n",
            " P-value High & 0.035 & 0.152 & 0.029 & 0.105 & 0.039 \\\\\n",
            " P-value Treat Bootstrap & 0.444 & 0.556 & 0.667 & 0.778 & 0.778 \\\\\n",
            " P-value Month & 0.001 & 0.001 & 0.0 & 0.0 & 0.0 \\\\\n",
            " P-value High Bootstrap & 0.444 & 0.333 & 0.444 & 0.667 & 0.556 \\\\\n",
            " P-value High x Month & 0.173 & 0.3 & 0.138 & 0.182 & 0.023 \\\\\n",
            " P-value Treat x High Bootstrap & 0.444 & 0.667 & 0.667 & 0.667 & 0.556 \\\\\n",
            "\\hline \\\\[-1.8ex]\n",
            " Observations & 491 & 381 & 872 & 872 & 872 \\\\\n",
            " $R^2$ & 0.077 & 0.031 & 0.058 & 0.055 & 0.060 \\\\\n",
            " % Adjusted $R^2$ & 0.071 & 0.023 & 0.055 & 0.052 & 0.056 \\\\\n",
            " % Residual Std. Error & 10.071 & 14.651 & 12.700 & 12.726 & 12.685 \\\\\n",
            " % F Statistic & 6.401$^{***}$ & 7.496$^{***}$ & 13.411$^{***}$ & 10.971$^{***}$ & 16.730$^{***}$ \\\\\n",
            "\\hline\n",
            "\\hline \\\\[-1.8ex]\n",
            "% \\textit{Note:} & \\multicolumn{5}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\\\\n",
            "\\end{tabular}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# use stargazer to create a table\n",
        "result_list = [results[('3km_wt', 1)], results[('3km_wt', 2)], results[('3km_wt', 3)], results[('1km_wt', 3)], results[('5km_wt', 3)]]\n",
        "stargazer = Stargazer(result_list)\n",
        "\n",
        "# configure Stargazer object for output\n",
        "stargazer.custom_columns(['Main Specification (3km)', 'Robustness (Pooled)'], [3, 2])\n",
        "stargazer.rename_covariates({'hi': 'High', 'monthnum': 'Month', 'interact': 'High x Month'})\n",
        "stargazer.show_degrees_of_freedom(False)\n",
        "stargazer.significant_digits(3)\n",
        "stargazer.covariate_order(['hi', 'monthnum', 'interact'])\n",
        "# add p-values as a rows\n",
        "stargazer.add_line('P-value High', pvals.loc['hi'].values.tolist())\n",
        "stargazer.add_line('P-value Treat Bootstrap', bootstrap_pvals.loc['hi'].values.tolist())\n",
        "stargazer.add_line('P-value Month', pvals.loc['monthnum'].values.tolist())\n",
        "stargazer.add_line('P-value High Bootstrap', bootstrap_pvals.loc['monthnum'].values.tolist())\n",
        "stargazer.add_line('P-value High x Month', pvals.loc['interact'].values.tolist())\n",
        "stargazer.add_line('P-value Treat x High Bootstrap', bootstrap_pvals.loc['interact'].values.tolist())\n",
        "\n",
        "\n",
        "latex_table6 = stargazer.render_latex()\n",
        "\n",
        "# edit the latex tables\n",
        "latex_table6 = latex_table6.replace(\"\\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) \\\\\",\n",
        "                                \"\\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) \\n \\\\\\ & Y1 & Y2 & Pooled & 1km & 5km \\\\\")\n",
        "latex_table6 = latex_table6.replace(\"Adjusted $R^2$\", \"% Adjusted $R^2$\")\n",
        "latex_table6 = latex_table6.replace(\"Residual Std. Error\", \"% Residual Std. Error\")\n",
        "latex_table6 = latex_table6.replace(\"F Statistic\", \"% F Statistic\")\n",
        "latex_table6 = latex_table6.replace(\"\\\\textit{Note\",\"% \\\\textit{Note\")\n",
        "latex_table6 = latex_table6.replace(\"salesPrice_trim_norm\",\"Trimmed Sales Price\")\n",
        "latex_table6 = latex_table6.replace(\"\\\\begin{table}[!htbp] \\\\centering\", \"\")\n",
        "latex_table6 = latex_table6.replace(\"\\\\end{table}\", \"\")\n",
        "\n",
        "print(latex_table6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXsVtSIyyW_w"
      },
      "source": [
        "## Table 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "hRr_Mp-DyYTi"
      },
      "outputs": [],
      "source": [
        "# copy the raw data and create columns for treatment and interaction variable\n",
        "ms1ms2_pooled_tab7 = ms1ms2_pooled.copy(deep=True)\n",
        "# filter relevant columns\n",
        "ms1ms2_pooled_tab7 = ms1ms2_pooled_tab7[['oafid', # id\n",
        "                                         'treat12', 'treat13', 'treatMS1MS2', # treatment variables\n",
        "                                         'inventory_trim', 'netrevenue_trim', 'logtotcons_trim', # outcome variables\n",
        "                                         'Y1round2', 'Y1round3', 'Y2round1', 'Y2round2', 'Y2round3','hi','subloc','interviewdate']] # independent variables\n",
        "\n",
        "ms1ms2_pooled_tab7.sort_index(inplace=True)\n",
        "ms1ms2_pooled_tab7['z'] = pd.NA\n",
        "ms1ms2_pooled_tab7['z_hi'] = pd.NA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EjJ8Mj1g3ND"
      },
      "source": [
        "### Running the first set of regressions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tb7xZ1W4yiA9",
        "outputId": "eabe3d8f-7a16-48be-a95b-c3f29b145855"
      },
      "outputs": [],
      "source": [
        "# list of treaments\n",
        "treatments = ['treat12', 'treat13', 'treatMS1MS2']\n",
        "\n",
        "# list of dependent variables\n",
        "dependent_vars = ['inventory_trim', 'netrevenue_trim', 'logtotcons_trim']\n",
        "\n",
        "# list of changeing independent variables depending on the treatment\n",
        "independent_vars = {\n",
        "    'treat12': 'Y1round2 + Y1round3',\n",
        "    'treat13': 'Y2round2 + Y2round3',\n",
        "    'treatMS1MS2': 'Y1round2 + Y1round3 + Y2round1 + Y2round2 + Y2round3'\n",
        "    }\n",
        "\n",
        "# empty dictionary to store results\n",
        "results = {}\n",
        "pvals = {var: [] for var in ['z', 'hi', 'z_hi','z+z_hi']}\n",
        "\n",
        "# Simulating the loop to replace variables and run regressions\n",
        "for dv in dependent_vars:\n",
        "    for treat in treatments:\n",
        "        # Stata automatically omits the missing values in the regression – here we have to do it manually so we copy the data and drop variables\n",
        "        df = ms1ms2_pooled_tab7.copy(deep=True)\n",
        "        df = df.dropna(subset=[dv, treat, 'hi', 'subloc','interviewdate'])\n",
        "        # setting treament variable\n",
        "        df['z'] = df[treat] # setting z to the treatment variable\n",
        "\n",
        "        # setting interaction variable\n",
        "        df['z_hi'] = df[treat]*df['hi'] # setting z_hi to the interaction of the treatment hi saturation\n",
        "\n",
        "        # setting the formula to run the regression\n",
        "        formula = f'{dv} ~ z + hi + z_hi + interviewdate + {independent_vars[treat]}'\n",
        "\n",
        "        # Run the regression\n",
        "        model_key = f'model_{dependent_vars.index(dv)*len(treatments) + treatments.index(treat)}'\n",
        "        results[model_key] = smf.ols(formula, data=df).fit(cov_type='cluster', cov_kwds={'groups': df['subloc']})\n",
        "\n",
        "        # test the hypothesis that z + z_hi = 0\n",
        "        hypothesis = 'z + z_hi = 0'\n",
        "        t_test = results[model_key].t_test(hypothesis)\n",
        "\n",
        "        # store p-value round to 3 decimals\n",
        "        pvals['z+z_hi'].append(np.round(t_test.pvalue,3))\n",
        "        pvals['z'].append(np.round(results[model_key].pvalues['z'],3))\n",
        "        pvals['hi'].append(np.round(results[model_key].pvalues['hi'],3))\n",
        "        pvals['z_hi'].append(np.round(results[model_key].pvalues['z_hi'],3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOjQSC-NhbD7"
      },
      "source": [
        "### Running boostrap regressions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "rtNR18qGhgM5"
      },
      "outputs": [],
      "source": [
        "n_bootstraps = 999  # reported data is based on 999 iterations\n",
        "bootstrap_res = {}\n",
        "bootstrap_pvals = {var: [] for var in ['z', 'hi', 'z_hi']}\n",
        "\n",
        "for dv in dependent_vars:\n",
        "    for treat in treatments:\n",
        "        df = ms1ms2_pooled_tab7.copy(deep=True)\n",
        "        df = df.dropna(subset=[dv, treat, 'hi', 'subloc', 'interviewdate'])\n",
        "        df['z'] = df[treat]\n",
        "        df['z_hi'] = df[treat] * df['hi']\n",
        "        df[dv] = df[dv].astype(float)\n",
        "\n",
        "        formula = f'{dv} ~ z + hi + z_hi + interviewdate + {independent_vars[treat]}'\n",
        "        model_key = f'model_{dependent_vars.index(dv)*len(treatments) + treatments.index(treat)}'\n",
        "        model = results[model_key]\n",
        "\n",
        "        # Wild bootstrap\n",
        "        res = wild_bootstrap(df, model, n_bootstraps, dv,'subloc')\n",
        "        bootstrap_res[model_key] = res\n",
        "\n",
        "        for i, var in enumerate(['z', 'hi', 'z_hi']):\n",
        "            observed_coef = model.params[var]\n",
        "            # calculating p-values as proportion of bootstrap coefs where abs(boot_coef) >= abs(obs_coef)\n",
        "            p_value = np.round(np.mean(np.abs(bootstrap_res[model_key][:,i]) >= np.abs(observed_coef)),3)\n",
        "            bootstrap_pvals[var].append(p_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UdXeJZAhhEo"
      },
      "source": [
        "### Output to LaTeX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "DOQVwnBvwMBm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\\begin{tabular}{@{\\extracolsep{5pt}}lccccccccc}\n",
            "\\\\[-1.8ex]\\hline\n",
            "\\hline \\\\[-1.8ex]\n",
            "\\\\[-1.8ex] & \\multicolumn{3}{c}{Inventory} & \\multicolumn{3}{c}{Net Revenues} & \\multicolumn{3}{c}{Consumption}  \\\\\n",
            "\\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) & (6) & (7) & (8) & (9) \n",
            " \\\\ & Y1 & Y2 & Pooled & Y1 & Y2 & Pooled & Y1 & Y2 & Pooled \\\\\n",
            "\\hline \\\\[-1.8ex]\n",
            " Treat & 0.759$^{***}$ & 0.546$^{***}$ & 0.740$^{***}$ & 1059.602$^{**}$ & 1193.768$^{*}$ & 1101.389$^{**}$ & 0.012$^{}$ & -0.051$^{}$ & -0.011$^{}$ \\\\\n",
            "& (0.189) & (0.185) & (0.155) & (437.732) & (685.048) & (430.091) & (0.040) & (0.040) & (0.023) \\\\\n",
            " High & 0.124$^{}$ & -0.028$^{}$ & 0.017$^{}$ & 533.903$^{}$ & -152.603$^{}$ & 164.936$^{}$ & -0.003$^{}$ & -0.084$^{}$ & -0.047$^{}$ \\\\\n",
            "& (0.355) & (0.219) & (0.241) & (551.179) & (558.948) & (479.685) & (0.051) & (0.053) & (0.043) \\\\\n",
            " Treat x High & -0.333$^{}$ & -0.065$^{}$ & -0.291$^{}$ & -1114.628$^{**}$ & -555.215$^{}$ & -816.770$^{}$ & -0.013$^{}$ & 0.174$^{***}$ & 0.067$^{*}$ \\\\\n",
            "& (0.229) & (0.255) & (0.192) & (535.594) & (804.864) & (520.036) & (0.052) & (0.055) & (0.037) \\\\\n",
            " P-value T + TH = 0 & 0.002 & 0.006 & 0.002 & 0.861 & 0.125 & 0.396 & 0.969 & 0.001 & 0.063 \\\\\n",
            " P-value Treat & 0.0 & 0.003 & 0.0 & 0.015 & 0.081 & 0.01 & 0.764 & 0.209 & 0.621 \\\\\n",
            " P-value Treat Bootstrap & 0.495 & 0.514 & 0.512 & 0.499 & 0.472 & 0.491 & 0.757 & 0.502 & 0.727 \\\\\n",
            " P-value High & 0.726 & 0.899 & 0.944 & 0.333 & 0.785 & 0.731 & 0.961 & 0.115 & 0.279 \\\\\n",
            " P-value High Bootstrap & 0.566 & 0.857 & 0.877 & 0.503 & 0.733 & 0.627 & 0.956 & 0.468 & 0.469 \\\\\n",
            " P-value Treat*High & 0.146 & 0.799 & 0.13 & 0.037 & 0.49 & 0.116 & 0.798 & 0.002 & 0.072 \\\\\n",
            " P-value Treat*High Bootstrap & 0.486 & 0.769 & 0.521 & 0.512 & 0.488 & 0.483 & 0.798 & 0.491 & 0.499 \\\\\n",
            "\\hline \\\\[-1.8ex]\n",
            " Observations & 3836 & 2944 & 6780 & 3795 & 2935 & 6730 & 3792 & 2944 & 6736 \\\\\n",
            " $R^2$ & 0.346 & 0.184 & 0.293 & 0.009 & 0.043 & 0.091 & 0.002 & 0.017 & 0.025 \\\\\n",
            " % % Adjusted $R^2$ & 0.345 & 0.182 & 0.292 & 0.008 & 0.041 & 0.090 & 0.000 & 0.015 & 0.024 \\\\\n",
            " % % Residual Std. Error & 3.015 & 2.793 & 2.947 & 6188.647 & 6410.741 & 6286.767 & 0.621 & 0.647 & 0.633 \\\\\n",
            " % % F Statistic & 369.556$^{***}$ & 93.029$^{***}$ & 364.779$^{***}$ & 2.004$^{*}$ & 19.627$^{***}$ & 119.335$^{***}$ & 0.616$^{}$ & 4.496$^{***}$ & 16.477$^{***}$ \\\\\n",
            "\\hline\n",
            "\\hline \\\\[-1.8ex]\n",
            "% % \\textit{Note:} & \\multicolumn{9}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\\\\n",
            "\\end{tabular}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# use stargazer to create a table\n",
        "result_list = list(results.values())\n",
        "stargazer = Stargazer(result_list)\n",
        "\n",
        "# configure Stargazer object for output\n",
        "stargazer.custom_columns(['Inventory', 'Net Revenues', 'Consumption'], [3, 3, 3])\n",
        "stargazer.rename_covariates({'z': 'Treat', 'hi': 'High', 'z_hi': 'Treat x High'})\n",
        "stargazer.show_degrees_of_freedom(False)\n",
        "stargazer.significant_digits(3)\n",
        "stargazer.covariate_order(['z', 'hi', 'z_hi'])\n",
        "# add p-values as a rows\n",
        "stargazer.add_line('P-value T + TH = 0', pvals['z+z_hi'])\n",
        "stargazer.add_line('P-value Treat', pvals['z'])\n",
        "stargazer.add_line('P-value Treat Bootstrap', bootstrap_pvals['z'])\n",
        "stargazer.add_line('P-value High', pvals['hi'])\n",
        "stargazer.add_line('P-value High Bootstrap', bootstrap_pvals['hi'])\n",
        "stargazer.add_line('P-value Treat*High', pvals['z_hi'])\n",
        "stargazer.add_line('P-value Treat*High Bootstrap', bootstrap_pvals['z_hi'])\n",
        "\n",
        "\n",
        "latex_table7 = stargazer.render_latex()\n",
        "\n",
        "# edit the latex table to add row for telling if Y1 Y2 or Pooled after \\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) & (6) & (7) & (8) & (9) \\\\\n",
        "latex_table7 = latex_table7.replace(\"\\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) & (6) & (7) & (8) & (9) \\\\\",\n",
        "                                \"\\\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) & (6) & (7) & (8) & (9) \\n \\\\\\ & Y1 & Y2 & Pooled & Y1 & Y2 & Pooled & Y1 & Y2 & Pooled \\\\\")\n",
        "latex_table7 = latex_table7.replace(\"Adjusted $R^2$\", \"% Adjusted $R^2$\")\n",
        "latex_table7 = latex_table7.replace(\"Residual Std. Error\", \"% Residual Std. Error\")\n",
        "latex_table7 = latex_table7.replace(\"F Statistic\", \"% F Statistic\")\n",
        "latex_table7 = latex_table7.replace(\"\\\\textit{\",\"% \\\\textit{\")\n",
        "latex_table7 = latex_table7.replace(\"\\\\begin{table}[!htbp] \\\\centering\", \"\")\n",
        "latex_table7 = latex_table7.replace(\"\\\\end{table}\", \"\")\n",
        "\n",
        "print(latex_table7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F11Z5SCUQyO_"
      },
      "source": [
        "## Table 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "hE0tG6KRQ0xg"
      },
      "outputs": [],
      "source": [
        "tab8_dt = ms1ms2_pooled.loc[:, ['treatMS1MS2', 'hi', 'treatMS1MS2hi', 'interviewdate', 'netrevenue_trim', 'strata_group', 'groupnum', 'subloc', 'Y1round1', 'Y1round2', 'Y1round3', 'Y2round1', 'Y2round2', 'Y2round3']].dropna()\n",
        "tab8_dt['net_revenue_3'] = tab8_dt['netrevenue_trim'] * 3\n",
        "model = smf.ols('net_revenue_3 ~ treatMS1MS2 + hi + treatMS1MS2hi + interviewdate + Y1round1 + Y1round2 + Y1round3 + Y2round1 + Y2round2 + Y2round3', data=tab8_dt)\n",
        "results_t8 = model.fit(cov_type='cluster', cov_kwds={'groups': tab8_dt['subloc']})\n",
        "model_params_t8 = results_t8.params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ocrbGi-hmfA",
        "outputId": "ef6091c5-aada-4e72-da7a-5d91243def0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\begin{tabular}{lrr}\n",
            "\\toprule\n",
            " & Low Saturation & High Saturation \\\\\n",
            "\\midrule\n",
            "1. Direct gains/HH (Ksh) & 3304.166 & 853.856 \\\\\n",
            "2. Indirect gains/HH (Ksh) & 0.000 & 494.807 \\\\\n",
            "3. Ratio of indirect to direct gains & 0.000 & 0.579 \\\\\n",
            "4. Direct beneficiary population (HH) & 247.000 & 495.000 \\\\\n",
            "5. Total local population (HH) & 3553.000 & 3553.000 \\\\\n",
            "6. Total direct gains (Ksh) & 816128.985 & 422658.745 \\\\\n",
            "7. Total indirect gains (Ksh) & 0.000 & 1758050.851 \\\\\n",
            "8. Total gains (direct + indirect; Ksh) & 816128.985 & 2180709.596 \\\\\n",
            "9. Fraction of gains direct & 1.000 & 0.194 \\\\\n",
            "10. Fraction of gains indirect & 0.000 & 0.806 \\\\\n",
            "\\bottomrule\n",
            "\\end{tabular}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Annualized coefficients\n",
        "treat_coef = model_params_t8['treatMS1MS2']\n",
        "treat_hi_coef = (model_params_t8['treatMS1MS2'] + model_params_t8['treatMS1MS2hi'])\n",
        "hi_coef = model_params_t8['hi']\n",
        "\n",
        "# Direct beneficiary population\n",
        "direct_beneficiary_pop_low = 247.0\n",
        "direct_beneficiary_pop_high = 495.0\n",
        "\n",
        "# Total direct gains\n",
        "total_direct_gains_low = treat_coef * direct_beneficiary_pop_low\n",
        "total_direct_gains_high = treat_hi_coef * direct_beneficiary_pop_high\n",
        "\n",
        "# Total indirect gains (only applicable to high saturation areas)\n",
        "total_indirect_gains_high = hi_coef * 3553.0\n",
        "\n",
        "# Total gains\n",
        "total_gains_low = total_direct_gains_low\n",
        "total_gains_high = total_direct_gains_high + total_indirect_gains_high\n",
        "\n",
        "# Fraction of gains direct\n",
        "fraction_gains_direct_low = 1  # All gains are direct in low saturation\n",
        "fraction_gains_direct_high = total_direct_gains_high / total_gains_high\n",
        "\n",
        "# Fraction of gains indirect (only applicable to high saturation areas)\n",
        "fraction_gains_indirect_high = total_indirect_gains_high / total_gains_high\n",
        "\n",
        "table_8 = {\n",
        "    \"1. Direct gains/HH (Ksh)\": [treat_coef, treat_hi_coef],\n",
        "    \"2. Indirect gains/HH (Ksh)\": [0, hi_coef],\n",
        "    \"3. Ratio of indirect to direct gains\": [0, hi_coef / treat_hi_coef],\n",
        "    \"4. Direct beneficiary population (HH)\": [direct_beneficiary_pop_low, direct_beneficiary_pop_high],\n",
        "    \"5. Total local population (HH)\": [3553.0, 3553.0],\n",
        "    \"6. Total direct gains (Ksh)\": [total_direct_gains_low, total_direct_gains_high],\n",
        "    \"7. Total indirect gains (Ksh)\": [0, total_indirect_gains_high],\n",
        "    \"8. Total gains (direct + indirect; Ksh)\": [total_gains_low, total_gains_high],\n",
        "    \"9. Fraction of gains direct\": [fraction_gains_direct_low, fraction_gains_direct_high],\n",
        "    \"10. Fraction of gains indirect\": [0, fraction_gains_indirect_high],\n",
        "}\n",
        "\n",
        "# Convert the calculations to DataFrame and transpose it\n",
        "table_8_df = pd.DataFrame(table_8, index=[\"Low Saturation\", \"High Saturation\"]).T\n",
        "\n",
        "# Now you can print table_8_df to see the recreated table\n",
        "table_8_df\n",
        "\n",
        "latex_table8 = table_8_df.to_latex(index=True, float_format=\"%.3f\")\n",
        "print(latex_table8)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "NLR-EsZmPhnZ",
        "J2Kt7J_ve0Jr",
        "MapKqTx56PLs",
        "EFcatyv4Dk08",
        "iFWCk0Ja1NUj",
        "eXsVtSIyyW_w"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
